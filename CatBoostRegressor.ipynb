{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vasya.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ8W9XMzQ1iJ",
        "outputId": "c58e3439-1e62-48c8-d747-285158fe93fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "TRAIN_DF_PATH = '/content/drive/MyDrive/INF554/train_df_thr-1.csv'\n",
        "VAL_DF_PATH = '/content/drive/MyDrive/INF554/val_df_thr1-1.csv'\n",
        "TEST_DF_PATH = '/content/drive/MyDrive/INF554/test_df_thr1_fixed.csv'"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz8Z_ymfREhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8e8780-1f87-4868-ac6d-eb7935170519"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from collections import Counter\n",
        "from math import ceil, floor\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "df = pd.read_csv(TRAIN_DF_PATH)\n",
        "df[df.retweet_count.isna()].shape\n",
        "df['retweet_count'].fillna(0, inplace=True)\n",
        "df.shape\n",
        "\n",
        "df_sample = df.sample(100)[['text']]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk-iDvXRRQJb",
        "outputId": "e6b8349e-51c1-4b85-9bea-c1c765526731"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "YNK40mUkSRWz",
        "outputId": "2cbb267a-532c-4d6d-9410-cd64587a93a8"
      },
      "source": [
        "df_train = pd.read_csv(TRAIN_DF_PATH)\n",
        "df_train.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>urls</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>text</th>\n",
              "      <th>bert_threshold_1_answer</th>\n",
              "      <th>bert_threshold_1_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>499614</td>\n",
              "      <td>499614.0</td>\n",
              "      <td>1.588532e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>8187.0</td>\n",
              "      <td>3761.0</td>\n",
              "      <td>4803.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Surprise\\nSurprise\\nSurprise\\n\\n*quoting Gomer Pyle again</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>86193</td>\n",
              "      <td>86193.0</td>\n",
              "      <td>1.588331e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>87997.0</td>\n",
              "      <td>723.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Surprise ruined ☹️</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>377477</td>\n",
              "      <td>377477.0</td>\n",
              "      <td>1.588556e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>37990.0</td>\n",
              "      <td>12424.0</td>\n",
              "      <td>3225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Are we, as a nation, poised to fail the marshmallow test?</td>\n",
              "      <td>0</td>\n",
              "      <td>0.012423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>367024</td>\n",
              "      <td>367024.0</td>\n",
              "      <td>1.588593e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Smh... and we got people over here praising Newsom..</td>\n",
              "      <td>0</td>\n",
              "      <td>0.023887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>72557</td>\n",
              "      <td>72557.0</td>\n",
              "      <td>1.588342e+12</td>\n",
              "      <td>59.0</td>\n",
              "      <td>True</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>223167.0</td>\n",
              "      <td>619.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>twitter.com/i/web/status/1…</td>\n",
              "      <td>COVID19</td>\n",
              "      <td>We are at war on two fronts: #COVID19 pandemic and this unprecedented virus. The other is this war against the Chinese Communist Party--both an information war and an economic war, says Steve Bannon. https://t.co/L5JscPd7ZQ</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Unnamed: 0.1  ...  bert_threshold_1_answer  bert_threshold_1_prob\n",
              "0  0           499614       ...  0                        0.011031             \n",
              "1  1           86193        ...  0                        0.011133             \n",
              "2  2           377477       ...  0                        0.012423             \n",
              "3  3           367024       ...  0                        0.023887             \n",
              "4  4           72557        ...  1                        0.996533             \n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y7VGDljRtIR"
      },
      "source": [
        "### Get insights from highest number of tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oMFmD9pRTnA"
      },
      "source": [
        "# df_train['retweet_count'].sort_values()[-50:]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYRtzlfKT43R"
      },
      "source": [
        "# s = '''245304    120903.0\n",
        "# 384201    122382.0\n",
        "# 244653    123334.0\n",
        "# 170223    126026.0\n",
        "# 177807    126414.0\n",
        "# 34679     128138.0\n",
        "# 89082     128469.0\n",
        "# 192294    129528.0\n",
        "# 288131    130964.0\n",
        "# 225462    131037.0\n",
        "# 30544     131089.0\n",
        "# 92135     131810.0\n",
        "# 322445    133198.0\n",
        "# 327406    136665.0\n",
        "# 456003    136876.0\n",
        "# 73799     138127.0\n",
        "# 220279    138475.0\n",
        "# 421049    138668.0\n",
        "# 93803     140896.0\n",
        "# 369808    141000.0\n",
        "# 182917    144605.0\n",
        "# 214140    144887.0\n",
        "# 356889    145836.0\n",
        "# 35250     146077.0\n",
        "# 408497    155376.0\n",
        "# 87853     156817.0\n",
        "# 313627    163910.0\n",
        "# 508653    166665.0\n",
        "# 243526    168249.0\n",
        "# 521825    178111.0\n",
        "# 427645    185406.0\n",
        "# 215765    187101.0\n",
        "# 183657    194810.0\n",
        "# 285202    207384.0\n",
        "# 306038    208130.0\n",
        "# 434088    208844.0\n",
        "# 180828    209370.0\n",
        "# 132765    241820.0\n",
        "# 328378    252369.0\n",
        "# 327826    256197.0\n",
        "# 179664    333211.0\n",
        "# 398273    334427.0\n",
        "# 519580    415787.0\n",
        "# 525624    636394.0\n",
        "# 324809    647993.0\n",
        "# 310505    942572.0'''\n",
        "# list_ = []\n",
        "# for i in s.split('\\n'):\n",
        "#   list_.append(int(i[:6]))\n",
        "# list_\n",
        "# df_train.iloc[list_]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuHAX58KRWWG"
      },
      "source": [
        "### Extract features from text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDV6YBkvRZS3",
        "outputId": "20548113-0089-4a5c-87d7-a251fab8aff7"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGHH_zg-R9OE"
      },
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "\n",
        "def clean_texts(df):\n",
        "    # remove URL\n",
        "    df['text_proc'] = df['text'].str.replace(r'http(\\S)+', r'')\n",
        "    df['text_proc'].fillna('', inplace=True)\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'http ...', r'')\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'http', r'')\n",
        "\n",
        "    # remove RT, @\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'(RT|rt)[ ]*@[ ]*[\\S]+', r'')\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'@[\\S]+', r'')\n",
        "\n",
        "    # remove non-ascii words and characters\n",
        "    df['text_proc'] = [''.join([i if ord(i) < 128 else '' for i in text]) for text in df['text_proc'].values]\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'_[\\S]?', r'')\n",
        "\n",
        "    # remove &, < and >\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'&amp;?', r'and')\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'&lt;', r'<')\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'&gt;', r'>')\n",
        "\n",
        "    # remove extra space\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'[ ]{2, }', r' ')\n",
        "\n",
        "    # insert space between punctuation marks\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'([\\w\\d]+)([^\\w\\d ]+)', r'\\1 \\2')\n",
        "    df['text_proc'] = df['text_proc'].str.replace(r'([^\\w\\d ]+)([\\w\\d]+)', r'\\1 \\2')\n",
        "\n",
        "    # lower case and strip white spaces at both ends\n",
        "    df['text_proc'] = df['text_proc'].str.lower()\n",
        "    df['text_proc'] = df['text_proc'].str.strip()\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_text_features(df_):\n",
        "    df = df_.copy()\n",
        "    df = clean_texts(df)\n",
        "    df['text'].fillna('', inplace=True)\n",
        "    df['text_length'] = df['text'].str.len()\n",
        "    df['text_proc_length'] = df['text_proc'].str.len()\n",
        "    df['text_proc_length_to_text_length'] = df['text_proc_length'] / df['text_length']\n",
        "    df['text_lines_count'] = df['text'].str.count('\\n')\n",
        "    df['text_word_count'] = df['text'].str.split().apply(len)\n",
        "    df['text_proc_word_count'] = df['text_proc'].str.split().apply(len)\n",
        "    df['text_proc_word_count_to_text_word_count'] = df['text_proc_word_count'] / df['text_word_count']\n",
        "    df['text_mean_word_length'] = df['text'].str.split().apply(lambda arr: np.mean([len(word) for word in arr]))\n",
        "    df['text_proc_mean_word_length'] = df['text_proc'].str.split().apply(lambda arr: np.mean([len(word) for word in arr]))\n",
        "    df['text_proc_mean_word_length_to_text_mean_word_length'] = df['text_proc_mean_word_length'] / df['text_mean_word_length']\n",
        "    df['text_proc_alphas_count'] = df['text_proc'].apply(lambda s: sum(c.isalpha() for c in s))\n",
        "    df['text_alphas_count'] = df['text'].apply(lambda s: sum(c.isalpha() for c in s))\n",
        "    df['text_proc_alphas_count_to_text_alphas_count'] = df['text_proc_alphas_count'] / df['text_alphas_count']\n",
        "    df['text_alphas_percent'] = df['text_alphas_count'] / df['text_length']\n",
        "    df['text_non_alphas_count'] = df['text'].apply(lambda s: sum(not c.isalpha() for c in s))\n",
        "    df['text_digits_count'] = df['text'].apply(lambda s: sum(c.isdigit() for c in s))\n",
        "    df['text_digits_count'] = df['text'].apply(lambda s: sum(c.isdigit() for c in s))\n",
        "    df['text_emoji_count'] = df['text'].apply(lambda s: sum(c in UNICODE_EMOJI for c in s))\n",
        "    df['text_emoji_percent'] = df['text_emoji_count'] / df['text_length']\n",
        "    df['text_has_emoji'] = (df['text_emoji_count'] > 0).astype(int)\n",
        "    df['text_upper_letter_count'] = df['text'].apply(lambda s: sum(1 for c in s if c.isupper()))\n",
        "    df['text_upper_letter_count_to_word_count'] = df['text_upper_letter_count'] / df['text_word_count']\n",
        "    df['text_upper_letter_count_to_length'] = df['text_upper_letter_count'] / df['text_length']\n",
        "    df['text_urls_count'] = df['text'].apply(lambda s: len(re.findall(r'http(\\S)+', s)))\n",
        "    df['text_urls_count_to_words_count'] = df['text_urls_count'] / df['text_word_count']\n",
        "    df['text_hashtags_count'] = df['text'].apply(lambda s: len(re.findall(r'#[a-zA-Z]+', s)))\n",
        "    df['text_hashtags_count_to_words_count'] = df['text_hashtags_count'] / df['text_word_count']\n",
        "    df['text_usertag_count'] = df['text'].apply(lambda s: len(re.findall(r'@[a-zA-Z_]+', s)))\n",
        "    df['text_usertags_count_to_words_count'] = df['text_usertag_count'] / df['text_word_count']\n",
        "    df['text_punctuation_count'] = df['text'].apply(lambda s: sum(1 for c in s if c in punctuation))\n",
        "    df['text_proc_punctuation_count'] = df['text_proc'].apply(lambda s: sum(1 for c in s if c in punctuation))\n",
        "    df['text_punctuation_rate'] = df['text_punctuation_count'] / df['text_length']\n",
        "    df['text_punctuation_to_alpha'] = df['text_punctuation_count'] / df['text_alphas_count']\n",
        "    df['text_proc_punctuation_to_alpha'] = df['text_proc_punctuation_count'] / df['text_proc_alphas_count']\n",
        "    df['text_punctuation_unique_count'] = df['text'].apply(lambda s: len(set([c for c in s if c in punctuation])))\n",
        "    df['text_proc_count_!'] = df['text_proc'].apply(lambda s: sum(c == '!' for c in s))\n",
        "    df['text_proc_count_?'] = df['text_proc'].apply(lambda s: sum(c == '?' for c in s))\n",
        "\n",
        "    return df"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGGKLKcFcUs1"
      },
      "source": [
        "def encode(s, word):\n",
        "  try:\n",
        "    if word in s.lower():\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  except:\n",
        "    # print(s)\n",
        "    return 0\n",
        "\n",
        "def simple_encoder(df_, list_):\n",
        "  df = df_.copy()\n",
        "  for word in list_:\n",
        "    df[word] = df['text'].apply(lambda s: encode(s, word))\n",
        "  return df\n",
        "\n",
        "listik_ = ['fuck', 'shit', 't.co', 'covid', 'coronavirus']\n",
        "\n",
        "df_train_encode = simple_encoder(df_train, listik_)\n",
        "df_train_encode.head()\n",
        "\n",
        "df_test = pd.read_csv(TEST_DF_PATH)\n",
        "df_test_encode = simple_encoder(df_test, listik_)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNn1fWoRboiA",
        "outputId": "97373d30-884e-4adb-9dac-4b8ff2490302"
      },
      "source": [
        "df_train_text = add_text_features(df_train_encode)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nY3K7eK25wM",
        "outputId": "f9107d5c-34fa-488e-999c-88b0242e47d3"
      },
      "source": [
        "df_test_text = add_text_features(df_test_encode)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jCeXUp-n0wJ"
      },
      "source": [
        "df_train_text['COVID'] = df_train_text['coronavirus'] + df_train_text['covid']\n",
        "df_test_text['COVID'] = df_test_text['coronavirus'] + df_test_text['covid']"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zq8oewM_c98"
      },
      "source": [
        "WORDS = ['#', 'coronavirus', 'covid', 'covid19', 'i', 'you', 'we', 'all', 'people', 'will', 'our', 'can', 'my', 'your', 'pandemic',\n",
        "         'new', 'trump', 'cases', 'help', 'need', 'health', 'good', 'deaths', 'should', 'please', 'today', 'world', 'virus', 'lockdown',\n",
        "         'work', 'news', 'china', 'government', 'crisis', 'support', 'country', 'im', 'thank', 'death', 'workers', '2020', '$', 'against',\n",
        "         'testing', 'response', 'must', 'president', 'never', 'patients', 'positive', 'public', 'social', 'hope', 'life', 'everyone', 'spread',\n",
        "         'fight', 'test', 'love', 'uk', 'safe', 'live', 'free', 'year', 'working', 'states', 'week', 'money', 'dr', 'vaccine', 'fuck', 'better',\n",
        "         'getting', 'shit', 'days', 'thing', 'real', 'america', 'times', 'data', 'lives', 'end', 'tests', 'community', 'best', 'thanks', 'needs',\n",
        "         'important', 'number', 'million', 'global', 'food', 'medical', 'corona', 'americans', 'died', 'outbreak', 'tested', 'family', 'die', 'video',\n",
        "         'yes', 'sure', 'media', 'together', 'weeks', 'economy', 'fucking', 'business', 'job', 'years', 'india', 'iran', 'numbers', 'bad', 'masks',\n",
        "         'check', 'hospital', 'case', 'children', 'risk', 'impact', 'story', 'april', 'latest', 'information', 'countries', 'protect',\n",
        "         'update', 'learn', 'distancing', 'post', 'team', 'city', 'report', 'la', 'old', 'online', 'continue', 'chinese', 'american',\n",
        "         'local', 'white', 'quarantine', 'confirmed', 'economic', 'research', 'person', 'wrong', 'govt', 'national', 'emergency', 'plan', 'place', \n",
        "         'doctors', 'dead', '20', 'buisenesses', 'human', 'rate', 'truth', 'months', 'activity', 'wuhan', 'feel', 'sick', 'himan', 'rate', 'breaking',\n",
        "         'disease', 'save', 'governor', 'others', 'hear', 'healthcare', 'famil', 'school', 'bill', 'sad', 'remember', 'stupid', 'nhs', 'women', 'gov',\n",
        "         'reopen', 'south', 'sitiation', 'cure', 'hospitals', 'kids', 'contact', 'damn', 'police', 'worse', 'app', 'resources', 'lab', 'questions',\n",
        "         'question', 'reports', 'york', 'nigeria', 'treatment', 'infected', 'covid9', 'cause', 'vote', 'leaders', 'federal', 'close', 'ass', 'experts',\n",
        "         'fighting', 'africa', ''\n",
        "]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6jL1bp3_dHI"
      },
      "source": [
        "def add_has_word_feature(df, word):\n",
        "    df['text_has_word_%s' % word] = df['text_proc'].apply(lambda s: int(word in s))\n",
        "    return df\n",
        "\n",
        "def add_has_words_features(df_, words):\n",
        "    df = df_.copy()\n",
        "    for word in words:\n",
        "        df = add_has_word_feature(df, word)\n",
        "    return df"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb7pR3C4_dM5"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def add_timestamp_features(df_):\n",
        "    df = df_.copy()\n",
        "    df['timestamp'].fillna(df['timestamp'].mean(), inplace=True)\n",
        "    df['datetime'] = df['timestamp'].apply(lambda s: datetime.fromtimestamp(s // 1000))\n",
        "    df['time_day'] = df['datetime'].apply(lambda s: s.day)\n",
        "    df['time_month'] = df['datetime'].apply(lambda s: s.month)\n",
        "    df['time_hour'] = df['datetime'].apply(lambda s: s.hour)\n",
        "    return df"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rceMau6z_low"
      },
      "source": [
        "df_train_text = add_has_words_features(df_train_text, WORDS)\n",
        "df_test_text = add_has_words_features(df_test_text, WORDS)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlLF5qtB_lx2"
      },
      "source": [
        "df_train_text = add_timestamp_features(df_train_text)\n",
        "df_test_text = add_timestamp_features(df_test_text)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXDYBv2_RZ0n"
      },
      "source": [
        "### Extract numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ipf2s3_Rcr3"
      },
      "source": [
        "def counting(s):\n",
        "  if type(s) == str:\n",
        "    return s.count(',') + 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def add_features(df_):\n",
        "  df = df_.copy()\n",
        "\n",
        "  df['user_verified'].fillna(0, inplace=True)\n",
        "  df['verified_int'] = df['user_verified'].apply(lambda x: int(x))\n",
        "  df['vfollowers'] = df['verified_int'] * df['user_followers_count']\n",
        "  df['vfriends'] = df['verified_int'] * df['user_friends_count']\n",
        "\n",
        "  df['user_mentions'].fillna(0, inplace=True)\n",
        "  df['mentions_int'] = df['user_mentions'].apply(lambda x: counting(x))\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "df_train_final = add_features(df_train_text)\n",
        "df_test_final = add_features(df_test_text)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ker3Y-y3NWfl",
        "outputId": "1b143a3d-ace6-40a5-d720-dc72927f1aa2"
      },
      "source": [
        "df_test_final.columns"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'id', 'timestamp', 'user_verified',\n",
              "       'user_statuses_count', 'user_followers_count', 'user_friends_count',\n",
              "       'user_mentions', 'urls',\n",
              "       ...\n",
              "       'text_has_word_africa', 'text_has_word_', 'datetime', 'time_day',\n",
              "       'time_month', 'time_hour', 'verified_int', 'vfollowers', 'vfriends',\n",
              "       'mentions_int'],\n",
              "      dtype='object', length=280)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIwzgUvtnap1"
      },
      "source": [
        "### To hide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsk-DAtik4Ms",
        "outputId": "d489fa92-76db-403e-b59b-faaf1dd1e1e4"
      },
      "source": [
        "list(df_train_final.columns)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Unnamed: 0',\n",
              " 'Unnamed: 0.1',\n",
              " 'id',\n",
              " 'timestamp',\n",
              " 'retweet_count',\n",
              " 'user_verified',\n",
              " 'user_statuses_count',\n",
              " 'user_followers_count',\n",
              " 'user_friends_count',\n",
              " 'user_mentions',\n",
              " 'urls',\n",
              " 'hashtags',\n",
              " 'text',\n",
              " 'bert_threshold_1_answer',\n",
              " 'bert_threshold_1_prob',\n",
              " 'fuck',\n",
              " 'shit',\n",
              " 't.co',\n",
              " 'covid',\n",
              " 'coronavirus',\n",
              " 'text_proc',\n",
              " 'text_length',\n",
              " 'text_proc_length',\n",
              " 'text_proc_length_to_text_length',\n",
              " 'text_lines_count',\n",
              " 'text_word_count',\n",
              " 'text_proc_word_count',\n",
              " 'text_proc_word_count_to_text_word_count',\n",
              " 'text_mean_word_length',\n",
              " 'text_proc_mean_word_length',\n",
              " 'text_proc_mean_word_length_to_text_mean_word_length',\n",
              " 'text_proc_alphas_count',\n",
              " 'text_alphas_count',\n",
              " 'text_proc_alphas_count_to_text_alphas_count',\n",
              " 'text_alphas_percent',\n",
              " 'text_non_alphas_count',\n",
              " 'text_digits_count',\n",
              " 'text_emoji_count',\n",
              " 'text_emoji_percent',\n",
              " 'text_has_emoji',\n",
              " 'text_upper_letter_count',\n",
              " 'text_upper_letter_count_to_word_count',\n",
              " 'text_upper_letter_count_to_length',\n",
              " 'text_urls_count',\n",
              " 'text_urls_count_to_words_count',\n",
              " 'text_hashtags_count',\n",
              " 'text_hashtags_count_to_words_count',\n",
              " 'text_usertag_count',\n",
              " 'text_usertags_count_to_words_count',\n",
              " 'text_punctuation_count',\n",
              " 'text_proc_punctuation_count',\n",
              " 'text_punctuation_rate',\n",
              " 'text_punctuation_to_alpha',\n",
              " 'text_proc_punctuation_to_alpha',\n",
              " 'text_punctuation_unique_count',\n",
              " 'text_proc_count_!',\n",
              " 'text_proc_count_?',\n",
              " 'COVID',\n",
              " 'text_has_word_#',\n",
              " 'text_has_word_coronavirus',\n",
              " 'text_has_word_covid',\n",
              " 'text_has_word_covid19',\n",
              " 'text_has_word_i',\n",
              " 'text_has_word_you',\n",
              " 'text_has_word_we',\n",
              " 'text_has_word_all',\n",
              " 'text_has_word_people',\n",
              " 'text_has_word_will',\n",
              " 'text_has_word_our',\n",
              " 'text_has_word_can',\n",
              " 'text_has_word_my',\n",
              " 'text_has_word_your',\n",
              " 'text_has_word_pandemic',\n",
              " 'text_has_word_new',\n",
              " 'text_has_word_trump',\n",
              " 'text_has_word_cases',\n",
              " 'text_has_word_help',\n",
              " 'text_has_word_need',\n",
              " 'text_has_word_health',\n",
              " 'text_has_word_good',\n",
              " 'text_has_word_deaths',\n",
              " 'text_has_word_should',\n",
              " 'text_has_word_please',\n",
              " 'text_has_word_today',\n",
              " 'text_has_word_world',\n",
              " 'text_has_word_virus',\n",
              " 'text_has_word_lockdown',\n",
              " 'text_has_word_work',\n",
              " 'text_has_word_news',\n",
              " 'text_has_word_china',\n",
              " 'text_has_word_government',\n",
              " 'text_has_word_crisis',\n",
              " 'text_has_word_support',\n",
              " 'text_has_word_country',\n",
              " 'text_has_word_im',\n",
              " 'text_has_word_thank',\n",
              " 'text_has_word_death',\n",
              " 'text_has_word_workers',\n",
              " 'text_has_word_2020',\n",
              " 'text_has_word_$',\n",
              " 'text_has_word_against',\n",
              " 'text_has_word_testing',\n",
              " 'text_has_word_response',\n",
              " 'text_has_word_must',\n",
              " 'text_has_word_president',\n",
              " 'text_has_word_never',\n",
              " 'text_has_word_patients',\n",
              " 'text_has_word_positive',\n",
              " 'text_has_word_public',\n",
              " 'text_has_word_social',\n",
              " 'text_has_word_hope',\n",
              " 'text_has_word_life',\n",
              " 'text_has_word_everyone',\n",
              " 'text_has_word_spread',\n",
              " 'text_has_word_fight',\n",
              " 'text_has_word_test',\n",
              " 'text_has_word_love',\n",
              " 'text_has_word_uk',\n",
              " 'text_has_word_safe',\n",
              " 'text_has_word_live',\n",
              " 'text_has_word_free',\n",
              " 'text_has_word_year',\n",
              " 'text_has_word_working',\n",
              " 'text_has_word_states',\n",
              " 'text_has_word_week',\n",
              " 'text_has_word_money',\n",
              " 'text_has_word_dr',\n",
              " 'text_has_word_vaccine',\n",
              " 'text_has_word_fuck',\n",
              " 'text_has_word_better',\n",
              " 'text_has_word_getting',\n",
              " 'text_has_word_shit',\n",
              " 'text_has_word_days',\n",
              " 'text_has_word_thing',\n",
              " 'text_has_word_real',\n",
              " 'text_has_word_america',\n",
              " 'text_has_word_times',\n",
              " 'text_has_word_data',\n",
              " 'text_has_word_lives',\n",
              " 'text_has_word_end',\n",
              " 'text_has_word_tests',\n",
              " 'text_has_word_community',\n",
              " 'text_has_word_best',\n",
              " 'text_has_word_thanks',\n",
              " 'text_has_word_needs',\n",
              " 'text_has_word_important',\n",
              " 'text_has_word_number',\n",
              " 'text_has_word_million',\n",
              " 'text_has_word_global',\n",
              " 'text_has_word_food',\n",
              " 'text_has_word_medical',\n",
              " 'text_has_word_corona',\n",
              " 'text_has_word_americans',\n",
              " 'text_has_word_died',\n",
              " 'text_has_word_outbreak',\n",
              " 'text_has_word_tested',\n",
              " 'text_has_word_family',\n",
              " 'text_has_word_die',\n",
              " 'text_has_word_video',\n",
              " 'text_has_word_yes',\n",
              " 'text_has_word_sure',\n",
              " 'text_has_word_media',\n",
              " 'text_has_word_together',\n",
              " 'text_has_word_weeks',\n",
              " 'text_has_word_economy',\n",
              " 'text_has_word_fucking',\n",
              " 'text_has_word_business',\n",
              " 'text_has_word_job',\n",
              " 'text_has_word_years',\n",
              " 'text_has_word_india',\n",
              " 'text_has_word_iran',\n",
              " 'text_has_word_numbers',\n",
              " 'text_has_word_bad',\n",
              " 'text_has_word_masks',\n",
              " 'text_has_word_check',\n",
              " 'text_has_word_hospital',\n",
              " 'text_has_word_case',\n",
              " 'text_has_word_children',\n",
              " 'text_has_word_risk',\n",
              " 'text_has_word_impact',\n",
              " 'text_has_word_story',\n",
              " 'text_has_word_april',\n",
              " 'text_has_word_latest',\n",
              " 'text_has_word_information',\n",
              " 'text_has_word_countries',\n",
              " 'text_has_word_protect',\n",
              " 'text_has_word_update',\n",
              " 'text_has_word_learn',\n",
              " 'text_has_word_distancing',\n",
              " 'text_has_word_post',\n",
              " 'text_has_word_team',\n",
              " 'text_has_word_city',\n",
              " 'text_has_word_report',\n",
              " 'text_has_word_la',\n",
              " 'text_has_word_old',\n",
              " 'text_has_word_online',\n",
              " 'text_has_word_continue',\n",
              " 'text_has_word_chinese',\n",
              " 'text_has_word_american',\n",
              " 'text_has_word_local',\n",
              " 'text_has_word_white',\n",
              " 'text_has_word_quarantine',\n",
              " 'text_has_word_confirmed',\n",
              " 'text_has_word_economic',\n",
              " 'text_has_word_research',\n",
              " 'text_has_word_person',\n",
              " 'text_has_word_wrong',\n",
              " 'text_has_word_govt',\n",
              " 'text_has_word_national',\n",
              " 'text_has_word_emergency',\n",
              " 'text_has_word_plan',\n",
              " 'text_has_word_place',\n",
              " 'text_has_word_doctors',\n",
              " 'text_has_word_dead',\n",
              " 'text_has_word_20',\n",
              " 'text_has_word_buisenesses',\n",
              " 'text_has_word_human',\n",
              " 'text_has_word_rate',\n",
              " 'text_has_word_truth',\n",
              " 'text_has_word_months',\n",
              " 'text_has_word_activity',\n",
              " 'text_has_word_wuhan',\n",
              " 'text_has_word_feel',\n",
              " 'text_has_word_sick',\n",
              " 'text_has_word_himan',\n",
              " 'text_has_word_breaking',\n",
              " 'text_has_word_disease',\n",
              " 'text_has_word_save',\n",
              " 'text_has_word_governor',\n",
              " 'text_has_word_others',\n",
              " 'text_has_word_hear',\n",
              " 'text_has_word_healthcare',\n",
              " 'text_has_word_famil',\n",
              " 'text_has_word_school',\n",
              " 'text_has_word_bill',\n",
              " 'text_has_word_sad',\n",
              " 'text_has_word_remember',\n",
              " 'text_has_word_stupid',\n",
              " 'text_has_word_nhs',\n",
              " 'text_has_word_women',\n",
              " 'text_has_word_gov',\n",
              " 'text_has_word_reopen',\n",
              " 'text_has_word_south',\n",
              " 'text_has_word_sitiation',\n",
              " 'text_has_word_cure',\n",
              " 'text_has_word_hospitals',\n",
              " 'text_has_word_kids',\n",
              " 'text_has_word_contact',\n",
              " 'text_has_word_damn',\n",
              " 'text_has_word_police',\n",
              " 'text_has_word_worse',\n",
              " 'text_has_word_app',\n",
              " 'text_has_word_resources',\n",
              " 'text_has_word_lab',\n",
              " 'text_has_word_questions',\n",
              " 'text_has_word_question',\n",
              " 'text_has_word_reports',\n",
              " 'text_has_word_york',\n",
              " 'text_has_word_nigeria',\n",
              " 'text_has_word_treatment',\n",
              " 'text_has_word_infected',\n",
              " 'text_has_word_covid9',\n",
              " 'text_has_word_cause',\n",
              " 'text_has_word_vote',\n",
              " 'text_has_word_leaders',\n",
              " 'text_has_word_federal',\n",
              " 'text_has_word_close',\n",
              " 'text_has_word_ass',\n",
              " 'text_has_word_experts',\n",
              " 'text_has_word_fighting',\n",
              " 'text_has_word_africa',\n",
              " 'text_has_word_',\n",
              " 'datetime',\n",
              " 'time_day',\n",
              " 'time_month',\n",
              " 'time_hour',\n",
              " 'verified_int',\n",
              " 'vfollowers',\n",
              " 'vfriends',\n",
              " 'mentions_int']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGDxLMxznZVi"
      },
      "source": [
        "features_numerical = [                           'timestamp',\n",
        "                                       'user_statuses_count',\n",
        "                                      'user_followers_count',\n",
        "                                        'user_friends_count',\n",
        "                                     'bert_threshold_1_prob',\n",
        "                                               'text_length',\n",
        "                                          'text_proc_length',\n",
        "                           'text_proc_length_to_text_length',\n",
        "                                          'text_lines_count',\n",
        "                                           'text_word_count',\n",
        "                                      'text_proc_word_count',\n",
        "                   'text_proc_word_count_to_text_word_count',\n",
        "                                     'text_mean_word_length',\n",
        "                                'text_proc_mean_word_length',\n",
        "       'text_proc_mean_word_length_to_text_mean_word_length',\n",
        "                                    'text_proc_alphas_count',\n",
        "                                         'text_alphas_count',\n",
        "               'text_proc_alphas_count_to_text_alphas_count',\n",
        "                                       'text_alphas_percent',\n",
        "                                     'text_non_alphas_count',\n",
        "                                         'text_digits_count',\n",
        "                                          'text_emoji_count',\n",
        "                                        'text_emoji_percent',\n",
        "                                            'text_has_emoji',\n",
        "                                   'text_upper_letter_count',\n",
        "                     'text_upper_letter_count_to_word_count',\n",
        "                         'text_upper_letter_count_to_length',\n",
        "                                           'text_urls_count',\n",
        "                            'text_urls_count_to_words_count',\n",
        "                                       'text_hashtags_count',\n",
        "                        'text_hashtags_count_to_words_count',\n",
        "                                        'text_usertag_count',\n",
        "                        'text_usertags_count_to_words_count',\n",
        "                                    'text_punctuation_count',\n",
        "                               'text_proc_punctuation_count',\n",
        "                                     'text_punctuation_rate',\n",
        "                                 'text_punctuation_to_alpha',\n",
        "                            'text_proc_punctuation_to_alpha',\n",
        "                             'text_punctuation_unique_count',\n",
        "                                         'text_proc_count_!',\n",
        "                                         'text_proc_count_?',\n",
        "                                              'verified_int',\n",
        "                                                'vfollowers',\n",
        "                                                  'vfriends',\n",
        "                                              'mentions_int',\n",
        "                       'text_has_word_#',\n",
        " 'text_has_word_coronavirus',\n",
        " 'text_has_word_covid',\n",
        " 'text_has_word_covid19',\n",
        " 'text_has_word_i',\n",
        " 'text_has_word_you',\n",
        " 'text_has_word_we',\n",
        " 'text_has_word_all',\n",
        " 'text_has_word_people',\n",
        " 'text_has_word_will',\n",
        " 'text_has_word_our',\n",
        " 'text_has_word_can',\n",
        " 'text_has_word_my',\n",
        " 'text_has_word_your',\n",
        " 'text_has_word_pandemic',\n",
        " 'text_has_word_new',\n",
        " 'text_has_word_trump',\n",
        " 'text_has_word_cases',\n",
        " 'text_has_word_help',\n",
        " 'text_has_word_need',\n",
        " 'text_has_word_health',\n",
        " 'text_has_word_good',\n",
        " 'text_has_word_deaths',\n",
        " 'text_has_word_should',\n",
        " 'text_has_word_please',\n",
        " 'text_has_word_today',\n",
        " 'text_has_word_world',\n",
        " 'text_has_word_virus',\n",
        " 'text_has_word_lockdown',\n",
        " 'text_has_word_work',\n",
        " 'text_has_word_news',\n",
        " 'text_has_word_china',\n",
        " 'text_has_word_government',\n",
        " 'text_has_word_crisis',\n",
        " 'text_has_word_support',\n",
        " 'text_has_word_country',\n",
        " 'text_has_word_im',\n",
        " 'text_has_word_thank',\n",
        " 'text_has_word_death',\n",
        " 'text_has_word_workers',\n",
        " 'text_has_word_2020',\n",
        " 'text_has_word_$',\n",
        " 'text_has_word_against',\n",
        " 'text_has_word_testing',\n",
        " 'text_has_word_response',\n",
        " 'text_has_word_must',\n",
        " 'text_has_word_president',\n",
        " 'text_has_word_never',\n",
        " 'text_has_word_patients',\n",
        " 'text_has_word_positive',\n",
        " 'text_has_word_public',\n",
        " 'text_has_word_social',\n",
        " 'text_has_word_hope',\n",
        " 'text_has_word_life',\n",
        " 'text_has_word_everyone',\n",
        " 'text_has_word_spread',\n",
        " 'text_has_word_fight',\n",
        " 'text_has_word_test',\n",
        " 'text_has_word_love',\n",
        " 'text_has_word_uk',\n",
        " 'text_has_word_safe',\n",
        " 'text_has_word_live',\n",
        " 'text_has_word_free',\n",
        " 'text_has_word_year',\n",
        " 'text_has_word_working',\n",
        " 'text_has_word_states',\n",
        " 'text_has_word_week',\n",
        " 'text_has_word_money',\n",
        " 'text_has_word_dr',\n",
        " 'text_has_word_vaccine',\n",
        " 'text_has_word_fuck',\n",
        " 'text_has_word_better',\n",
        " 'text_has_word_getting',\n",
        " 'text_has_word_shit',\n",
        " 'text_has_word_days',\n",
        " 'text_has_word_thing',\n",
        " 'text_has_word_real',\n",
        " 'text_has_word_america',\n",
        " 'text_has_word_times',\n",
        " 'text_has_word_data',\n",
        " 'text_has_word_lives',\n",
        " 'text_has_word_end',\n",
        " 'text_has_word_tests',\n",
        " 'text_has_word_community',\n",
        " 'text_has_word_best',\n",
        " 'text_has_word_thanks',\n",
        " 'text_has_word_needs',\n",
        " 'text_has_word_important',\n",
        " 'text_has_word_number',\n",
        " 'text_has_word_million',\n",
        " 'text_has_word_global',\n",
        " 'text_has_word_food',\n",
        " 'text_has_word_medical',\n",
        " 'text_has_word_corona',\n",
        " 'text_has_word_americans',\n",
        " 'text_has_word_died',\n",
        " 'text_has_word_outbreak',\n",
        " 'text_has_word_tested',\n",
        " 'text_has_word_family',\n",
        " 'text_has_word_die',\n",
        " 'text_has_word_video',\n",
        " 'text_has_word_yes',\n",
        " 'text_has_word_sure',\n",
        " 'text_has_word_media',\n",
        " 'text_has_word_together',\n",
        " 'text_has_word_weeks',\n",
        " 'text_has_word_economy',\n",
        " 'text_has_word_fucking',\n",
        " 'text_has_word_business',\n",
        " 'text_has_word_job',\n",
        " 'text_has_word_years',\n",
        " 'text_has_word_india',\n",
        " 'text_has_word_iran',\n",
        " 'text_has_word_numbers',\n",
        " 'text_has_word_bad',\n",
        " 'text_has_word_masks',\n",
        " 'text_has_word_check',\n",
        " 'text_has_word_hospital',\n",
        " 'text_has_word_case',\n",
        " 'text_has_word_children',\n",
        " 'text_has_word_risk',\n",
        " 'text_has_word_impact',\n",
        " 'text_has_word_story',\n",
        " 'text_has_word_april',\n",
        " 'text_has_word_latest',\n",
        " 'text_has_word_information',\n",
        " 'text_has_word_countries',\n",
        " 'text_has_word_protect',\n",
        " 'text_has_word_update',\n",
        " 'text_has_word_learn',\n",
        " 'text_has_word_distancing',\n",
        " 'text_has_word_post',\n",
        " 'text_has_word_team',\n",
        " 'text_has_word_city',\n",
        " 'text_has_word_report',\n",
        " 'text_has_word_la',\n",
        " 'text_has_word_old',\n",
        " 'text_has_word_online',\n",
        " 'text_has_word_continue',\n",
        " 'text_has_word_chinese',\n",
        " 'text_has_word_american',\n",
        " 'text_has_word_local',\n",
        " 'text_has_word_white',\n",
        " 'text_has_word_quarantine',\n",
        " 'text_has_word_confirmed',\n",
        " 'text_has_word_economic',\n",
        " 'text_has_word_research',\n",
        " 'text_has_word_person',\n",
        " 'text_has_word_wrong',\n",
        " 'text_has_word_govt',\n",
        " 'text_has_word_national',\n",
        " 'text_has_word_emergency',\n",
        " 'text_has_word_plan',\n",
        " 'text_has_word_place',\n",
        " 'text_has_word_doctors',\n",
        " 'text_has_word_dead',\n",
        " 'text_has_word_20',\n",
        " 'text_has_word_buisenesses',\n",
        " 'text_has_word_human',\n",
        " 'text_has_word_rate',\n",
        " 'text_has_word_truth',\n",
        " 'text_has_word_months',\n",
        " 'text_has_word_activity',\n",
        " 'text_has_word_wuhan',\n",
        " 'text_has_word_feel',\n",
        " 'text_has_word_sick',\n",
        " 'text_has_word_himan',\n",
        " 'text_has_word_breaking',\n",
        " 'text_has_word_disease',\n",
        " 'text_has_word_save',\n",
        " 'text_has_word_governor',\n",
        " 'text_has_word_others',\n",
        " 'text_has_word_hear',\n",
        " 'text_has_word_healthcare',\n",
        " 'text_has_word_famil',\n",
        " 'text_has_word_school',\n",
        " 'text_has_word_bill',\n",
        " 'text_has_word_sad',\n",
        " 'text_has_word_remember',\n",
        " 'text_has_word_stupid',\n",
        " 'text_has_word_nhs',\n",
        " 'text_has_word_women',\n",
        " 'text_has_word_gov',\n",
        " 'text_has_word_reopen',\n",
        " 'text_has_word_south',\n",
        " 'text_has_word_sitiation',\n",
        " 'text_has_word_cure',\n",
        " 'text_has_word_hospitals',\n",
        " 'text_has_word_kids',\n",
        " 'text_has_word_contact',\n",
        " 'text_has_word_damn',\n",
        " 'text_has_word_police',\n",
        " 'text_has_word_worse',\n",
        " 'text_has_word_app',\n",
        " 'text_has_word_resources',\n",
        " 'text_has_word_lab',\n",
        " 'text_has_word_questions',\n",
        " 'text_has_word_question',\n",
        " 'text_has_word_reports',\n",
        " 'text_has_word_york',\n",
        " 'text_has_word_nigeria',\n",
        " 'text_has_word_treatment',\n",
        " 'text_has_word_infected',\n",
        " 'text_has_word_covid9',\n",
        " 'text_has_word_cause',\n",
        " 'text_has_word_vote',\n",
        " 'text_has_word_leaders',\n",
        " 'text_has_word_federal',\n",
        " 'text_has_word_close',\n",
        " 'text_has_word_ass',\n",
        " 'text_has_word_experts',\n",
        " 'text_has_word_fighting',\n",
        " 'text_has_word_africa',\n",
        " 'text_has_word_',\n",
        "                      ]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fj7H1bQpszu"
      },
      "source": [
        "features_category = ['fuck', 'shit', 't.co', 'COVID', 'time_day',\n",
        " 'time_month',\n",
        " 'time_hour',]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYM_hniURdhS"
      },
      "source": [
        "### Make data to put into test model + Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XOLUBFTrR9m",
        "outputId": "09a1d95a-4f18-414e-ffff-8ca1152fcdab"
      },
      "source": [
        "features_numerical + features_category"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['timestamp',\n",
              " 'user_statuses_count',\n",
              " 'user_followers_count',\n",
              " 'user_friends_count',\n",
              " 'bert_threshold_1_prob',\n",
              " 'text_length',\n",
              " 'text_proc_length',\n",
              " 'text_proc_length_to_text_length',\n",
              " 'text_lines_count',\n",
              " 'text_word_count',\n",
              " 'text_proc_word_count',\n",
              " 'text_proc_word_count_to_text_word_count',\n",
              " 'text_mean_word_length',\n",
              " 'text_proc_mean_word_length',\n",
              " 'text_proc_mean_word_length_to_text_mean_word_length',\n",
              " 'text_proc_alphas_count',\n",
              " 'text_alphas_count',\n",
              " 'text_proc_alphas_count_to_text_alphas_count',\n",
              " 'text_alphas_percent',\n",
              " 'text_non_alphas_count',\n",
              " 'text_digits_count',\n",
              " 'text_emoji_count',\n",
              " 'text_emoji_percent',\n",
              " 'text_has_emoji',\n",
              " 'text_upper_letter_count',\n",
              " 'text_upper_letter_count_to_word_count',\n",
              " 'text_upper_letter_count_to_length',\n",
              " 'text_urls_count',\n",
              " 'text_urls_count_to_words_count',\n",
              " 'text_hashtags_count',\n",
              " 'text_hashtags_count_to_words_count',\n",
              " 'text_usertag_count',\n",
              " 'text_usertags_count_to_words_count',\n",
              " 'text_punctuation_count',\n",
              " 'text_proc_punctuation_count',\n",
              " 'text_punctuation_rate',\n",
              " 'text_punctuation_to_alpha',\n",
              " 'text_proc_punctuation_to_alpha',\n",
              " 'text_punctuation_unique_count',\n",
              " 'text_proc_count_!',\n",
              " 'text_proc_count_?',\n",
              " 'verified_int',\n",
              " 'vfollowers',\n",
              " 'vfriends',\n",
              " 'mentions_int',\n",
              " 'text_has_word_#',\n",
              " 'text_has_word_coronavirus',\n",
              " 'text_has_word_covid',\n",
              " 'text_has_word_covid19',\n",
              " 'text_has_word_i',\n",
              " 'text_has_word_you',\n",
              " 'text_has_word_we',\n",
              " 'text_has_word_all',\n",
              " 'text_has_word_people',\n",
              " 'text_has_word_will',\n",
              " 'text_has_word_our',\n",
              " 'text_has_word_can',\n",
              " 'text_has_word_my',\n",
              " 'text_has_word_your',\n",
              " 'text_has_word_pandemic',\n",
              " 'text_has_word_new',\n",
              " 'text_has_word_trump',\n",
              " 'text_has_word_cases',\n",
              " 'text_has_word_help',\n",
              " 'text_has_word_need',\n",
              " 'text_has_word_health',\n",
              " 'text_has_word_good',\n",
              " 'text_has_word_deaths',\n",
              " 'text_has_word_should',\n",
              " 'text_has_word_please',\n",
              " 'text_has_word_today',\n",
              " 'text_has_word_world',\n",
              " 'text_has_word_virus',\n",
              " 'text_has_word_lockdown',\n",
              " 'text_has_word_work',\n",
              " 'text_has_word_news',\n",
              " 'text_has_word_china',\n",
              " 'text_has_word_government',\n",
              " 'text_has_word_crisis',\n",
              " 'text_has_word_support',\n",
              " 'text_has_word_country',\n",
              " 'text_has_word_im',\n",
              " 'text_has_word_thank',\n",
              " 'text_has_word_death',\n",
              " 'text_has_word_workers',\n",
              " 'text_has_word_2020',\n",
              " 'text_has_word_$',\n",
              " 'text_has_word_against',\n",
              " 'text_has_word_testing',\n",
              " 'text_has_word_response',\n",
              " 'text_has_word_must',\n",
              " 'text_has_word_president',\n",
              " 'text_has_word_never',\n",
              " 'text_has_word_patients',\n",
              " 'text_has_word_positive',\n",
              " 'text_has_word_public',\n",
              " 'text_has_word_social',\n",
              " 'text_has_word_hope',\n",
              " 'text_has_word_life',\n",
              " 'text_has_word_everyone',\n",
              " 'text_has_word_spread',\n",
              " 'text_has_word_fight',\n",
              " 'text_has_word_test',\n",
              " 'text_has_word_love',\n",
              " 'text_has_word_uk',\n",
              " 'text_has_word_safe',\n",
              " 'text_has_word_live',\n",
              " 'text_has_word_free',\n",
              " 'text_has_word_year',\n",
              " 'text_has_word_working',\n",
              " 'text_has_word_states',\n",
              " 'text_has_word_week',\n",
              " 'text_has_word_money',\n",
              " 'text_has_word_dr',\n",
              " 'text_has_word_vaccine',\n",
              " 'text_has_word_fuck',\n",
              " 'text_has_word_better',\n",
              " 'text_has_word_getting',\n",
              " 'text_has_word_shit',\n",
              " 'text_has_word_days',\n",
              " 'text_has_word_thing',\n",
              " 'text_has_word_real',\n",
              " 'text_has_word_america',\n",
              " 'text_has_word_times',\n",
              " 'text_has_word_data',\n",
              " 'text_has_word_lives',\n",
              " 'text_has_word_end',\n",
              " 'text_has_word_tests',\n",
              " 'text_has_word_community',\n",
              " 'text_has_word_best',\n",
              " 'text_has_word_thanks',\n",
              " 'text_has_word_needs',\n",
              " 'text_has_word_important',\n",
              " 'text_has_word_number',\n",
              " 'text_has_word_million',\n",
              " 'text_has_word_global',\n",
              " 'text_has_word_food',\n",
              " 'text_has_word_medical',\n",
              " 'text_has_word_corona',\n",
              " 'text_has_word_americans',\n",
              " 'text_has_word_died',\n",
              " 'text_has_word_outbreak',\n",
              " 'text_has_word_tested',\n",
              " 'text_has_word_family',\n",
              " 'text_has_word_die',\n",
              " 'text_has_word_video',\n",
              " 'text_has_word_yes',\n",
              " 'text_has_word_sure',\n",
              " 'text_has_word_media',\n",
              " 'text_has_word_together',\n",
              " 'text_has_word_weeks',\n",
              " 'text_has_word_economy',\n",
              " 'text_has_word_fucking',\n",
              " 'text_has_word_business',\n",
              " 'text_has_word_job',\n",
              " 'text_has_word_years',\n",
              " 'text_has_word_india',\n",
              " 'text_has_word_iran',\n",
              " 'text_has_word_numbers',\n",
              " 'text_has_word_bad',\n",
              " 'text_has_word_masks',\n",
              " 'text_has_word_check',\n",
              " 'text_has_word_hospital',\n",
              " 'text_has_word_case',\n",
              " 'text_has_word_children',\n",
              " 'text_has_word_risk',\n",
              " 'text_has_word_impact',\n",
              " 'text_has_word_story',\n",
              " 'text_has_word_april',\n",
              " 'text_has_word_latest',\n",
              " 'text_has_word_information',\n",
              " 'text_has_word_countries',\n",
              " 'text_has_word_protect',\n",
              " 'text_has_word_update',\n",
              " 'text_has_word_learn',\n",
              " 'text_has_word_distancing',\n",
              " 'text_has_word_post',\n",
              " 'text_has_word_team',\n",
              " 'text_has_word_city',\n",
              " 'text_has_word_report',\n",
              " 'text_has_word_la',\n",
              " 'text_has_word_old',\n",
              " 'text_has_word_online',\n",
              " 'text_has_word_continue',\n",
              " 'text_has_word_chinese',\n",
              " 'text_has_word_american',\n",
              " 'text_has_word_local',\n",
              " 'text_has_word_white',\n",
              " 'text_has_word_quarantine',\n",
              " 'text_has_word_confirmed',\n",
              " 'text_has_word_economic',\n",
              " 'text_has_word_research',\n",
              " 'text_has_word_person',\n",
              " 'text_has_word_wrong',\n",
              " 'text_has_word_govt',\n",
              " 'text_has_word_national',\n",
              " 'text_has_word_emergency',\n",
              " 'text_has_word_plan',\n",
              " 'text_has_word_place',\n",
              " 'text_has_word_doctors',\n",
              " 'text_has_word_dead',\n",
              " 'text_has_word_20',\n",
              " 'text_has_word_buisenesses',\n",
              " 'text_has_word_human',\n",
              " 'text_has_word_rate',\n",
              " 'text_has_word_truth',\n",
              " 'text_has_word_months',\n",
              " 'text_has_word_activity',\n",
              " 'text_has_word_wuhan',\n",
              " 'text_has_word_feel',\n",
              " 'text_has_word_sick',\n",
              " 'text_has_word_himan',\n",
              " 'text_has_word_breaking',\n",
              " 'text_has_word_disease',\n",
              " 'text_has_word_save',\n",
              " 'text_has_word_governor',\n",
              " 'text_has_word_others',\n",
              " 'text_has_word_hear',\n",
              " 'text_has_word_healthcare',\n",
              " 'text_has_word_famil',\n",
              " 'text_has_word_school',\n",
              " 'text_has_word_bill',\n",
              " 'text_has_word_sad',\n",
              " 'text_has_word_remember',\n",
              " 'text_has_word_stupid',\n",
              " 'text_has_word_nhs',\n",
              " 'text_has_word_women',\n",
              " 'text_has_word_gov',\n",
              " 'text_has_word_reopen',\n",
              " 'text_has_word_south',\n",
              " 'text_has_word_sitiation',\n",
              " 'text_has_word_cure',\n",
              " 'text_has_word_hospitals',\n",
              " 'text_has_word_kids',\n",
              " 'text_has_word_contact',\n",
              " 'text_has_word_damn',\n",
              " 'text_has_word_police',\n",
              " 'text_has_word_worse',\n",
              " 'text_has_word_app',\n",
              " 'text_has_word_resources',\n",
              " 'text_has_word_lab',\n",
              " 'text_has_word_questions',\n",
              " 'text_has_word_question',\n",
              " 'text_has_word_reports',\n",
              " 'text_has_word_york',\n",
              " 'text_has_word_nigeria',\n",
              " 'text_has_word_treatment',\n",
              " 'text_has_word_infected',\n",
              " 'text_has_word_covid9',\n",
              " 'text_has_word_cause',\n",
              " 'text_has_word_vote',\n",
              " 'text_has_word_leaders',\n",
              " 'text_has_word_federal',\n",
              " 'text_has_word_close',\n",
              " 'text_has_word_ass',\n",
              " 'text_has_word_experts',\n",
              " 'text_has_word_fighting',\n",
              " 'text_has_word_africa',\n",
              " 'text_has_word_',\n",
              " 'fuck',\n",
              " 'shit',\n",
              " 't.co',\n",
              " 'COVID',\n",
              " 'time_day',\n",
              " 'time_month',\n",
              " 'time_hour']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "Si1lBknQqzJK",
        "outputId": "41707efb-3cb3-4182-c1f8-a87625a56a7e"
      },
      "source": [
        "df_test_final[features_numerical + features_category]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>bert_threshold_1_prob</th>\n",
              "      <th>text_length</th>\n",
              "      <th>text_proc_length</th>\n",
              "      <th>text_proc_length_to_text_length</th>\n",
              "      <th>text_lines_count</th>\n",
              "      <th>text_word_count</th>\n",
              "      <th>text_proc_word_count</th>\n",
              "      <th>text_proc_word_count_to_text_word_count</th>\n",
              "      <th>text_mean_word_length</th>\n",
              "      <th>text_proc_mean_word_length</th>\n",
              "      <th>text_proc_mean_word_length_to_text_mean_word_length</th>\n",
              "      <th>text_proc_alphas_count</th>\n",
              "      <th>text_alphas_count</th>\n",
              "      <th>text_proc_alphas_count_to_text_alphas_count</th>\n",
              "      <th>text_alphas_percent</th>\n",
              "      <th>text_non_alphas_count</th>\n",
              "      <th>text_digits_count</th>\n",
              "      <th>text_emoji_count</th>\n",
              "      <th>text_emoji_percent</th>\n",
              "      <th>text_has_emoji</th>\n",
              "      <th>text_upper_letter_count</th>\n",
              "      <th>text_upper_letter_count_to_word_count</th>\n",
              "      <th>text_upper_letter_count_to_length</th>\n",
              "      <th>text_urls_count</th>\n",
              "      <th>text_urls_count_to_words_count</th>\n",
              "      <th>text_hashtags_count</th>\n",
              "      <th>text_hashtags_count_to_words_count</th>\n",
              "      <th>text_usertag_count</th>\n",
              "      <th>text_usertags_count_to_words_count</th>\n",
              "      <th>text_punctuation_count</th>\n",
              "      <th>text_proc_punctuation_count</th>\n",
              "      <th>text_punctuation_rate</th>\n",
              "      <th>text_punctuation_to_alpha</th>\n",
              "      <th>text_proc_punctuation_to_alpha</th>\n",
              "      <th>text_punctuation_unique_count</th>\n",
              "      <th>text_proc_count_!</th>\n",
              "      <th>...</th>\n",
              "      <th>text_has_word_women</th>\n",
              "      <th>text_has_word_gov</th>\n",
              "      <th>text_has_word_reopen</th>\n",
              "      <th>text_has_word_south</th>\n",
              "      <th>text_has_word_sitiation</th>\n",
              "      <th>text_has_word_cure</th>\n",
              "      <th>text_has_word_hospitals</th>\n",
              "      <th>text_has_word_kids</th>\n",
              "      <th>text_has_word_contact</th>\n",
              "      <th>text_has_word_damn</th>\n",
              "      <th>text_has_word_police</th>\n",
              "      <th>text_has_word_worse</th>\n",
              "      <th>text_has_word_app</th>\n",
              "      <th>text_has_word_resources</th>\n",
              "      <th>text_has_word_lab</th>\n",
              "      <th>text_has_word_questions</th>\n",
              "      <th>text_has_word_question</th>\n",
              "      <th>text_has_word_reports</th>\n",
              "      <th>text_has_word_york</th>\n",
              "      <th>text_has_word_nigeria</th>\n",
              "      <th>text_has_word_treatment</th>\n",
              "      <th>text_has_word_infected</th>\n",
              "      <th>text_has_word_covid9</th>\n",
              "      <th>text_has_word_cause</th>\n",
              "      <th>text_has_word_vote</th>\n",
              "      <th>text_has_word_leaders</th>\n",
              "      <th>text_has_word_federal</th>\n",
              "      <th>text_has_word_close</th>\n",
              "      <th>text_has_word_ass</th>\n",
              "      <th>text_has_word_experts</th>\n",
              "      <th>text_has_word_fighting</th>\n",
              "      <th>text_has_word_africa</th>\n",
              "      <th>text_has_word_</th>\n",
              "      <th>fuck</th>\n",
              "      <th>shit</th>\n",
              "      <th>t.co</th>\n",
              "      <th>COVID</th>\n",
              "      <th>time_day</th>\n",
              "      <th>time_month</th>\n",
              "      <th>time_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.588644e+12</td>\n",
              "      <td>229.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.023905</td>\n",
              "      <td>93</td>\n",
              "      <td>95</td>\n",
              "      <td>1.021505</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>1.187500</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>4.052632</td>\n",
              "      <td>0.831309</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010753</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.043011</td>\n",
              "      <td>0.057971</td>\n",
              "      <td>0.057971</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.588464e+12</td>\n",
              "      <td>106991.0</td>\n",
              "      <td>41273.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>0.017365</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>1.052632</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.588564e+12</td>\n",
              "      <td>24127.0</td>\n",
              "      <td>345.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.012459</td>\n",
              "      <td>124</td>\n",
              "      <td>119</td>\n",
              "      <td>0.959677</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.681818</td>\n",
              "      <td>4.454545</td>\n",
              "      <td>0.951456</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.774194</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.588639e+12</td>\n",
              "      <td>771.0</td>\n",
              "      <td>6555.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.996568</td>\n",
              "      <td>297</td>\n",
              "      <td>255</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>49</td>\n",
              "      <td>1.113636</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>4.224490</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>197</td>\n",
              "      <td>228</td>\n",
              "      <td>0.864035</td>\n",
              "      <td>0.767677</td>\n",
              "      <td>69</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.043771</td>\n",
              "      <td>2</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>0.053872</td>\n",
              "      <td>0.070175</td>\n",
              "      <td>0.030457</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.588693e+12</td>\n",
              "      <td>32595.0</td>\n",
              "      <td>6490.0</td>\n",
              "      <td>1206.0</td>\n",
              "      <td>0.010962</td>\n",
              "      <td>69</td>\n",
              "      <td>46</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>36</td>\n",
              "      <td>52</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.753623</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>1</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285329</th>\n",
              "      <td>1.588674e+12</td>\n",
              "      <td>10532.0</td>\n",
              "      <td>6506208.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.996574</td>\n",
              "      <td>182</td>\n",
              "      <td>175</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>31</td>\n",
              "      <td>1.347826</td>\n",
              "      <td>6.652174</td>\n",
              "      <td>4.193548</td>\n",
              "      <td>0.630403</td>\n",
              "      <td>120</td>\n",
              "      <td>137</td>\n",
              "      <td>0.875912</td>\n",
              "      <td>0.752747</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>1.130435</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>5</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.094891</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285330</th>\n",
              "      <td>1.588296e+12</td>\n",
              "      <td>151.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.996578</td>\n",
              "      <td>243</td>\n",
              "      <td>234</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>47</td>\n",
              "      <td>1.566667</td>\n",
              "      <td>7.033333</td>\n",
              "      <td>3.914894</td>\n",
              "      <td>0.556620</td>\n",
              "      <td>159</td>\n",
              "      <td>177</td>\n",
              "      <td>0.898305</td>\n",
              "      <td>0.728395</td>\n",
              "      <td>66</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.123457</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>4</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>0.078189</td>\n",
              "      <td>0.107345</td>\n",
              "      <td>0.088050</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285331</th>\n",
              "      <td>1.588550e+12</td>\n",
              "      <td>381.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>0.010936</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>1.157895</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285332</th>\n",
              "      <td>1.588656e+12</td>\n",
              "      <td>33982.0</td>\n",
              "      <td>974249.0</td>\n",
              "      <td>340.0</td>\n",
              "      <td>0.023877</td>\n",
              "      <td>107</td>\n",
              "      <td>108</td>\n",
              "      <td>1.009346</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>1.047619</td>\n",
              "      <td>4.142857</td>\n",
              "      <td>3.954545</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.803738</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.018692</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.009346</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285333</th>\n",
              "      <td>1.588578e+12</td>\n",
              "      <td>87981.0</td>\n",
              "      <td>1106541.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>0.011081</td>\n",
              "      <td>39</td>\n",
              "      <td>15</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>12.333333</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>14</td>\n",
              "      <td>31</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.128205</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>285334 rows × 266 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           timestamp  user_statuses_count  ...  time_month  time_hour\n",
              "0       1.588644e+12  229.0                ...  5           2        \n",
              "1       1.588464e+12  106991.0             ...  5           23       \n",
              "2       1.588564e+12  24127.0              ...  5           3        \n",
              "3       1.588639e+12  771.0                ...  5           0        \n",
              "4       1.588693e+12  32595.0              ...  5           15       \n",
              "...              ...      ...              ... ..           ..       \n",
              "285329  1.588674e+12  10532.0              ...  5           10       \n",
              "285330  1.588296e+12  151.0                ...  5           1        \n",
              "285331  1.588550e+12  381.0                ...  5           23       \n",
              "285332  1.588656e+12  33982.0              ...  5           5        \n",
              "285333  1.588578e+12  87981.0              ...  5           7        \n",
              "\n",
              "[285334 rows x 266 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKlDbuj3lwiZ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joJXyEtEvECN"
      },
      "source": [
        "df_train_NaN_final = df_train_final.fillna(0)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK_aBuAIO7x3"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w7ocoLgRiWz"
      },
      "source": [
        "# numeric_features = features_numerical\n",
        "# numeric_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='median')),\n",
        "#     ('scaler', StandardScaler())])\n",
        "\n",
        "# categorical_features = features_category\n",
        "# categorical_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numeric_transformer, numeric_features),\n",
        "#         ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# # Append classifier to preprocessing pipeline.\n",
        "# # Now we have a full prediction pipeline.\n",
        "# clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "#                       ('classifier', LogisticRegression(max_iter=250))])\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df_train_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan), df_train_NaN_final['retweet_count'].astype(int), test_size=0.2)\n",
        "# # print(y_train)\n",
        "# clf.fit(X_train[:70000], y_train[:70000])\n",
        "# # print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWEIzsVP1Ai3"
      },
      "source": [
        "# y_pred = clf.predict(X_test)\n",
        "# print(\"MAE score: %.3f\" % MAE(y_test, y_pred))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC0xmSipJqV8"
      },
      "source": [
        "# y_pred = clf.predict(X_train[70000:])\n",
        "# print(\"MAE score: %.3f\" % MAE(y_train[70000:], y_pred))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30adpoHQ4hIa"
      },
      "source": [
        "# y_pred_test = clf.predict(df_test_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umezaHkPRi6r"
      },
      "source": [
        "### RandomForrest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiGPdDO2Rkmo"
      },
      "source": [
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# random_forest = RandomForestRegressor(random_state=52, n_jobs = -1, criterion= 'entropy', max_features='auto')\n",
        "\n",
        "# #search for the intrravek of parametera\n",
        "# all_params = grid = np.arange(40, 110, 10)\n",
        "# #GridSearchCV for cv = 4\n",
        "# grid = {'n_estimators' : all_params}\n",
        "# grid_search = GridSearchCV(random_forest, grid, scoring = 'mae', cv = 40)\n",
        "# grid_search.fit(np.array(train), np.array(ytrain).ravel())\n",
        "\n",
        "# print(\"Best parameter is:{} \\n \".format(grid_search.best_params_))"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNGr7nc1z9Yn"
      },
      "source": [
        "# numeric_features = features_numerical\n",
        "# numeric_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='median')),\n",
        "#     ('scaler', StandardScaler())])\n",
        "\n",
        "# categorical_features = features_category\n",
        "# categorical_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numeric_transformer, numeric_features),\n",
        "#         ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# # Append classifier to preprocessing pipeline.\n",
        "# # Now we have a full prediction pipeline.\n",
        "# clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "#                       ('classifier', RandomForestRegressor())]\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df_train_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan), df_train_NaN_final['retweet_count'].astype(int), test_size=0.2)\n",
        "# # print(y_train)\n",
        "# clf.fit(X_train, y_train)\n",
        "# print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeCAKE5gz9bm"
      },
      "source": [
        "# y_pred = clf.predict(X_test)\n",
        "# print(\"MAE score: %.3f\" % MAE(y_test, y_pred))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYJrSKLuC8Ce"
      },
      "source": [
        "### CatBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke8DJw5ZHR-u",
        "outputId": "70d17bbf-7009-4d76-921a-c4cf865766be"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVcSH2kXC_Xx"
      },
      "source": [
        "import catboost\n",
        "from catboost import CatBoostRegressor, Pool"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jKjnhCtsCs4"
      },
      "source": [
        "### CatBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZTUicYfEh3e",
        "outputId": "cf6cf977-65ed-4ad7-a1b9-9047a24fc978"
      },
      "source": [
        "numeric_features = features_numerical\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = features_category\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        # ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf1 = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', CatBoostRegressor(iterations=1000, depth=7, loss_function ='MAE', eval_metric = 'MAE', random_seed=57, learning_rate=0.1, l2_leaf_reg=6))])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train_final[features_numerical].replace([np.inf, -np.inf], np.nan), df_train_NaN_final['retweet_count'].astype(int), test_size=0.2)\n",
        "# print(y_train)\n",
        "clf1.fit(X_train[:350000], y_train[:350000])\n",
        "# print(\"model score: %.3f\" % clf1.score(X_test, y_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 147.3433870\ttotal: 382ms\tremaining: 6m 21s\n",
            "1:\tlearn: 146.9163923\ttotal: 672ms\tremaining: 5m 35s\n",
            "2:\tlearn: 146.7177261\ttotal: 940ms\tremaining: 5m 12s\n",
            "3:\tlearn: 146.4811010\ttotal: 1.21s\tremaining: 5m\n",
            "4:\tlearn: 146.2567377\ttotal: 1.49s\tremaining: 4m 56s\n",
            "5:\tlearn: 145.9595738\ttotal: 1.74s\tremaining: 4m 47s\n",
            "6:\tlearn: 145.8997260\ttotal: 2s\tremaining: 4m 43s\n",
            "7:\tlearn: 145.6508018\ttotal: 2.27s\tremaining: 4m 41s\n",
            "8:\tlearn: 145.6076132\ttotal: 2.54s\tremaining: 4m 39s\n",
            "9:\tlearn: 145.3366754\ttotal: 2.79s\tremaining: 4m 36s\n",
            "10:\tlearn: 145.1432610\ttotal: 3.06s\tremaining: 4m 34s\n",
            "11:\tlearn: 144.9662792\ttotal: 3.33s\tremaining: 4m 34s\n",
            "12:\tlearn: 144.8059611\ttotal: 3.61s\tremaining: 4m 33s\n",
            "13:\tlearn: 144.7912048\ttotal: 3.87s\tremaining: 4m 32s\n",
            "14:\tlearn: 144.7241735\ttotal: 4.11s\tremaining: 4m 29s\n",
            "15:\tlearn: 144.6248504\ttotal: 4.35s\tremaining: 4m 27s\n",
            "16:\tlearn: 144.5041745\ttotal: 4.6s\tremaining: 4m 25s\n",
            "17:\tlearn: 144.3345014\ttotal: 4.83s\tremaining: 4m 23s\n",
            "18:\tlearn: 144.3288804\ttotal: 5.08s\tremaining: 4m 22s\n",
            "19:\tlearn: 144.3083538\ttotal: 5.33s\tremaining: 4m 21s\n",
            "20:\tlearn: 144.1027597\ttotal: 5.57s\tremaining: 4m 19s\n",
            "21:\tlearn: 144.0234072\ttotal: 5.82s\tremaining: 4m 18s\n",
            "22:\tlearn: 143.9052847\ttotal: 6.06s\tremaining: 4m 17s\n",
            "23:\tlearn: 143.8998564\ttotal: 6.3s\tremaining: 4m 16s\n",
            "24:\tlearn: 143.8508118\ttotal: 6.56s\tremaining: 4m 15s\n",
            "25:\tlearn: 143.8491895\ttotal: 6.79s\tremaining: 4m 14s\n",
            "26:\tlearn: 143.7650210\ttotal: 7.05s\tremaining: 4m 14s\n",
            "27:\tlearn: 143.7263287\ttotal: 7.29s\tremaining: 4m 12s\n",
            "28:\tlearn: 143.7243379\ttotal: 7.55s\tremaining: 4m 12s\n",
            "29:\tlearn: 143.7110688\ttotal: 7.78s\tremaining: 4m 11s\n",
            "30:\tlearn: 143.5904760\ttotal: 8s\tremaining: 4m 10s\n",
            "31:\tlearn: 143.5637484\ttotal: 8.23s\tremaining: 4m 8s\n",
            "32:\tlearn: 143.5626658\ttotal: 8.47s\tremaining: 4m 8s\n",
            "33:\tlearn: 143.5353380\ttotal: 8.71s\tremaining: 4m 7s\n",
            "34:\tlearn: 143.5209326\ttotal: 8.94s\tremaining: 4m 6s\n",
            "35:\tlearn: 143.5205946\ttotal: 9.17s\tremaining: 4m 5s\n",
            "36:\tlearn: 143.4679370\ttotal: 9.42s\tremaining: 4m 5s\n",
            "37:\tlearn: 143.4663410\ttotal: 9.67s\tremaining: 4m 4s\n",
            "38:\tlearn: 143.4605498\ttotal: 9.93s\tremaining: 4m 4s\n",
            "39:\tlearn: 143.4523635\ttotal: 10.2s\tremaining: 4m 4s\n",
            "40:\tlearn: 143.3689750\ttotal: 10.4s\tremaining: 4m 4s\n",
            "41:\tlearn: 143.3671100\ttotal: 10.7s\tremaining: 4m 3s\n",
            "42:\tlearn: 143.3607660\ttotal: 10.9s\tremaining: 4m 3s\n",
            "43:\tlearn: 143.3429543\ttotal: 11.2s\tremaining: 4m 3s\n",
            "44:\tlearn: 143.3357757\ttotal: 11.4s\tremaining: 4m 2s\n",
            "45:\tlearn: 143.0773211\ttotal: 11.7s\tremaining: 4m 1s\n",
            "46:\tlearn: 143.0403336\ttotal: 11.9s\tremaining: 4m 1s\n",
            "47:\tlearn: 143.0397138\ttotal: 12.1s\tremaining: 4m\n",
            "48:\tlearn: 143.0290200\ttotal: 12.4s\tremaining: 4m\n",
            "49:\tlearn: 143.0274985\ttotal: 12.6s\tremaining: 4m\n",
            "50:\tlearn: 143.0267737\ttotal: 12.9s\tremaining: 3m 59s\n",
            "51:\tlearn: 143.0134357\ttotal: 13.1s\tremaining: 3m 59s\n",
            "52:\tlearn: 143.0077035\ttotal: 13.4s\tremaining: 3m 58s\n",
            "53:\tlearn: 143.0060566\ttotal: 13.6s\tremaining: 3m 58s\n",
            "54:\tlearn: 143.0053526\ttotal: 13.9s\tremaining: 3m 58s\n",
            "55:\tlearn: 143.0039656\ttotal: 14.1s\tremaining: 3m 57s\n",
            "56:\tlearn: 142.8048721\ttotal: 14.3s\tremaining: 3m 57s\n",
            "57:\tlearn: 142.8043008\ttotal: 14.6s\tremaining: 3m 56s\n",
            "58:\tlearn: 142.8004704\ttotal: 14.8s\tremaining: 3m 56s\n",
            "59:\tlearn: 142.7998699\ttotal: 15s\tremaining: 3m 55s\n",
            "60:\tlearn: 142.7963206\ttotal: 15.3s\tremaining: 3m 55s\n",
            "61:\tlearn: 142.7951485\ttotal: 15.5s\tremaining: 3m 54s\n",
            "62:\tlearn: 142.7722212\ttotal: 15.8s\tremaining: 3m 54s\n",
            "63:\tlearn: 142.7714412\ttotal: 16s\tremaining: 3m 54s\n",
            "64:\tlearn: 142.7274095\ttotal: 16.2s\tremaining: 3m 53s\n",
            "65:\tlearn: 142.7157682\ttotal: 16.5s\tremaining: 3m 53s\n",
            "66:\tlearn: 142.6961545\ttotal: 16.8s\tremaining: 3m 53s\n",
            "67:\tlearn: 142.6937334\ttotal: 17s\tremaining: 3m 52s\n",
            "68:\tlearn: 142.6934977\ttotal: 17.2s\tremaining: 3m 52s\n",
            "69:\tlearn: 142.6896449\ttotal: 17.5s\tremaining: 3m 51s\n",
            "70:\tlearn: 142.6694066\ttotal: 17.7s\tremaining: 3m 51s\n",
            "71:\tlearn: 142.6566025\ttotal: 18s\tremaining: 3m 51s\n",
            "72:\tlearn: 142.6546768\ttotal: 18.2s\tremaining: 3m 51s\n",
            "73:\tlearn: 142.6538337\ttotal: 18.5s\tremaining: 3m 51s\n",
            "74:\tlearn: 142.6532175\ttotal: 18.7s\tremaining: 3m 51s\n",
            "75:\tlearn: 142.6525695\ttotal: 19s\tremaining: 3m 50s\n",
            "76:\tlearn: 142.6506959\ttotal: 19.3s\tremaining: 3m 50s\n",
            "77:\tlearn: 142.6497372\ttotal: 19.5s\tremaining: 3m 50s\n",
            "78:\tlearn: 142.6494458\ttotal: 19.7s\tremaining: 3m 49s\n",
            "79:\tlearn: 142.6490937\ttotal: 19.9s\tremaining: 3m 49s\n",
            "80:\tlearn: 142.6488491\ttotal: 20.2s\tremaining: 3m 49s\n",
            "81:\tlearn: 142.6487809\ttotal: 20.4s\tremaining: 3m 48s\n",
            "82:\tlearn: 142.6486691\ttotal: 20.7s\tremaining: 3m 48s\n",
            "83:\tlearn: 142.6485365\ttotal: 21s\tremaining: 3m 48s\n",
            "84:\tlearn: 142.6383942\ttotal: 21.2s\tremaining: 3m 47s\n",
            "85:\tlearn: 142.6379909\ttotal: 21.4s\tremaining: 3m 47s\n",
            "86:\tlearn: 142.6378192\ttotal: 21.6s\tremaining: 3m 46s\n",
            "87:\tlearn: 142.6375884\ttotal: 21.8s\tremaining: 3m 46s\n",
            "88:\tlearn: 142.6374779\ttotal: 22.1s\tremaining: 3m 45s\n",
            "89:\tlearn: 142.6363988\ttotal: 22.3s\tremaining: 3m 45s\n",
            "90:\tlearn: 142.6348648\ttotal: 22.6s\tremaining: 3m 45s\n",
            "91:\tlearn: 142.6337402\ttotal: 22.8s\tremaining: 3m 45s\n",
            "92:\tlearn: 142.6323735\ttotal: 23.1s\tremaining: 3m 44s\n",
            "93:\tlearn: 142.6316094\ttotal: 23.3s\tremaining: 3m 44s\n",
            "94:\tlearn: 142.6314628\ttotal: 23.5s\tremaining: 3m 44s\n",
            "95:\tlearn: 142.6306852\ttotal: 23.8s\tremaining: 3m 43s\n",
            "96:\tlearn: 142.6265335\ttotal: 24s\tremaining: 3m 43s\n",
            "97:\tlearn: 142.6262882\ttotal: 24.2s\tremaining: 3m 42s\n",
            "98:\tlearn: 142.6262484\ttotal: 24.4s\tremaining: 3m 42s\n",
            "99:\tlearn: 142.6257321\ttotal: 24.7s\tremaining: 3m 42s\n",
            "100:\tlearn: 142.6240734\ttotal: 24.9s\tremaining: 3m 41s\n",
            "101:\tlearn: 142.6217720\ttotal: 25.1s\tremaining: 3m 41s\n",
            "102:\tlearn: 142.6217604\ttotal: 25.4s\tremaining: 3m 41s\n",
            "103:\tlearn: 142.6213623\ttotal: 25.6s\tremaining: 3m 40s\n",
            "104:\tlearn: 142.6205118\ttotal: 25.8s\tremaining: 3m 40s\n",
            "105:\tlearn: 142.6202325\ttotal: 26s\tremaining: 3m 39s\n",
            "106:\tlearn: 142.6197021\ttotal: 26.3s\tremaining: 3m 39s\n",
            "107:\tlearn: 142.6195216\ttotal: 26.6s\tremaining: 3m 40s\n",
            "108:\tlearn: 142.6194920\ttotal: 26.9s\tremaining: 3m 39s\n",
            "109:\tlearn: 142.6193713\ttotal: 27.1s\tremaining: 3m 39s\n",
            "110:\tlearn: 142.6190685\ttotal: 27.4s\tremaining: 3m 39s\n",
            "111:\tlearn: 142.6176590\ttotal: 27.6s\tremaining: 3m 39s\n",
            "112:\tlearn: 142.6176493\ttotal: 27.9s\tremaining: 3m 38s\n",
            "113:\tlearn: 142.6175306\ttotal: 28.1s\tremaining: 3m 38s\n",
            "114:\tlearn: 142.6175217\ttotal: 28.4s\tremaining: 3m 38s\n",
            "115:\tlearn: 142.6174698\ttotal: 28.7s\tremaining: 3m 38s\n",
            "116:\tlearn: 142.6174275\ttotal: 28.9s\tremaining: 3m 38s\n",
            "117:\tlearn: 142.6110238\ttotal: 29.1s\tremaining: 3m 37s\n",
            "118:\tlearn: 142.6103892\ttotal: 29.4s\tremaining: 3m 37s\n",
            "119:\tlearn: 142.6099598\ttotal: 29.6s\tremaining: 3m 37s\n",
            "120:\tlearn: 142.6097676\ttotal: 29.8s\tremaining: 3m 36s\n",
            "121:\tlearn: 142.6095073\ttotal: 30.1s\tremaining: 3m 36s\n",
            "122:\tlearn: 142.6092995\ttotal: 30.4s\tremaining: 3m 36s\n",
            "123:\tlearn: 142.6091252\ttotal: 30.6s\tremaining: 3m 36s\n",
            "124:\tlearn: 142.6090054\ttotal: 30.9s\tremaining: 3m 36s\n",
            "125:\tlearn: 142.6087902\ttotal: 31.2s\tremaining: 3m 36s\n",
            "126:\tlearn: 142.6086350\ttotal: 31.4s\tremaining: 3m 36s\n",
            "127:\tlearn: 142.6085219\ttotal: 31.7s\tremaining: 3m 36s\n",
            "128:\tlearn: 142.6084536\ttotal: 32s\tremaining: 3m 35s\n",
            "129:\tlearn: 142.6083991\ttotal: 32.2s\tremaining: 3m 35s\n",
            "130:\tlearn: 142.6083514\ttotal: 32.5s\tremaining: 3m 35s\n",
            "131:\tlearn: 142.6083205\ttotal: 32.8s\tremaining: 3m 35s\n",
            "132:\tlearn: 142.6082962\ttotal: 33.1s\tremaining: 3m 35s\n",
            "133:\tlearn: 142.6082759\ttotal: 33.4s\tremaining: 3m 35s\n",
            "134:\tlearn: 142.6082361\ttotal: 33.6s\tremaining: 3m 35s\n",
            "135:\tlearn: 142.6082112\ttotal: 33.9s\tremaining: 3m 35s\n",
            "136:\tlearn: 142.6081973\ttotal: 34.1s\tremaining: 3m 35s\n",
            "137:\tlearn: 142.6081899\ttotal: 34.4s\tremaining: 3m 35s\n",
            "138:\tlearn: 142.6081837\ttotal: 34.7s\tremaining: 3m 34s\n",
            "139:\tlearn: 142.6081785\ttotal: 35s\tremaining: 3m 34s\n",
            "140:\tlearn: 142.6081743\ttotal: 35.3s\tremaining: 3m 34s\n",
            "141:\tlearn: 142.6081710\ttotal: 35.6s\tremaining: 3m 34s\n",
            "142:\tlearn: 142.6081681\ttotal: 35.8s\tremaining: 3m 34s\n",
            "143:\tlearn: 142.6081657\ttotal: 36.1s\tremaining: 3m 34s\n",
            "144:\tlearn: 142.6081638\ttotal: 36.4s\tremaining: 3m 34s\n",
            "145:\tlearn: 142.6081622\ttotal: 36.7s\tremaining: 3m 34s\n",
            "146:\tlearn: 142.6081609\ttotal: 37s\tremaining: 3m 34s\n",
            "147:\tlearn: 142.6081598\ttotal: 37.3s\tremaining: 3m 34s\n",
            "148:\tlearn: 142.6081589\ttotal: 37.5s\tremaining: 3m 34s\n",
            "149:\tlearn: 142.6081571\ttotal: 37.8s\tremaining: 3m 34s\n",
            "150:\tlearn: 142.6081565\ttotal: 38.1s\tremaining: 3m 34s\n",
            "151:\tlearn: 142.6081561\ttotal: 38.4s\tremaining: 3m 34s\n",
            "152:\tlearn: 142.6081557\ttotal: 38.7s\tremaining: 3m 34s\n",
            "153:\tlearn: 142.6081553\ttotal: 39s\tremaining: 3m 34s\n",
            "154:\tlearn: 142.6081550\ttotal: 39.3s\tremaining: 3m 34s\n",
            "155:\tlearn: 142.6081548\ttotal: 39.6s\tremaining: 3m 34s\n",
            "156:\tlearn: 142.6081546\ttotal: 39.9s\tremaining: 3m 34s\n",
            "157:\tlearn: 142.6081537\ttotal: 40.2s\tremaining: 3m 34s\n",
            "158:\tlearn: 142.6081536\ttotal: 40.4s\tremaining: 3m 33s\n",
            "159:\tlearn: 142.6081535\ttotal: 40.7s\tremaining: 3m 33s\n",
            "160:\tlearn: 142.6081534\ttotal: 41s\tremaining: 3m 33s\n",
            "161:\tlearn: 142.6081533\ttotal: 41.3s\tremaining: 3m 33s\n",
            "162:\tlearn: 142.6081533\ttotal: 41.6s\tremaining: 3m 33s\n",
            "163:\tlearn: 142.6081532\ttotal: 41.9s\tremaining: 3m 33s\n",
            "164:\tlearn: 142.6081531\ttotal: 42.2s\tremaining: 3m 33s\n",
            "165:\tlearn: 142.6081531\ttotal: 42.5s\tremaining: 3m 33s\n",
            "166:\tlearn: 142.6081531\ttotal: 42.7s\tremaining: 3m 33s\n",
            "167:\tlearn: 142.6081530\ttotal: 43s\tremaining: 3m 33s\n",
            "168:\tlearn: 142.6081530\ttotal: 43.3s\tremaining: 3m 32s\n",
            "169:\tlearn: 142.6081530\ttotal: 43.6s\tremaining: 3m 32s\n",
            "170:\tlearn: 142.6081530\ttotal: 43.8s\tremaining: 3m 32s\n",
            "171:\tlearn: 142.6081530\ttotal: 44.1s\tremaining: 3m 32s\n",
            "172:\tlearn: 142.6081529\ttotal: 44.4s\tremaining: 3m 32s\n",
            "173:\tlearn: 142.6081529\ttotal: 44.7s\tremaining: 3m 32s\n",
            "174:\tlearn: 142.6081529\ttotal: 45s\tremaining: 3m 31s\n",
            "175:\tlearn: 142.6081529\ttotal: 45.3s\tremaining: 3m 31s\n",
            "176:\tlearn: 142.6081529\ttotal: 45.5s\tremaining: 3m 31s\n",
            "177:\tlearn: 142.6081529\ttotal: 45.8s\tremaining: 3m 31s\n",
            "178:\tlearn: 142.6081529\ttotal: 46.1s\tremaining: 3m 31s\n",
            "179:\tlearn: 142.6081529\ttotal: 46.4s\tremaining: 3m 31s\n",
            "180:\tlearn: 142.6081529\ttotal: 46.6s\tremaining: 3m 31s\n",
            "181:\tlearn: 142.6081528\ttotal: 46.9s\tremaining: 3m 30s\n",
            "182:\tlearn: 142.6081528\ttotal: 47.2s\tremaining: 3m 30s\n",
            "183:\tlearn: 142.6081528\ttotal: 47.5s\tremaining: 3m 30s\n",
            "184:\tlearn: 142.6081528\ttotal: 47.8s\tremaining: 3m 30s\n",
            "185:\tlearn: 142.6081528\ttotal: 48.1s\tremaining: 3m 30s\n",
            "186:\tlearn: 142.6081528\ttotal: 48.3s\tremaining: 3m 30s\n",
            "187:\tlearn: 142.6081528\ttotal: 48.6s\tremaining: 3m 30s\n",
            "188:\tlearn: 142.6081528\ttotal: 48.9s\tremaining: 3m 29s\n",
            "189:\tlearn: 142.6081528\ttotal: 49.2s\tremaining: 3m 29s\n",
            "190:\tlearn: 142.6081528\ttotal: 49.5s\tremaining: 3m 29s\n",
            "191:\tlearn: 142.6081528\ttotal: 49.7s\tremaining: 3m 29s\n",
            "192:\tlearn: 142.6081528\ttotal: 50s\tremaining: 3m 29s\n",
            "193:\tlearn: 142.6081528\ttotal: 50.3s\tremaining: 3m 29s\n",
            "194:\tlearn: 142.6081528\ttotal: 50.6s\tremaining: 3m 28s\n",
            "195:\tlearn: 142.6081528\ttotal: 50.9s\tremaining: 3m 28s\n",
            "196:\tlearn: 142.6081528\ttotal: 51.2s\tremaining: 3m 28s\n",
            "197:\tlearn: 142.6081528\ttotal: 51.4s\tremaining: 3m 28s\n",
            "198:\tlearn: 142.6081528\ttotal: 51.7s\tremaining: 3m 28s\n",
            "199:\tlearn: 142.6081528\ttotal: 52s\tremaining: 3m 27s\n",
            "200:\tlearn: 142.6081528\ttotal: 52.3s\tremaining: 3m 27s\n",
            "201:\tlearn: 142.6081164\ttotal: 52.5s\tremaining: 3m 27s\n",
            "202:\tlearn: 142.6073604\ttotal: 52.8s\tremaining: 3m 27s\n",
            "203:\tlearn: 142.6066818\ttotal: 53.1s\tremaining: 3m 27s\n",
            "204:\tlearn: 142.6060728\ttotal: 53.4s\tremaining: 3m 26s\n",
            "205:\tlearn: 142.6055256\ttotal: 53.6s\tremaining: 3m 26s\n",
            "206:\tlearn: 142.6050338\ttotal: 53.9s\tremaining: 3m 26s\n",
            "207:\tlearn: 142.6045917\ttotal: 54.2s\tremaining: 3m 26s\n",
            "208:\tlearn: 142.6045870\ttotal: 54.5s\tremaining: 3m 26s\n",
            "209:\tlearn: 142.6045815\ttotal: 54.8s\tremaining: 3m 25s\n",
            "210:\tlearn: 142.6045769\ttotal: 55s\tremaining: 3m 25s\n",
            "211:\tlearn: 142.6045729\ttotal: 55.3s\tremaining: 3m 25s\n",
            "212:\tlearn: 142.6045695\ttotal: 55.6s\tremaining: 3m 25s\n",
            "213:\tlearn: 142.6041721\ttotal: 55.8s\tremaining: 3m 25s\n",
            "214:\tlearn: 142.6038147\ttotal: 56.1s\tremaining: 3m 24s\n",
            "215:\tlearn: 142.6038119\ttotal: 56.4s\tremaining: 3m 24s\n",
            "216:\tlearn: 142.6038097\ttotal: 56.7s\tremaining: 3m 24s\n",
            "217:\tlearn: 142.6038087\ttotal: 56.9s\tremaining: 3m 24s\n",
            "218:\tlearn: 142.6034874\ttotal: 57.2s\tremaining: 3m 24s\n",
            "219:\tlearn: 142.6031983\ttotal: 57.5s\tremaining: 3m 23s\n",
            "220:\tlearn: 142.6031967\ttotal: 57.8s\tremaining: 3m 23s\n",
            "221:\tlearn: 142.6029366\ttotal: 58.1s\tremaining: 3m 23s\n",
            "222:\tlearn: 142.6027027\ttotal: 58.4s\tremaining: 3m 23s\n",
            "223:\tlearn: 142.6027027\ttotal: 58.6s\tremaining: 3m 23s\n",
            "224:\tlearn: 142.6027013\ttotal: 58.9s\tremaining: 3m 22s\n",
            "225:\tlearn: 142.6027002\ttotal: 59.2s\tremaining: 3m 22s\n",
            "226:\tlearn: 142.6026994\ttotal: 59.5s\tremaining: 3m 22s\n",
            "227:\tlearn: 142.6024890\ttotal: 59.7s\tremaining: 3m 22s\n",
            "228:\tlearn: 142.6024890\ttotal: 1m\tremaining: 3m 22s\n",
            "229:\tlearn: 142.6024883\ttotal: 1m\tremaining: 3m 21s\n",
            "230:\tlearn: 142.6022991\ttotal: 1m\tremaining: 3m 21s\n",
            "231:\tlearn: 142.6021290\ttotal: 1m\tremaining: 3m 21s\n",
            "232:\tlearn: 142.6021289\ttotal: 1m 1s\tremaining: 3m 21s\n",
            "233:\tlearn: 142.6019759\ttotal: 1m 1s\tremaining: 3m 21s\n",
            "234:\tlearn: 142.6019727\ttotal: 1m 1s\tremaining: 3m 20s\n",
            "235:\tlearn: 142.6019699\ttotal: 1m 1s\tremaining: 3m 20s\n",
            "236:\tlearn: 142.6019675\ttotal: 1m 2s\tremaining: 3m 20s\n",
            "237:\tlearn: 142.6018299\ttotal: 1m 2s\tremaining: 3m 20s\n",
            "238:\tlearn: 142.6017061\ttotal: 1m 2s\tremaining: 3m 19s\n",
            "239:\tlearn: 142.6016877\ttotal: 1m 3s\tremaining: 3m 19s\n",
            "240:\tlearn: 142.6015762\ttotal: 1m 3s\tremaining: 3m 19s\n",
            "241:\tlearn: 142.6015757\ttotal: 1m 3s\tremaining: 3m 19s\n",
            "242:\tlearn: 142.6015738\ttotal: 1m 3s\tremaining: 3m 18s\n",
            "243:\tlearn: 142.6015722\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "244:\tlearn: 142.6014719\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "245:\tlearn: 142.6014715\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "246:\tlearn: 142.6013813\ttotal: 1m 4s\tremaining: 3m 18s\n",
            "247:\tlearn: 142.6013001\ttotal: 1m 5s\tremaining: 3m 17s\n",
            "248:\tlearn: 142.6012998\ttotal: 1m 5s\tremaining: 3m 17s\n",
            "249:\tlearn: 142.6012995\ttotal: 1m 5s\tremaining: 3m 17s\n",
            "250:\tlearn: 142.6012264\ttotal: 1m 6s\tremaining: 3m 17s\n",
            "251:\tlearn: 142.6012262\ttotal: 1m 6s\tremaining: 3m 16s\n",
            "252:\tlearn: 142.6012260\ttotal: 1m 6s\tremaining: 3m 16s\n",
            "253:\tlearn: 142.6012258\ttotal: 1m 6s\tremaining: 3m 16s\n",
            "254:\tlearn: 142.6011601\ttotal: 1m 7s\tremaining: 3m 16s\n",
            "255:\tlearn: 142.6011010\ttotal: 1m 7s\tremaining: 3m 16s\n",
            "256:\tlearn: 142.6010478\ttotal: 1m 7s\tremaining: 3m 15s\n",
            "257:\tlearn: 142.6009999\ttotal: 1m 8s\tremaining: 3m 15s\n",
            "258:\tlearn: 142.6009568\ttotal: 1m 8s\tremaining: 3m 15s\n",
            "259:\tlearn: 142.6009567\ttotal: 1m 8s\tremaining: 3m 15s\n",
            "260:\tlearn: 142.6009421\ttotal: 1m 8s\tremaining: 3m 15s\n",
            "261:\tlearn: 142.6009034\ttotal: 1m 9s\tremaining: 3m 15s\n",
            "262:\tlearn: 142.6008685\ttotal: 1m 9s\tremaining: 3m 14s\n",
            "263:\tlearn: 142.6008371\ttotal: 1m 9s\tremaining: 3m 14s\n",
            "264:\tlearn: 142.6008089\ttotal: 1m 10s\tremaining: 3m 14s\n",
            "265:\tlearn: 142.6008089\ttotal: 1m 10s\tremaining: 3m 14s\n",
            "266:\tlearn: 142.6007835\ttotal: 1m 10s\tremaining: 3m 14s\n",
            "267:\tlearn: 142.6007606\ttotal: 1m 11s\tremaining: 3m 14s\n",
            "268:\tlearn: 142.6007400\ttotal: 1m 11s\tremaining: 3m 13s\n",
            "269:\tlearn: 142.6007215\ttotal: 1m 11s\tremaining: 3m 13s\n",
            "270:\tlearn: 142.6007048\ttotal: 1m 11s\tremaining: 3m 13s\n",
            "271:\tlearn: 142.6006898\ttotal: 1m 12s\tremaining: 3m 13s\n",
            "272:\tlearn: 142.6006764\ttotal: 1m 12s\tremaining: 3m 13s\n",
            "273:\tlearn: 142.6006642\ttotal: 1m 12s\tremaining: 3m 12s\n",
            "274:\tlearn: 142.6006533\ttotal: 1m 13s\tremaining: 3m 12s\n",
            "275:\tlearn: 142.6006434\ttotal: 1m 13s\tremaining: 3m 12s\n",
            "276:\tlearn: 142.6006346\ttotal: 1m 13s\tremaining: 3m 12s\n",
            "277:\tlearn: 142.6006266\ttotal: 1m 13s\tremaining: 3m 12s\n",
            "278:\tlearn: 142.6006194\ttotal: 1m 14s\tremaining: 3m 11s\n",
            "279:\tlearn: 142.6006130\ttotal: 1m 14s\tremaining: 3m 11s\n",
            "280:\tlearn: 142.6006072\ttotal: 1m 14s\tremaining: 3m 11s\n",
            "281:\tlearn: 142.6006020\ttotal: 1m 15s\tremaining: 3m 11s\n",
            "282:\tlearn: 142.6005973\ttotal: 1m 15s\tremaining: 3m 10s\n",
            "283:\tlearn: 142.6005930\ttotal: 1m 15s\tremaining: 3m 10s\n",
            "284:\tlearn: 142.6005892\ttotal: 1m 15s\tremaining: 3m 10s\n",
            "285:\tlearn: 142.6005858\ttotal: 1m 16s\tremaining: 3m 10s\n",
            "286:\tlearn: 142.6005827\ttotal: 1m 16s\tremaining: 3m 9s\n",
            "287:\tlearn: 142.6005799\ttotal: 1m 16s\tremaining: 3m 9s\n",
            "288:\tlearn: 142.6005774\ttotal: 1m 17s\tremaining: 3m 9s\n",
            "289:\tlearn: 142.6005752\ttotal: 1m 17s\tremaining: 3m 9s\n",
            "290:\tlearn: 142.6005731\ttotal: 1m 17s\tremaining: 3m 9s\n",
            "291:\tlearn: 142.6005713\ttotal: 1m 17s\tremaining: 3m 8s\n",
            "292:\tlearn: 142.6005697\ttotal: 1m 18s\tremaining: 3m 8s\n",
            "293:\tlearn: 142.6005682\ttotal: 1m 18s\tremaining: 3m 8s\n",
            "294:\tlearn: 142.6005669\ttotal: 1m 18s\tremaining: 3m 8s\n",
            "295:\tlearn: 142.6005657\ttotal: 1m 18s\tremaining: 3m 7s\n",
            "296:\tlearn: 142.6005646\ttotal: 1m 19s\tremaining: 3m 7s\n",
            "297:\tlearn: 142.6005645\ttotal: 1m 19s\tremaining: 3m 7s\n",
            "298:\tlearn: 142.6005635\ttotal: 1m 19s\tremaining: 3m 7s\n",
            "299:\tlearn: 142.6005626\ttotal: 1m 20s\tremaining: 3m 7s\n",
            "300:\tlearn: 142.6005619\ttotal: 1m 20s\tremaining: 3m 6s\n",
            "301:\tlearn: 142.6005612\ttotal: 1m 20s\tremaining: 3m 6s\n",
            "302:\tlearn: 142.6005605\ttotal: 1m 21s\tremaining: 3m 6s\n",
            "303:\tlearn: 142.6005599\ttotal: 1m 21s\tremaining: 3m 6s\n",
            "304:\tlearn: 142.6005594\ttotal: 1m 21s\tremaining: 3m 6s\n",
            "305:\tlearn: 142.6005590\ttotal: 1m 21s\tremaining: 3m 5s\n",
            "306:\tlearn: 142.6005586\ttotal: 1m 22s\tremaining: 3m 5s\n",
            "307:\tlearn: 142.6005582\ttotal: 1m 22s\tremaining: 3m 5s\n",
            "308:\tlearn: 142.6005578\ttotal: 1m 22s\tremaining: 3m 5s\n",
            "309:\tlearn: 142.6005575\ttotal: 1m 23s\tremaining: 3m 5s\n",
            "310:\tlearn: 142.6005573\ttotal: 1m 23s\tremaining: 3m 4s\n",
            "311:\tlearn: 142.6005570\ttotal: 1m 23s\tremaining: 3m 4s\n",
            "312:\tlearn: 142.6005568\ttotal: 1m 24s\tremaining: 3m 4s\n",
            "313:\tlearn: 142.6005566\ttotal: 1m 24s\tremaining: 3m 4s\n",
            "314:\tlearn: 142.6005564\ttotal: 1m 24s\tremaining: 3m 4s\n",
            "315:\tlearn: 142.6005563\ttotal: 1m 24s\tremaining: 3m 3s\n",
            "316:\tlearn: 142.6005561\ttotal: 1m 25s\tremaining: 3m 3s\n",
            "317:\tlearn: 142.6005560\ttotal: 1m 25s\tremaining: 3m 3s\n",
            "318:\tlearn: 142.6005559\ttotal: 1m 25s\tremaining: 3m 3s\n",
            "319:\tlearn: 142.6005558\ttotal: 1m 26s\tremaining: 3m 3s\n",
            "320:\tlearn: 142.6005557\ttotal: 1m 26s\tremaining: 3m 2s\n",
            "321:\tlearn: 142.6005556\ttotal: 1m 26s\tremaining: 3m 2s\n",
            "322:\tlearn: 142.6005555\ttotal: 1m 27s\tremaining: 3m 2s\n",
            "323:\tlearn: 142.6005554\ttotal: 1m 27s\tremaining: 3m 2s\n",
            "324:\tlearn: 142.6005554\ttotal: 1m 27s\tremaining: 3m 1s\n",
            "325:\tlearn: 142.6005553\ttotal: 1m 27s\tremaining: 3m 1s\n",
            "326:\tlearn: 142.6005553\ttotal: 1m 28s\tremaining: 3m 1s\n",
            "327:\tlearn: 142.6005552\ttotal: 1m 28s\tremaining: 3m 1s\n",
            "328:\tlearn: 142.6005552\ttotal: 1m 28s\tremaining: 3m\n",
            "329:\tlearn: 142.6005551\ttotal: 1m 28s\tremaining: 3m\n",
            "330:\tlearn: 142.6005551\ttotal: 1m 29s\tremaining: 3m\n",
            "331:\tlearn: 142.6005551\ttotal: 1m 29s\tremaining: 2m 59s\n",
            "332:\tlearn: 142.6005551\ttotal: 1m 29s\tremaining: 2m 59s\n",
            "333:\tlearn: 142.6005550\ttotal: 1m 30s\tremaining: 2m 59s\n",
            "334:\tlearn: 142.6005550\ttotal: 1m 30s\tremaining: 2m 59s\n",
            "335:\tlearn: 142.6005550\ttotal: 1m 30s\tremaining: 2m 59s\n",
            "336:\tlearn: 142.6005550\ttotal: 1m 30s\tremaining: 2m 58s\n",
            "337:\tlearn: 142.6005550\ttotal: 1m 31s\tremaining: 2m 58s\n",
            "338:\tlearn: 142.6005549\ttotal: 1m 31s\tremaining: 2m 58s\n",
            "339:\tlearn: 142.6005549\ttotal: 1m 31s\tremaining: 2m 58s\n",
            "340:\tlearn: 142.6005549\ttotal: 1m 31s\tremaining: 2m 57s\n",
            "341:\tlearn: 142.6005549\ttotal: 1m 32s\tremaining: 2m 57s\n",
            "342:\tlearn: 142.6005549\ttotal: 1m 32s\tremaining: 2m 57s\n",
            "343:\tlearn: 142.6005549\ttotal: 1m 32s\tremaining: 2m 57s\n",
            "344:\tlearn: 142.6005549\ttotal: 1m 33s\tremaining: 2m 56s\n",
            "345:\tlearn: 142.6005549\ttotal: 1m 33s\tremaining: 2m 56s\n",
            "346:\tlearn: 142.6005549\ttotal: 1m 33s\tremaining: 2m 56s\n",
            "347:\tlearn: 142.6005549\ttotal: 1m 33s\tremaining: 2m 56s\n",
            "348:\tlearn: 142.6005549\ttotal: 1m 34s\tremaining: 2m 55s\n",
            "349:\tlearn: 142.6005549\ttotal: 1m 34s\tremaining: 2m 55s\n",
            "350:\tlearn: 142.6005548\ttotal: 1m 34s\tremaining: 2m 55s\n",
            "351:\tlearn: 142.6005547\ttotal: 1m 35s\tremaining: 2m 55s\n",
            "352:\tlearn: 142.6005546\ttotal: 1m 35s\tremaining: 2m 54s\n",
            "353:\tlearn: 142.6005546\ttotal: 1m 35s\tremaining: 2m 54s\n",
            "354:\tlearn: 142.6005546\ttotal: 1m 35s\tremaining: 2m 54s\n",
            "355:\tlearn: 142.6005546\ttotal: 1m 36s\tremaining: 2m 54s\n",
            "356:\tlearn: 142.6005546\ttotal: 1m 36s\tremaining: 2m 53s\n",
            "357:\tlearn: 142.6005546\ttotal: 1m 36s\tremaining: 2m 53s\n",
            "358:\tlearn: 142.6005546\ttotal: 1m 37s\tremaining: 2m 53s\n",
            "359:\tlearn: 142.6005546\ttotal: 1m 37s\tremaining: 2m 53s\n",
            "360:\tlearn: 142.6005546\ttotal: 1m 37s\tremaining: 2m 52s\n",
            "361:\tlearn: 142.6005546\ttotal: 1m 37s\tremaining: 2m 52s\n",
            "362:\tlearn: 142.6005546\ttotal: 1m 38s\tremaining: 2m 52s\n",
            "363:\tlearn: 142.6005546\ttotal: 1m 38s\tremaining: 2m 51s\n",
            "364:\tlearn: 142.6005546\ttotal: 1m 38s\tremaining: 2m 51s\n",
            "365:\tlearn: 142.6005546\ttotal: 1m 39s\tremaining: 2m 51s\n",
            "366:\tlearn: 142.6005546\ttotal: 1m 39s\tremaining: 2m 51s\n",
            "367:\tlearn: 142.6005546\ttotal: 1m 39s\tremaining: 2m 51s\n",
            "368:\tlearn: 142.6005546\ttotal: 1m 40s\tremaining: 2m 51s\n",
            "369:\tlearn: 142.6005546\ttotal: 1m 40s\tremaining: 2m 50s\n",
            "370:\tlearn: 142.6005546\ttotal: 1m 40s\tremaining: 2m 50s\n",
            "371:\tlearn: 142.6005546\ttotal: 1m 41s\tremaining: 2m 50s\n",
            "372:\tlearn: 142.6005546\ttotal: 1m 41s\tremaining: 2m 50s\n",
            "373:\tlearn: 142.6005546\ttotal: 1m 41s\tremaining: 2m 50s\n",
            "374:\tlearn: 142.6005545\ttotal: 1m 41s\tremaining: 2m 49s\n",
            "375:\tlearn: 142.6005544\ttotal: 1m 42s\tremaining: 2m 49s\n",
            "376:\tlearn: 142.6005544\ttotal: 1m 42s\tremaining: 2m 49s\n",
            "377:\tlearn: 142.6005544\ttotal: 1m 42s\tremaining: 2m 49s\n",
            "378:\tlearn: 142.6005544\ttotal: 1m 43s\tremaining: 2m 49s\n",
            "379:\tlearn: 142.6005544\ttotal: 1m 43s\tremaining: 2m 48s\n",
            "380:\tlearn: 142.6005544\ttotal: 1m 43s\tremaining: 2m 48s\n",
            "381:\tlearn: 142.6005544\ttotal: 1m 44s\tremaining: 2m 48s\n",
            "382:\tlearn: 142.6005544\ttotal: 1m 44s\tremaining: 2m 48s\n",
            "383:\tlearn: 142.6005544\ttotal: 1m 44s\tremaining: 2m 47s\n",
            "384:\tlearn: 142.6005544\ttotal: 1m 44s\tremaining: 2m 47s\n",
            "385:\tlearn: 142.6005544\ttotal: 1m 45s\tremaining: 2m 47s\n",
            "386:\tlearn: 142.6005544\ttotal: 1m 45s\tremaining: 2m 47s\n",
            "387:\tlearn: 142.6005544\ttotal: 1m 45s\tremaining: 2m 46s\n",
            "388:\tlearn: 142.6005544\ttotal: 1m 46s\tremaining: 2m 46s\n",
            "389:\tlearn: 142.6005544\ttotal: 1m 46s\tremaining: 2m 46s\n",
            "390:\tlearn: 142.6005544\ttotal: 1m 46s\tremaining: 2m 46s\n",
            "391:\tlearn: 142.6005544\ttotal: 1m 46s\tremaining: 2m 45s\n",
            "392:\tlearn: 142.6005544\ttotal: 1m 47s\tremaining: 2m 45s\n",
            "393:\tlearn: 142.6005544\ttotal: 1m 47s\tremaining: 2m 45s\n",
            "394:\tlearn: 142.6005544\ttotal: 1m 47s\tremaining: 2m 45s\n",
            "395:\tlearn: 142.6005544\ttotal: 1m 48s\tremaining: 2m 44s\n",
            "396:\tlearn: 142.6005544\ttotal: 1m 48s\tremaining: 2m 44s\n",
            "397:\tlearn: 142.6005544\ttotal: 1m 48s\tremaining: 2m 44s\n",
            "398:\tlearn: 142.6005544\ttotal: 1m 48s\tremaining: 2m 43s\n",
            "399:\tlearn: 142.6005544\ttotal: 1m 49s\tremaining: 2m 43s\n",
            "400:\tlearn: 142.6005544\ttotal: 1m 49s\tremaining: 2m 43s\n",
            "401:\tlearn: 142.6005544\ttotal: 1m 49s\tremaining: 2m 43s\n",
            "402:\tlearn: 142.6005544\ttotal: 1m 49s\tremaining: 2m 42s\n",
            "403:\tlearn: 142.6005544\ttotal: 1m 50s\tremaining: 2m 42s\n",
            "404:\tlearn: 142.6005544\ttotal: 1m 50s\tremaining: 2m 42s\n",
            "405:\tlearn: 142.6005544\ttotal: 1m 50s\tremaining: 2m 42s\n",
            "406:\tlearn: 142.6005544\ttotal: 1m 51s\tremaining: 2m 41s\n",
            "407:\tlearn: 142.6005544\ttotal: 1m 51s\tremaining: 2m 41s\n",
            "408:\tlearn: 142.6005544\ttotal: 1m 51s\tremaining: 2m 41s\n",
            "409:\tlearn: 142.6005544\ttotal: 1m 51s\tremaining: 2m 40s\n",
            "410:\tlearn: 142.6005544\ttotal: 1m 52s\tremaining: 2m 40s\n",
            "411:\tlearn: 142.6005544\ttotal: 1m 52s\tremaining: 2m 40s\n",
            "412:\tlearn: 142.6005544\ttotal: 1m 52s\tremaining: 2m 40s\n",
            "413:\tlearn: 142.6005544\ttotal: 1m 52s\tremaining: 2m 39s\n",
            "414:\tlearn: 142.6005544\ttotal: 1m 53s\tremaining: 2m 39s\n",
            "415:\tlearn: 142.6005544\ttotal: 1m 53s\tremaining: 2m 39s\n",
            "416:\tlearn: 142.6005544\ttotal: 1m 53s\tremaining: 2m 39s\n",
            "417:\tlearn: 142.6005544\ttotal: 1m 54s\tremaining: 2m 38s\n",
            "418:\tlearn: 142.6005544\ttotal: 1m 54s\tremaining: 2m 38s\n",
            "419:\tlearn: 142.6005544\ttotal: 1m 54s\tremaining: 2m 38s\n",
            "420:\tlearn: 142.6005544\ttotal: 1m 54s\tremaining: 2m 37s\n",
            "421:\tlearn: 142.6005544\ttotal: 1m 55s\tremaining: 2m 37s\n",
            "422:\tlearn: 142.6005544\ttotal: 1m 55s\tremaining: 2m 37s\n",
            "423:\tlearn: 142.6005544\ttotal: 1m 55s\tremaining: 2m 37s\n",
            "424:\tlearn: 142.6005544\ttotal: 1m 55s\tremaining: 2m 36s\n",
            "425:\tlearn: 142.6005544\ttotal: 1m 56s\tremaining: 2m 36s\n",
            "426:\tlearn: 142.6005544\ttotal: 1m 56s\tremaining: 2m 36s\n",
            "427:\tlearn: 142.6005544\ttotal: 1m 56s\tremaining: 2m 36s\n",
            "428:\tlearn: 142.6005544\ttotal: 1m 57s\tremaining: 2m 35s\n",
            "429:\tlearn: 142.6005544\ttotal: 1m 57s\tremaining: 2m 35s\n",
            "430:\tlearn: 142.6005544\ttotal: 1m 57s\tremaining: 2m 35s\n",
            "431:\tlearn: 142.6005544\ttotal: 1m 57s\tremaining: 2m 34s\n",
            "432:\tlearn: 142.6005544\ttotal: 1m 58s\tremaining: 2m 34s\n",
            "433:\tlearn: 142.6005544\ttotal: 1m 58s\tremaining: 2m 34s\n",
            "434:\tlearn: 142.6005544\ttotal: 1m 58s\tremaining: 2m 34s\n",
            "435:\tlearn: 142.6005544\ttotal: 1m 58s\tremaining: 2m 33s\n",
            "436:\tlearn: 142.6005544\ttotal: 1m 59s\tremaining: 2m 33s\n",
            "437:\tlearn: 142.6005544\ttotal: 1m 59s\tremaining: 2m 33s\n",
            "438:\tlearn: 142.6005544\ttotal: 1m 59s\tremaining: 2m 33s\n",
            "439:\tlearn: 142.6005544\ttotal: 2m\tremaining: 2m 32s\n",
            "440:\tlearn: 142.6005544\ttotal: 2m\tremaining: 2m 32s\n",
            "441:\tlearn: 142.6005544\ttotal: 2m\tremaining: 2m 32s\n",
            "442:\tlearn: 142.6005544\ttotal: 2m\tremaining: 2m 32s\n",
            "443:\tlearn: 142.6005544\ttotal: 2m 1s\tremaining: 2m 31s\n",
            "444:\tlearn: 142.6005544\ttotal: 2m 1s\tremaining: 2m 31s\n",
            "445:\tlearn: 142.6005544\ttotal: 2m 1s\tremaining: 2m 31s\n",
            "446:\tlearn: 142.6005544\ttotal: 2m 2s\tremaining: 2m 30s\n",
            "447:\tlearn: 142.6005544\ttotal: 2m 2s\tremaining: 2m 30s\n",
            "448:\tlearn: 142.6005544\ttotal: 2m 2s\tremaining: 2m 30s\n",
            "449:\tlearn: 142.6005544\ttotal: 2m 2s\tremaining: 2m 30s\n",
            "450:\tlearn: 142.6005544\ttotal: 2m 3s\tremaining: 2m 29s\n",
            "451:\tlearn: 142.6005544\ttotal: 2m 3s\tremaining: 2m 29s\n",
            "452:\tlearn: 142.6005544\ttotal: 2m 3s\tremaining: 2m 29s\n",
            "453:\tlearn: 142.6005544\ttotal: 2m 3s\tremaining: 2m 29s\n",
            "454:\tlearn: 142.6005544\ttotal: 2m 4s\tremaining: 2m 28s\n",
            "455:\tlearn: 142.6005544\ttotal: 2m 4s\tremaining: 2m 28s\n",
            "456:\tlearn: 142.6005544\ttotal: 2m 4s\tremaining: 2m 28s\n",
            "457:\tlearn: 142.6005544\ttotal: 2m 5s\tremaining: 2m 27s\n",
            "458:\tlearn: 142.6005544\ttotal: 2m 5s\tremaining: 2m 27s\n",
            "459:\tlearn: 142.6005544\ttotal: 2m 5s\tremaining: 2m 27s\n",
            "460:\tlearn: 142.6005544\ttotal: 2m 5s\tremaining: 2m 27s\n",
            "461:\tlearn: 142.6005544\ttotal: 2m 6s\tremaining: 2m 26s\n",
            "462:\tlearn: 142.6005544\ttotal: 2m 6s\tremaining: 2m 26s\n",
            "463:\tlearn: 142.6005544\ttotal: 2m 6s\tremaining: 2m 26s\n",
            "464:\tlearn: 142.6005544\ttotal: 2m 6s\tremaining: 2m 26s\n",
            "465:\tlearn: 142.6005544\ttotal: 2m 7s\tremaining: 2m 25s\n",
            "466:\tlearn: 142.6005544\ttotal: 2m 7s\tremaining: 2m 25s\n",
            "467:\tlearn: 142.6005544\ttotal: 2m 7s\tremaining: 2m 25s\n",
            "468:\tlearn: 142.6005544\ttotal: 2m 8s\tremaining: 2m 24s\n",
            "469:\tlearn: 142.6005544\ttotal: 2m 8s\tremaining: 2m 24s\n",
            "470:\tlearn: 142.6005544\ttotal: 2m 8s\tremaining: 2m 24s\n",
            "471:\tlearn: 142.6005544\ttotal: 2m 8s\tremaining: 2m 24s\n",
            "472:\tlearn: 142.6005544\ttotal: 2m 9s\tremaining: 2m 23s\n",
            "473:\tlearn: 142.6005544\ttotal: 2m 9s\tremaining: 2m 23s\n",
            "474:\tlearn: 142.6005544\ttotal: 2m 9s\tremaining: 2m 23s\n",
            "475:\tlearn: 142.6005544\ttotal: 2m 9s\tremaining: 2m 23s\n",
            "476:\tlearn: 142.6005267\ttotal: 2m 10s\tremaining: 2m 22s\n",
            "477:\tlearn: 142.6005041\ttotal: 2m 10s\tremaining: 2m 22s\n",
            "478:\tlearn: 142.6004852\ttotal: 2m 10s\tremaining: 2m 22s\n",
            "479:\tlearn: 142.6004685\ttotal: 2m 11s\tremaining: 2m 22s\n",
            "480:\tlearn: 142.6004550\ttotal: 2m 11s\tremaining: 2m 21s\n",
            "481:\tlearn: 142.6004440\ttotal: 2m 11s\tremaining: 2m 21s\n",
            "482:\tlearn: 142.6004346\ttotal: 2m 11s\tremaining: 2m 21s\n",
            "483:\tlearn: 142.6004265\ttotal: 2m 12s\tremaining: 2m 20s\n",
            "484:\tlearn: 142.6004203\ttotal: 2m 12s\tremaining: 2m 20s\n",
            "485:\tlearn: 142.6004151\ttotal: 2m 12s\tremaining: 2m 20s\n",
            "486:\tlearn: 142.6004109\ttotal: 2m 13s\tremaining: 2m 20s\n",
            "487:\tlearn: 142.6004074\ttotal: 2m 13s\tremaining: 2m 19s\n",
            "488:\tlearn: 142.6004045\ttotal: 2m 13s\tremaining: 2m 19s\n",
            "489:\tlearn: 142.6004024\ttotal: 2m 13s\tremaining: 2m 19s\n",
            "490:\tlearn: 142.6004005\ttotal: 2m 14s\tremaining: 2m 19s\n",
            "491:\tlearn: 142.6003991\ttotal: 2m 14s\tremaining: 2m 18s\n",
            "492:\tlearn: 142.6003978\ttotal: 2m 14s\tremaining: 2m 18s\n",
            "493:\tlearn: 142.6003967\ttotal: 2m 15s\tremaining: 2m 18s\n",
            "494:\tlearn: 142.6003958\ttotal: 2m 15s\tremaining: 2m 18s\n",
            "495:\tlearn: 142.6003950\ttotal: 2m 15s\tremaining: 2m 17s\n",
            "496:\tlearn: 142.6003945\ttotal: 2m 15s\tremaining: 2m 17s\n",
            "497:\tlearn: 142.6002166\ttotal: 2m 16s\tremaining: 2m 17s\n",
            "498:\tlearn: 142.5994362\ttotal: 2m 16s\tremaining: 2m 17s\n",
            "499:\tlearn: 142.5988314\ttotal: 2m 16s\tremaining: 2m 16s\n",
            "500:\tlearn: 142.5985686\ttotal: 2m 16s\tremaining: 2m 16s\n",
            "501:\tlearn: 142.5985241\ttotal: 2m 17s\tremaining: 2m 16s\n",
            "502:\tlearn: 142.5984906\ttotal: 2m 17s\tremaining: 2m 15s\n",
            "503:\tlearn: 142.5984632\ttotal: 2m 17s\tremaining: 2m 15s\n",
            "504:\tlearn: 142.5984414\ttotal: 2m 17s\tremaining: 2m 15s\n",
            "505:\tlearn: 142.5984225\ttotal: 2m 18s\tremaining: 2m 14s\n",
            "506:\tlearn: 142.5984083\ttotal: 2m 18s\tremaining: 2m 14s\n",
            "507:\tlearn: 142.5983971\ttotal: 2m 18s\tremaining: 2m 14s\n",
            "508:\tlearn: 142.5983877\ttotal: 2m 19s\tremaining: 2m 14s\n",
            "509:\tlearn: 142.5983849\ttotal: 2m 19s\tremaining: 2m 13s\n",
            "510:\tlearn: 142.5977565\ttotal: 2m 19s\tremaining: 2m 13s\n",
            "511:\tlearn: 142.5976396\ttotal: 2m 19s\tremaining: 2m 13s\n",
            "512:\tlearn: 142.5967789\ttotal: 2m 20s\tremaining: 2m 13s\n",
            "513:\tlearn: 142.5888440\ttotal: 2m 20s\tremaining: 2m 12s\n",
            "514:\tlearn: 142.5887916\ttotal: 2m 20s\tremaining: 2m 12s\n",
            "515:\tlearn: 142.5817675\ttotal: 2m 20s\tremaining: 2m 12s\n",
            "516:\tlearn: 142.5814118\ttotal: 2m 21s\tremaining: 2m 11s\n",
            "517:\tlearn: 142.5813025\ttotal: 2m 21s\tremaining: 2m 11s\n",
            "518:\tlearn: 142.5812729\ttotal: 2m 21s\tremaining: 2m 11s\n",
            "519:\tlearn: 142.5812509\ttotal: 2m 22s\tremaining: 2m 11s\n",
            "520:\tlearn: 142.5812335\ttotal: 2m 22s\tremaining: 2m 10s\n",
            "521:\tlearn: 142.5812188\ttotal: 2m 22s\tremaining: 2m 10s\n",
            "522:\tlearn: 142.5812081\ttotal: 2m 22s\tremaining: 2m 10s\n",
            "523:\tlearn: 142.5811277\ttotal: 2m 23s\tremaining: 2m 10s\n",
            "524:\tlearn: 142.5811160\ttotal: 2m 23s\tremaining: 2m 9s\n",
            "525:\tlearn: 142.5811066\ttotal: 2m 23s\tremaining: 2m 9s\n",
            "526:\tlearn: 142.5810281\ttotal: 2m 24s\tremaining: 2m 9s\n",
            "527:\tlearn: 142.5809660\ttotal: 2m 24s\tremaining: 2m 8s\n",
            "528:\tlearn: 142.5808827\ttotal: 2m 24s\tremaining: 2m 8s\n",
            "529:\tlearn: 142.5808824\ttotal: 2m 24s\tremaining: 2m 8s\n",
            "530:\tlearn: 142.5808660\ttotal: 2m 25s\tremaining: 2m 8s\n",
            "531:\tlearn: 142.5808528\ttotal: 2m 25s\tremaining: 2m 7s\n",
            "532:\tlearn: 142.5808320\ttotal: 2m 25s\tremaining: 2m 7s\n",
            "533:\tlearn: 142.5807731\ttotal: 2m 25s\tremaining: 2m 7s\n",
            "534:\tlearn: 142.5791621\ttotal: 2m 26s\tremaining: 2m 6s\n",
            "535:\tlearn: 142.5788837\ttotal: 2m 26s\tremaining: 2m 6s\n",
            "536:\tlearn: 142.5787675\ttotal: 2m 26s\tremaining: 2m 6s\n",
            "537:\tlearn: 142.5784954\ttotal: 2m 26s\tremaining: 2m 6s\n",
            "538:\tlearn: 142.5782718\ttotal: 2m 27s\tremaining: 2m 5s\n",
            "539:\tlearn: 142.5781618\ttotal: 2m 27s\tremaining: 2m 5s\n",
            "540:\tlearn: 142.5766385\ttotal: 2m 27s\tremaining: 2m 5s\n",
            "541:\tlearn: 142.5572074\ttotal: 2m 27s\tremaining: 2m 4s\n",
            "542:\tlearn: 142.5337142\ttotal: 2m 28s\tremaining: 2m 4s\n",
            "543:\tlearn: 142.5331292\ttotal: 2m 28s\tremaining: 2m 4s\n",
            "544:\tlearn: 142.5330247\ttotal: 2m 28s\tremaining: 2m 3s\n",
            "545:\tlearn: 142.5329762\ttotal: 2m 28s\tremaining: 2m 3s\n",
            "546:\tlearn: 142.5326879\ttotal: 2m 28s\tremaining: 2m 3s\n",
            "547:\tlearn: 142.5311516\ttotal: 2m 29s\tremaining: 2m 3s\n",
            "548:\tlearn: 142.5287530\ttotal: 2m 29s\tremaining: 2m 2s\n",
            "549:\tlearn: 142.5275822\ttotal: 2m 29s\tremaining: 2m 2s\n",
            "550:\tlearn: 142.5241223\ttotal: 2m 29s\tremaining: 2m 2s\n",
            "551:\tlearn: 142.5231023\ttotal: 2m 30s\tremaining: 2m 1s\n",
            "552:\tlearn: 142.5230046\ttotal: 2m 30s\tremaining: 2m 1s\n",
            "553:\tlearn: 142.5221634\ttotal: 2m 30s\tremaining: 2m 1s\n",
            "554:\tlearn: 142.4559976\ttotal: 2m 30s\tremaining: 2m\n",
            "555:\tlearn: 142.4555319\ttotal: 2m 30s\tremaining: 2m\n",
            "556:\tlearn: 142.4542594\ttotal: 2m 31s\tremaining: 2m\n",
            "557:\tlearn: 142.4541819\ttotal: 2m 31s\tremaining: 1m 59s\n",
            "558:\tlearn: 142.4530906\ttotal: 2m 31s\tremaining: 1m 59s\n",
            "559:\tlearn: 142.4526845\ttotal: 2m 31s\tremaining: 1m 59s\n",
            "560:\tlearn: 142.4521886\ttotal: 2m 32s\tremaining: 1m 59s\n",
            "561:\tlearn: 142.4516926\ttotal: 2m 32s\tremaining: 1m 58s\n",
            "562:\tlearn: 142.4514294\ttotal: 2m 32s\tremaining: 1m 58s\n",
            "563:\tlearn: 142.4512362\ttotal: 2m 32s\tremaining: 1m 58s\n",
            "564:\tlearn: 142.4511738\ttotal: 2m 33s\tremaining: 1m 57s\n",
            "565:\tlearn: 142.4509594\ttotal: 2m 33s\tremaining: 1m 57s\n",
            "566:\tlearn: 142.4508066\ttotal: 2m 33s\tremaining: 1m 57s\n",
            "567:\tlearn: 142.4507958\ttotal: 2m 33s\tremaining: 1m 56s\n",
            "568:\tlearn: 142.4507268\ttotal: 2m 34s\tremaining: 1m 56s\n",
            "569:\tlearn: 142.4503791\ttotal: 2m 34s\tremaining: 1m 56s\n",
            "570:\tlearn: 142.4498690\ttotal: 2m 34s\tremaining: 1m 56s\n",
            "571:\tlearn: 142.4498482\ttotal: 2m 34s\tremaining: 1m 55s\n",
            "572:\tlearn: 142.4479897\ttotal: 2m 35s\tremaining: 1m 55s\n",
            "573:\tlearn: 142.4458595\ttotal: 2m 35s\tremaining: 1m 55s\n",
            "574:\tlearn: 142.4441238\ttotal: 2m 35s\tremaining: 1m 54s\n",
            "575:\tlearn: 142.4276403\ttotal: 2m 35s\tremaining: 1m 54s\n",
            "576:\tlearn: 142.4260174\ttotal: 2m 35s\tremaining: 1m 54s\n",
            "577:\tlearn: 142.4026653\ttotal: 2m 36s\tremaining: 1m 54s\n",
            "578:\tlearn: 142.3991530\ttotal: 2m 36s\tremaining: 1m 53s\n",
            "579:\tlearn: 142.3926627\ttotal: 2m 36s\tremaining: 1m 53s\n",
            "580:\tlearn: 142.3775154\ttotal: 2m 36s\tremaining: 1m 53s\n",
            "581:\tlearn: 142.3775135\ttotal: 2m 37s\tremaining: 1m 52s\n",
            "582:\tlearn: 142.3775054\ttotal: 2m 37s\tremaining: 1m 52s\n",
            "583:\tlearn: 142.3750690\ttotal: 2m 37s\tremaining: 1m 52s\n",
            "584:\tlearn: 142.3750621\ttotal: 2m 37s\tremaining: 1m 51s\n",
            "585:\tlearn: 142.3731823\ttotal: 2m 38s\tremaining: 1m 51s\n",
            "586:\tlearn: 142.3730981\ttotal: 2m 38s\tremaining: 1m 51s\n",
            "587:\tlearn: 142.3728549\ttotal: 2m 38s\tremaining: 1m 51s\n",
            "588:\tlearn: 142.3724720\ttotal: 2m 38s\tremaining: 1m 50s\n",
            "589:\tlearn: 142.3716292\ttotal: 2m 38s\tremaining: 1m 50s\n",
            "590:\tlearn: 142.3703883\ttotal: 2m 39s\tremaining: 1m 50s\n",
            "591:\tlearn: 142.3701633\ttotal: 2m 39s\tremaining: 1m 49s\n",
            "592:\tlearn: 142.3698406\ttotal: 2m 39s\tremaining: 1m 49s\n",
            "593:\tlearn: 142.3566524\ttotal: 2m 39s\tremaining: 1m 49s\n",
            "594:\tlearn: 142.2434253\ttotal: 2m 40s\tremaining: 1m 49s\n",
            "595:\tlearn: 142.2234386\ttotal: 2m 40s\tremaining: 1m 48s\n",
            "596:\tlearn: 142.2229772\ttotal: 2m 40s\tremaining: 1m 48s\n",
            "597:\tlearn: 142.2229644\ttotal: 2m 40s\tremaining: 1m 48s\n",
            "598:\tlearn: 142.2229557\ttotal: 2m 41s\tremaining: 1m 47s\n",
            "599:\tlearn: 142.2160756\ttotal: 2m 41s\tremaining: 1m 47s\n",
            "600:\tlearn: 142.2159785\ttotal: 2m 41s\tremaining: 1m 47s\n",
            "601:\tlearn: 142.2148492\ttotal: 2m 41s\tremaining: 1m 46s\n",
            "602:\tlearn: 142.1969434\ttotal: 2m 42s\tremaining: 1m 46s\n",
            "603:\tlearn: 142.1965649\ttotal: 2m 42s\tremaining: 1m 46s\n",
            "604:\tlearn: 142.0382721\ttotal: 2m 42s\tremaining: 1m 46s\n",
            "605:\tlearn: 142.0381477\ttotal: 2m 42s\tremaining: 1m 45s\n",
            "606:\tlearn: 142.0380007\ttotal: 2m 42s\tremaining: 1m 45s\n",
            "607:\tlearn: 142.0379465\ttotal: 2m 43s\tremaining: 1m 45s\n",
            "608:\tlearn: 142.0377692\ttotal: 2m 43s\tremaining: 1m 44s\n",
            "609:\tlearn: 142.0376481\ttotal: 2m 43s\tremaining: 1m 44s\n",
            "610:\tlearn: 142.0376021\ttotal: 2m 43s\tremaining: 1m 44s\n",
            "611:\tlearn: 142.0375651\ttotal: 2m 44s\tremaining: 1m 44s\n",
            "612:\tlearn: 142.0375356\ttotal: 2m 44s\tremaining: 1m 43s\n",
            "613:\tlearn: 142.0375263\ttotal: 2m 44s\tremaining: 1m 43s\n",
            "614:\tlearn: 142.0372477\ttotal: 2m 44s\tremaining: 1m 43s\n",
            "615:\tlearn: 142.0365599\ttotal: 2m 45s\tremaining: 1m 42s\n",
            "616:\tlearn: 142.0365240\ttotal: 2m 45s\tremaining: 1m 42s\n",
            "617:\tlearn: 142.0364080\ttotal: 2m 45s\tremaining: 1m 42s\n",
            "618:\tlearn: 142.0356955\ttotal: 2m 45s\tremaining: 1m 42s\n",
            "619:\tlearn: 142.0247949\ttotal: 2m 46s\tremaining: 1m 41s\n",
            "620:\tlearn: 142.0097351\ttotal: 2m 46s\tremaining: 1m 41s\n",
            "621:\tlearn: 142.0086443\ttotal: 2m 46s\tremaining: 1m 41s\n",
            "622:\tlearn: 142.0058097\ttotal: 2m 46s\tremaining: 1m 40s\n",
            "623:\tlearn: 142.0040276\ttotal: 2m 47s\tremaining: 1m 40s\n",
            "624:\tlearn: 142.0035971\ttotal: 2m 47s\tremaining: 1m 40s\n",
            "625:\tlearn: 142.0035801\ttotal: 2m 47s\tremaining: 1m 40s\n",
            "626:\tlearn: 142.0010509\ttotal: 2m 48s\tremaining: 1m 39s\n",
            "627:\tlearn: 141.9898979\ttotal: 2m 48s\tremaining: 1m 39s\n",
            "628:\tlearn: 141.9898644\ttotal: 2m 48s\tremaining: 1m 39s\n",
            "629:\tlearn: 141.9897046\ttotal: 2m 48s\tremaining: 1m 39s\n",
            "630:\tlearn: 141.9894843\ttotal: 2m 49s\tremaining: 1m 38s\n",
            "631:\tlearn: 141.9892370\ttotal: 2m 49s\tremaining: 1m 38s\n",
            "632:\tlearn: 141.9891776\ttotal: 2m 49s\tremaining: 1m 38s\n",
            "633:\tlearn: 141.9887889\ttotal: 2m 49s\tremaining: 1m 38s\n",
            "634:\tlearn: 141.9886496\ttotal: 2m 50s\tremaining: 1m 37s\n",
            "635:\tlearn: 141.9884964\ttotal: 2m 50s\tremaining: 1m 37s\n",
            "636:\tlearn: 141.9884711\ttotal: 2m 50s\tremaining: 1m 37s\n",
            "637:\tlearn: 141.9884046\ttotal: 2m 50s\tremaining: 1m 36s\n",
            "638:\tlearn: 141.9883880\ttotal: 2m 51s\tremaining: 1m 36s\n",
            "639:\tlearn: 141.9883659\ttotal: 2m 51s\tremaining: 1m 36s\n",
            "640:\tlearn: 141.9881205\ttotal: 2m 51s\tremaining: 1m 36s\n",
            "641:\tlearn: 141.9876142\ttotal: 2m 51s\tremaining: 1m 35s\n",
            "642:\tlearn: 141.9875247\ttotal: 2m 52s\tremaining: 1m 35s\n",
            "643:\tlearn: 141.9874358\ttotal: 2m 52s\tremaining: 1m 35s\n",
            "644:\tlearn: 141.9871708\ttotal: 2m 52s\tremaining: 1m 34s\n",
            "645:\tlearn: 141.9868670\ttotal: 2m 52s\tremaining: 1m 34s\n",
            "646:\tlearn: 141.9855165\ttotal: 2m 53s\tremaining: 1m 34s\n",
            "647:\tlearn: 141.9850978\ttotal: 2m 53s\tremaining: 1m 34s\n",
            "648:\tlearn: 141.9630234\ttotal: 2m 53s\tremaining: 1m 33s\n",
            "649:\tlearn: 141.8498848\ttotal: 2m 53s\tremaining: 1m 33s\n",
            "650:\tlearn: 141.8493070\ttotal: 2m 53s\tremaining: 1m 33s\n",
            "651:\tlearn: 141.8491519\ttotal: 2m 54s\tremaining: 1m 32s\n",
            "652:\tlearn: 141.8488906\ttotal: 2m 54s\tremaining: 1m 32s\n",
            "653:\tlearn: 141.8488312\ttotal: 2m 54s\tremaining: 1m 32s\n",
            "654:\tlearn: 141.8487148\ttotal: 2m 54s\tremaining: 1m 32s\n",
            "655:\tlearn: 141.8473852\ttotal: 2m 55s\tremaining: 1m 31s\n",
            "656:\tlearn: 141.8473530\ttotal: 2m 55s\tremaining: 1m 31s\n",
            "657:\tlearn: 141.8462333\ttotal: 2m 55s\tremaining: 1m 31s\n",
            "658:\tlearn: 141.8461138\ttotal: 2m 55s\tremaining: 1m 31s\n",
            "659:\tlearn: 141.8460348\ttotal: 2m 56s\tremaining: 1m 30s\n",
            "660:\tlearn: 141.8459604\ttotal: 2m 56s\tremaining: 1m 30s\n",
            "661:\tlearn: 141.8458964\ttotal: 2m 56s\tremaining: 1m 30s\n",
            "662:\tlearn: 141.8458081\ttotal: 2m 56s\tremaining: 1m 29s\n",
            "663:\tlearn: 141.8457782\ttotal: 2m 57s\tremaining: 1m 29s\n",
            "664:\tlearn: 141.8457746\ttotal: 2m 57s\tremaining: 1m 29s\n",
            "665:\tlearn: 141.8457579\ttotal: 2m 57s\tremaining: 1m 29s\n",
            "666:\tlearn: 141.8456537\ttotal: 2m 57s\tremaining: 1m 28s\n",
            "667:\tlearn: 141.8456399\ttotal: 2m 58s\tremaining: 1m 28s\n",
            "668:\tlearn: 141.8456216\ttotal: 2m 58s\tremaining: 1m 28s\n",
            "669:\tlearn: 141.8456078\ttotal: 2m 58s\tremaining: 1m 27s\n",
            "670:\tlearn: 141.8456011\ttotal: 2m 58s\tremaining: 1m 27s\n",
            "671:\tlearn: 141.8455906\ttotal: 2m 58s\tremaining: 1m 27s\n",
            "672:\tlearn: 141.8455892\ttotal: 2m 59s\tremaining: 1m 27s\n",
            "673:\tlearn: 141.8455684\ttotal: 2m 59s\tremaining: 1m 26s\n",
            "674:\tlearn: 141.8455644\ttotal: 2m 59s\tremaining: 1m 26s\n",
            "675:\tlearn: 141.8455076\ttotal: 2m 59s\tremaining: 1m 26s\n",
            "676:\tlearn: 141.8455067\ttotal: 3m\tremaining: 1m 25s\n",
            "677:\tlearn: 141.8455024\ttotal: 3m\tremaining: 1m 25s\n",
            "678:\tlearn: 141.8454951\ttotal: 3m\tremaining: 1m 25s\n",
            "679:\tlearn: 141.8454495\ttotal: 3m\tremaining: 1m 25s\n",
            "680:\tlearn: 141.8454462\ttotal: 3m 1s\tremaining: 1m 24s\n",
            "681:\tlearn: 141.8454091\ttotal: 3m 1s\tremaining: 1m 24s\n",
            "682:\tlearn: 141.8454000\ttotal: 3m 1s\tremaining: 1m 24s\n",
            "683:\tlearn: 141.8453911\ttotal: 3m 1s\tremaining: 1m 23s\n",
            "684:\tlearn: 141.8453837\ttotal: 3m 2s\tremaining: 1m 23s\n",
            "685:\tlearn: 141.8452851\ttotal: 3m 2s\tremaining: 1m 23s\n",
            "686:\tlearn: 141.8452014\ttotal: 3m 2s\tremaining: 1m 23s\n",
            "687:\tlearn: 141.8451652\ttotal: 3m 2s\tremaining: 1m 22s\n",
            "688:\tlearn: 141.8451635\ttotal: 3m 2s\tremaining: 1m 22s\n",
            "689:\tlearn: 141.8451607\ttotal: 3m 3s\tremaining: 1m 22s\n",
            "690:\tlearn: 141.8451602\ttotal: 3m 3s\tremaining: 1m 22s\n",
            "691:\tlearn: 141.8451558\ttotal: 3m 3s\tremaining: 1m 21s\n",
            "692:\tlearn: 141.8451513\ttotal: 3m 3s\tremaining: 1m 21s\n",
            "693:\tlearn: 141.8451483\ttotal: 3m 4s\tremaining: 1m 21s\n",
            "694:\tlearn: 141.8451433\ttotal: 3m 4s\tremaining: 1m 20s\n",
            "695:\tlearn: 141.8450549\ttotal: 3m 4s\tremaining: 1m 20s\n",
            "696:\tlearn: 141.8450494\ttotal: 3m 4s\tremaining: 1m 20s\n",
            "697:\tlearn: 141.8450447\ttotal: 3m 5s\tremaining: 1m 20s\n",
            "698:\tlearn: 141.8450420\ttotal: 3m 5s\tremaining: 1m 19s\n",
            "699:\tlearn: 141.8448825\ttotal: 3m 5s\tremaining: 1m 19s\n",
            "700:\tlearn: 141.8447470\ttotal: 3m 5s\tremaining: 1m 19s\n",
            "701:\tlearn: 141.8442850\ttotal: 3m 6s\tremaining: 1m 18s\n",
            "702:\tlearn: 141.8437991\ttotal: 3m 6s\tremaining: 1m 18s\n",
            "703:\tlearn: 141.8392488\ttotal: 3m 6s\tremaining: 1m 18s\n",
            "704:\tlearn: 141.8389652\ttotal: 3m 6s\tremaining: 1m 18s\n",
            "705:\tlearn: 141.8374948\ttotal: 3m 7s\tremaining: 1m 17s\n",
            "706:\tlearn: 141.8343243\ttotal: 3m 7s\tremaining: 1m 17s\n",
            "707:\tlearn: 141.8312593\ttotal: 3m 7s\tremaining: 1m 17s\n",
            "708:\tlearn: 141.8122570\ttotal: 3m 7s\tremaining: 1m 17s\n",
            "709:\tlearn: 141.8122418\ttotal: 3m 8s\tremaining: 1m 16s\n",
            "710:\tlearn: 141.7574255\ttotal: 3m 8s\tremaining: 1m 16s\n",
            "711:\tlearn: 141.7571954\ttotal: 3m 8s\tremaining: 1m 16s\n",
            "712:\tlearn: 141.7571872\ttotal: 3m 8s\tremaining: 1m 16s\n",
            "713:\tlearn: 141.7565414\ttotal: 3m 9s\tremaining: 1m 15s\n",
            "714:\tlearn: 141.7565046\ttotal: 3m 9s\tremaining: 1m 15s\n",
            "715:\tlearn: 141.7564698\ttotal: 3m 9s\tremaining: 1m 15s\n",
            "716:\tlearn: 141.7564255\ttotal: 3m 9s\tremaining: 1m 14s\n",
            "717:\tlearn: 141.7564200\ttotal: 3m 10s\tremaining: 1m 14s\n",
            "718:\tlearn: 141.7561185\ttotal: 3m 10s\tremaining: 1m 14s\n",
            "719:\tlearn: 141.7558690\ttotal: 3m 10s\tremaining: 1m 14s\n",
            "720:\tlearn: 141.7558600\ttotal: 3m 10s\tremaining: 1m 13s\n",
            "721:\tlearn: 141.7553555\ttotal: 3m 11s\tremaining: 1m 13s\n",
            "722:\tlearn: 141.7553177\ttotal: 3m 11s\tremaining: 1m 13s\n",
            "723:\tlearn: 141.7552731\ttotal: 3m 11s\tremaining: 1m 13s\n",
            "724:\tlearn: 141.7552725\ttotal: 3m 11s\tremaining: 1m 12s\n",
            "725:\tlearn: 141.7549533\ttotal: 3m 12s\tremaining: 1m 12s\n",
            "726:\tlearn: 141.7095282\ttotal: 3m 12s\tremaining: 1m 12s\n",
            "727:\tlearn: 141.7086523\ttotal: 3m 12s\tremaining: 1m 11s\n",
            "728:\tlearn: 141.7086417\ttotal: 3m 12s\tremaining: 1m 11s\n",
            "729:\tlearn: 141.7086390\ttotal: 3m 13s\tremaining: 1m 11s\n",
            "730:\tlearn: 141.7086376\ttotal: 3m 13s\tremaining: 1m 11s\n",
            "731:\tlearn: 141.7086368\ttotal: 3m 13s\tremaining: 1m 10s\n",
            "732:\tlearn: 141.7086341\ttotal: 3m 14s\tremaining: 1m 10s\n",
            "733:\tlearn: 141.7085994\ttotal: 3m 14s\tremaining: 1m 10s\n",
            "734:\tlearn: 141.7078703\ttotal: 3m 14s\tremaining: 1m 10s\n",
            "735:\tlearn: 141.7062924\ttotal: 3m 14s\tremaining: 1m 9s\n",
            "736:\tlearn: 141.7062884\ttotal: 3m 15s\tremaining: 1m 9s\n",
            "737:\tlearn: 141.7062882\ttotal: 3m 15s\tremaining: 1m 9s\n",
            "738:\tlearn: 141.7050685\ttotal: 3m 15s\tremaining: 1m 9s\n",
            "739:\tlearn: 141.7034379\ttotal: 3m 15s\tremaining: 1m 8s\n",
            "740:\tlearn: 141.7032807\ttotal: 3m 15s\tremaining: 1m 8s\n",
            "741:\tlearn: 141.7030392\ttotal: 3m 16s\tremaining: 1m 8s\n",
            "742:\tlearn: 141.7025862\ttotal: 3m 16s\tremaining: 1m 7s\n",
            "743:\tlearn: 141.7023412\ttotal: 3m 16s\tremaining: 1m 7s\n",
            "744:\tlearn: 141.7022325\ttotal: 3m 16s\tremaining: 1m 7s\n",
            "745:\tlearn: 141.6987466\ttotal: 3m 17s\tremaining: 1m 7s\n",
            "746:\tlearn: 141.6985364\ttotal: 3m 17s\tremaining: 1m 6s\n",
            "747:\tlearn: 141.6983516\ttotal: 3m 17s\tremaining: 1m 6s\n",
            "748:\tlearn: 141.6970999\ttotal: 3m 17s\tremaining: 1m 6s\n",
            "749:\tlearn: 141.6969559\ttotal: 3m 18s\tremaining: 1m 6s\n",
            "750:\tlearn: 141.6968399\ttotal: 3m 18s\tremaining: 1m 5s\n",
            "751:\tlearn: 141.6967662\ttotal: 3m 18s\tremaining: 1m 5s\n",
            "752:\tlearn: 141.6967563\ttotal: 3m 18s\tremaining: 1m 5s\n",
            "753:\tlearn: 141.6963518\ttotal: 3m 18s\tremaining: 1m 4s\n",
            "754:\tlearn: 141.6958927\ttotal: 3m 19s\tremaining: 1m 4s\n",
            "755:\tlearn: 141.6955860\ttotal: 3m 19s\tremaining: 1m 4s\n",
            "756:\tlearn: 141.6953020\ttotal: 3m 19s\tremaining: 1m 4s\n",
            "757:\tlearn: 141.6952989\ttotal: 3m 19s\tremaining: 1m 3s\n",
            "758:\tlearn: 141.6951128\ttotal: 3m 20s\tremaining: 1m 3s\n",
            "759:\tlearn: 141.6945773\ttotal: 3m 20s\tremaining: 1m 3s\n",
            "760:\tlearn: 141.6945430\ttotal: 3m 20s\tremaining: 1m 3s\n",
            "761:\tlearn: 141.6943771\ttotal: 3m 20s\tremaining: 1m 2s\n",
            "762:\tlearn: 141.6943318\ttotal: 3m 21s\tremaining: 1m 2s\n",
            "763:\tlearn: 141.6943185\ttotal: 3m 21s\tremaining: 1m 2s\n",
            "764:\tlearn: 141.6943005\ttotal: 3m 21s\tremaining: 1m 1s\n",
            "765:\tlearn: 141.5295490\ttotal: 3m 21s\tremaining: 1m 1s\n",
            "766:\tlearn: 141.5174945\ttotal: 3m 22s\tremaining: 1m 1s\n",
            "767:\tlearn: 141.5165703\ttotal: 3m 22s\tremaining: 1m 1s\n",
            "768:\tlearn: 141.5135658\ttotal: 3m 22s\tremaining: 1m\n",
            "769:\tlearn: 141.5133215\ttotal: 3m 22s\tremaining: 1m\n",
            "770:\tlearn: 141.5109859\ttotal: 3m 23s\tremaining: 1m\n",
            "771:\tlearn: 141.5108970\ttotal: 3m 23s\tremaining: 1m\n",
            "772:\tlearn: 141.5108421\ttotal: 3m 23s\tremaining: 59.8s\n",
            "773:\tlearn: 141.5062588\ttotal: 3m 23s\tremaining: 59.5s\n",
            "774:\tlearn: 141.5062277\ttotal: 3m 24s\tremaining: 59.2s\n",
            "775:\tlearn: 141.5060654\ttotal: 3m 24s\tremaining: 59s\n",
            "776:\tlearn: 141.5045098\ttotal: 3m 24s\tremaining: 58.7s\n",
            "777:\tlearn: 141.5000782\ttotal: 3m 24s\tremaining: 58.4s\n",
            "778:\tlearn: 141.4941337\ttotal: 3m 24s\tremaining: 58.1s\n",
            "779:\tlearn: 141.4939940\ttotal: 3m 25s\tremaining: 57.9s\n",
            "780:\tlearn: 141.4908921\ttotal: 3m 25s\tremaining: 57.6s\n",
            "781:\tlearn: 141.4826381\ttotal: 3m 25s\tremaining: 57.3s\n",
            "782:\tlearn: 141.4742460\ttotal: 3m 25s\tremaining: 57.1s\n",
            "783:\tlearn: 141.4740172\ttotal: 3m 26s\tremaining: 56.8s\n",
            "784:\tlearn: 141.4736699\ttotal: 3m 26s\tremaining: 56.5s\n",
            "785:\tlearn: 141.4650980\ttotal: 3m 26s\tremaining: 56.3s\n",
            "786:\tlearn: 141.4570768\ttotal: 3m 26s\tremaining: 56s\n",
            "787:\tlearn: 141.4567742\ttotal: 3m 27s\tremaining: 55.7s\n",
            "788:\tlearn: 141.4561371\ttotal: 3m 27s\tremaining: 55.4s\n",
            "789:\tlearn: 141.4558791\ttotal: 3m 27s\tremaining: 55.2s\n",
            "790:\tlearn: 141.4551426\ttotal: 3m 27s\tremaining: 54.9s\n",
            "791:\tlearn: 141.4551321\ttotal: 3m 28s\tremaining: 54.6s\n",
            "792:\tlearn: 141.4548645\ttotal: 3m 28s\tremaining: 54.4s\n",
            "793:\tlearn: 141.4548524\ttotal: 3m 28s\tremaining: 54.1s\n",
            "794:\tlearn: 141.4548061\ttotal: 3m 28s\tremaining: 53.8s\n",
            "795:\tlearn: 141.4544182\ttotal: 3m 29s\tremaining: 53.6s\n",
            "796:\tlearn: 141.4544106\ttotal: 3m 29s\tremaining: 53.3s\n",
            "797:\tlearn: 141.4543988\ttotal: 3m 29s\tremaining: 53s\n",
            "798:\tlearn: 141.4543614\ttotal: 3m 29s\tremaining: 52.8s\n",
            "799:\tlearn: 141.4538750\ttotal: 3m 30s\tremaining: 52.5s\n",
            "800:\tlearn: 141.4536817\ttotal: 3m 30s\tremaining: 52.2s\n",
            "801:\tlearn: 141.4536306\ttotal: 3m 30s\tremaining: 52s\n",
            "802:\tlearn: 141.4535654\ttotal: 3m 30s\tremaining: 51.7s\n",
            "803:\tlearn: 141.4525934\ttotal: 3m 31s\tremaining: 51.4s\n",
            "804:\tlearn: 141.4426373\ttotal: 3m 31s\tremaining: 51.2s\n",
            "805:\tlearn: 141.4416233\ttotal: 3m 31s\tremaining: 50.9s\n",
            "806:\tlearn: 141.4376800\ttotal: 3m 31s\tremaining: 50.6s\n",
            "807:\tlearn: 141.4337437\ttotal: 3m 31s\tremaining: 50.4s\n",
            "808:\tlearn: 141.4336303\ttotal: 3m 32s\tremaining: 50.1s\n",
            "809:\tlearn: 141.4330721\ttotal: 3m 32s\tremaining: 49.8s\n",
            "810:\tlearn: 141.4329605\ttotal: 3m 32s\tremaining: 49.6s\n",
            "811:\tlearn: 141.4329326\ttotal: 3m 32s\tremaining: 49.3s\n",
            "812:\tlearn: 141.4320489\ttotal: 3m 33s\tremaining: 49s\n",
            "813:\tlearn: 141.4318175\ttotal: 3m 33s\tremaining: 48.7s\n",
            "814:\tlearn: 141.4300693\ttotal: 3m 33s\tremaining: 48.5s\n",
            "815:\tlearn: 141.4300524\ttotal: 3m 33s\tremaining: 48.2s\n",
            "816:\tlearn: 141.4299239\ttotal: 3m 34s\tremaining: 48s\n",
            "817:\tlearn: 141.4283105\ttotal: 3m 34s\tremaining: 47.7s\n",
            "818:\tlearn: 141.4281172\ttotal: 3m 34s\tremaining: 47.4s\n",
            "819:\tlearn: 141.4281117\ttotal: 3m 34s\tremaining: 47.2s\n",
            "820:\tlearn: 141.4280972\ttotal: 3m 35s\tremaining: 46.9s\n",
            "821:\tlearn: 141.4280941\ttotal: 3m 35s\tremaining: 46.6s\n",
            "822:\tlearn: 141.4280913\ttotal: 3m 35s\tremaining: 46.4s\n",
            "823:\tlearn: 141.4280860\ttotal: 3m 35s\tremaining: 46.1s\n",
            "824:\tlearn: 141.4280597\ttotal: 3m 36s\tremaining: 45.8s\n",
            "825:\tlearn: 141.4280447\ttotal: 3m 36s\tremaining: 45.6s\n",
            "826:\tlearn: 141.4280333\ttotal: 3m 36s\tremaining: 45.3s\n",
            "827:\tlearn: 141.4279416\ttotal: 3m 36s\tremaining: 45s\n",
            "828:\tlearn: 141.4279350\ttotal: 3m 37s\tremaining: 44.8s\n",
            "829:\tlearn: 141.4277821\ttotal: 3m 37s\tremaining: 44.5s\n",
            "830:\tlearn: 141.4276468\ttotal: 3m 37s\tremaining: 44.2s\n",
            "831:\tlearn: 141.4276064\ttotal: 3m 37s\tremaining: 44s\n",
            "832:\tlearn: 141.4274175\ttotal: 3m 37s\tremaining: 43.7s\n",
            "833:\tlearn: 141.4271768\ttotal: 3m 38s\tremaining: 43.4s\n",
            "834:\tlearn: 141.4247891\ttotal: 3m 38s\tremaining: 43.2s\n",
            "835:\tlearn: 141.4245675\ttotal: 3m 38s\tremaining: 42.9s\n",
            "836:\tlearn: 141.4239864\ttotal: 3m 38s\tremaining: 42.6s\n",
            "837:\tlearn: 141.4239390\ttotal: 3m 39s\tremaining: 42.4s\n",
            "838:\tlearn: 141.3729829\ttotal: 3m 39s\tremaining: 42.1s\n",
            "839:\tlearn: 141.3726990\ttotal: 3m 39s\tremaining: 41.8s\n",
            "840:\tlearn: 141.3714208\ttotal: 3m 39s\tremaining: 41.6s\n",
            "841:\tlearn: 141.3710619\ttotal: 3m 40s\tremaining: 41.3s\n",
            "842:\tlearn: 141.3710074\ttotal: 3m 40s\tremaining: 41s\n",
            "843:\tlearn: 141.3709703\ttotal: 3m 40s\tremaining: 40.8s\n",
            "844:\tlearn: 141.3709244\ttotal: 3m 40s\tremaining: 40.5s\n",
            "845:\tlearn: 141.1635312\ttotal: 3m 41s\tremaining: 40.3s\n",
            "846:\tlearn: 141.1630187\ttotal: 3m 41s\tremaining: 40s\n",
            "847:\tlearn: 141.1621708\ttotal: 3m 41s\tremaining: 39.7s\n",
            "848:\tlearn: 141.1619656\ttotal: 3m 41s\tremaining: 39.5s\n",
            "849:\tlearn: 141.1618340\ttotal: 3m 42s\tremaining: 39.2s\n",
            "850:\tlearn: 141.1617636\ttotal: 3m 42s\tremaining: 39s\n",
            "851:\tlearn: 141.1613678\ttotal: 3m 42s\tremaining: 38.7s\n",
            "852:\tlearn: 141.1613185\ttotal: 3m 42s\tremaining: 38.4s\n",
            "853:\tlearn: 141.1610568\ttotal: 3m 43s\tremaining: 38.2s\n",
            "854:\tlearn: 141.1607434\ttotal: 3m 43s\tremaining: 37.9s\n",
            "855:\tlearn: 141.1607339\ttotal: 3m 43s\tremaining: 37.6s\n",
            "856:\tlearn: 141.1606920\ttotal: 3m 44s\tremaining: 37.4s\n",
            "857:\tlearn: 141.1568135\ttotal: 3m 44s\tremaining: 37.1s\n",
            "858:\tlearn: 141.1568056\ttotal: 3m 44s\tremaining: 36.9s\n",
            "859:\tlearn: 141.1567961\ttotal: 3m 44s\tremaining: 36.6s\n",
            "860:\tlearn: 141.1195398\ttotal: 3m 45s\tremaining: 36.3s\n",
            "861:\tlearn: 141.1194947\ttotal: 3m 45s\tremaining: 36.1s\n",
            "862:\tlearn: 141.1194492\ttotal: 3m 45s\tremaining: 35.8s\n",
            "863:\tlearn: 141.1193348\ttotal: 3m 45s\tremaining: 35.6s\n",
            "864:\tlearn: 141.1193126\ttotal: 3m 46s\tremaining: 35.3s\n",
            "865:\tlearn: 141.1192791\ttotal: 3m 46s\tremaining: 35.1s\n",
            "866:\tlearn: 141.1192332\ttotal: 3m 47s\tremaining: 34.8s\n",
            "867:\tlearn: 141.1181918\ttotal: 3m 47s\tremaining: 34.6s\n",
            "868:\tlearn: 141.1181309\ttotal: 3m 47s\tremaining: 34.3s\n",
            "869:\tlearn: 141.1180980\ttotal: 3m 47s\tremaining: 34s\n",
            "870:\tlearn: 141.1179271\ttotal: 3m 48s\tremaining: 33.8s\n",
            "871:\tlearn: 141.1179124\ttotal: 3m 48s\tremaining: 33.5s\n",
            "872:\tlearn: 141.1176737\ttotal: 3m 48s\tremaining: 33.3s\n",
            "873:\tlearn: 141.1175433\ttotal: 3m 48s\tremaining: 33s\n",
            "874:\tlearn: 141.1174987\ttotal: 3m 49s\tremaining: 32.7s\n",
            "875:\tlearn: 141.1172547\ttotal: 3m 49s\tremaining: 32.5s\n",
            "876:\tlearn: 141.1172419\ttotal: 3m 49s\tremaining: 32.2s\n",
            "877:\tlearn: 141.1172391\ttotal: 3m 49s\tremaining: 31.9s\n",
            "878:\tlearn: 141.1163510\ttotal: 3m 49s\tremaining: 31.7s\n",
            "879:\tlearn: 141.1162966\ttotal: 3m 50s\tremaining: 31.4s\n",
            "880:\tlearn: 141.1162884\ttotal: 3m 50s\tremaining: 31.1s\n",
            "881:\tlearn: 141.1162820\ttotal: 3m 50s\tremaining: 30.9s\n",
            "882:\tlearn: 141.1162801\ttotal: 3m 50s\tremaining: 30.6s\n",
            "883:\tlearn: 141.1162756\ttotal: 3m 51s\tremaining: 30.3s\n",
            "884:\tlearn: 141.1162734\ttotal: 3m 51s\tremaining: 30.1s\n",
            "885:\tlearn: 141.1162688\ttotal: 3m 51s\tremaining: 29.8s\n",
            "886:\tlearn: 141.1162671\ttotal: 3m 51s\tremaining: 29.5s\n",
            "887:\tlearn: 141.1162546\ttotal: 3m 52s\tremaining: 29.3s\n",
            "888:\tlearn: 141.1150126\ttotal: 3m 52s\tremaining: 29s\n",
            "889:\tlearn: 141.1150017\ttotal: 3m 52s\tremaining: 28.7s\n",
            "890:\tlearn: 141.1150006\ttotal: 3m 52s\tremaining: 28.5s\n",
            "891:\tlearn: 141.1145268\ttotal: 3m 53s\tremaining: 28.2s\n",
            "892:\tlearn: 141.1125965\ttotal: 3m 53s\tremaining: 28s\n",
            "893:\tlearn: 141.1125925\ttotal: 3m 53s\tremaining: 27.7s\n",
            "894:\tlearn: 141.1125800\ttotal: 3m 53s\tremaining: 27.4s\n",
            "895:\tlearn: 141.1125698\ttotal: 3m 54s\tremaining: 27.2s\n",
            "896:\tlearn: 141.1124597\ttotal: 3m 54s\tremaining: 26.9s\n",
            "897:\tlearn: 141.1123657\ttotal: 3m 54s\tremaining: 26.6s\n",
            "898:\tlearn: 141.1123526\ttotal: 3m 54s\tremaining: 26.4s\n",
            "899:\tlearn: 141.1116714\ttotal: 3m 55s\tremaining: 26.1s\n",
            "900:\tlearn: 141.1115557\ttotal: 3m 55s\tremaining: 25.9s\n",
            "901:\tlearn: 141.1114720\ttotal: 3m 55s\tremaining: 25.6s\n",
            "902:\tlearn: 141.1114059\ttotal: 3m 55s\tremaining: 25.3s\n",
            "903:\tlearn: 141.1113790\ttotal: 3m 56s\tremaining: 25.1s\n",
            "904:\tlearn: 141.1113474\ttotal: 3m 56s\tremaining: 24.8s\n",
            "905:\tlearn: 141.1113206\ttotal: 3m 56s\tremaining: 24.5s\n",
            "906:\tlearn: 141.1110859\ttotal: 3m 56s\tremaining: 24.3s\n",
            "907:\tlearn: 141.1109543\ttotal: 3m 57s\tremaining: 24s\n",
            "908:\tlearn: 141.1109507\ttotal: 3m 57s\tremaining: 23.8s\n",
            "909:\tlearn: 141.1102928\ttotal: 3m 57s\tremaining: 23.5s\n",
            "910:\tlearn: 141.1099272\ttotal: 3m 57s\tremaining: 23.2s\n",
            "911:\tlearn: 141.1098781\ttotal: 3m 58s\tremaining: 23s\n",
            "912:\tlearn: 141.1098499\ttotal: 3m 58s\tremaining: 22.7s\n",
            "913:\tlearn: 141.1098352\ttotal: 3m 58s\tremaining: 22.4s\n",
            "914:\tlearn: 141.1096563\ttotal: 3m 58s\tremaining: 22.2s\n",
            "915:\tlearn: 141.1094947\ttotal: 3m 58s\tremaining: 21.9s\n",
            "916:\tlearn: 141.1094809\ttotal: 3m 59s\tremaining: 21.7s\n",
            "917:\tlearn: 141.1094626\ttotal: 3m 59s\tremaining: 21.4s\n",
            "918:\tlearn: 141.1094594\ttotal: 3m 59s\tremaining: 21.1s\n",
            "919:\tlearn: 141.1094482\ttotal: 3m 59s\tremaining: 20.9s\n",
            "920:\tlearn: 141.1094220\ttotal: 4m\tremaining: 20.6s\n",
            "921:\tlearn: 141.1094161\ttotal: 4m\tremaining: 20.3s\n",
            "922:\tlearn: 141.1093924\ttotal: 4m\tremaining: 20.1s\n",
            "923:\tlearn: 141.1093727\ttotal: 4m\tremaining: 19.8s\n",
            "924:\tlearn: 141.1093705\ttotal: 4m 1s\tremaining: 19.5s\n",
            "925:\tlearn: 141.1093664\ttotal: 4m 1s\tremaining: 19.3s\n",
            "926:\tlearn: 141.1093567\ttotal: 4m 1s\tremaining: 19s\n",
            "927:\tlearn: 141.1090928\ttotal: 4m 1s\tremaining: 18.8s\n",
            "928:\tlearn: 141.1090907\ttotal: 4m 2s\tremaining: 18.5s\n",
            "929:\tlearn: 141.1090870\ttotal: 4m 2s\tremaining: 18.2s\n",
            "930:\tlearn: 141.1090819\ttotal: 4m 2s\tremaining: 18s\n",
            "931:\tlearn: 141.1090614\ttotal: 4m 2s\tremaining: 17.7s\n",
            "932:\tlearn: 141.1090598\ttotal: 4m 2s\tremaining: 17.4s\n",
            "933:\tlearn: 141.1090591\ttotal: 4m 3s\tremaining: 17.2s\n",
            "934:\tlearn: 141.1090564\ttotal: 4m 3s\tremaining: 16.9s\n",
            "935:\tlearn: 141.1090554\ttotal: 4m 3s\tremaining: 16.7s\n",
            "936:\tlearn: 141.1090264\ttotal: 4m 3s\tremaining: 16.4s\n",
            "937:\tlearn: 141.1090055\ttotal: 4m 4s\tremaining: 16.1s\n",
            "938:\tlearn: 141.1089920\ttotal: 4m 4s\tremaining: 15.9s\n",
            "939:\tlearn: 141.1089894\ttotal: 4m 4s\tremaining: 15.6s\n",
            "940:\tlearn: 141.1089893\ttotal: 4m 4s\tremaining: 15.3s\n",
            "941:\tlearn: 141.1089860\ttotal: 4m 4s\tremaining: 15.1s\n",
            "942:\tlearn: 141.1089853\ttotal: 4m 5s\tremaining: 14.8s\n",
            "943:\tlearn: 141.1089847\ttotal: 4m 5s\tremaining: 14.6s\n",
            "944:\tlearn: 141.1089811\ttotal: 4m 5s\tremaining: 14.3s\n",
            "945:\tlearn: 141.1088101\ttotal: 4m 5s\tremaining: 14s\n",
            "946:\tlearn: 141.1086233\ttotal: 4m 6s\tremaining: 13.8s\n",
            "947:\tlearn: 141.1086013\ttotal: 4m 6s\tremaining: 13.5s\n",
            "948:\tlearn: 141.1086003\ttotal: 4m 6s\tremaining: 13.3s\n",
            "949:\tlearn: 141.1086003\ttotal: 4m 6s\tremaining: 13s\n",
            "950:\tlearn: 141.1086002\ttotal: 4m 7s\tremaining: 12.7s\n",
            "951:\tlearn: 141.1085996\ttotal: 4m 7s\tremaining: 12.5s\n",
            "952:\tlearn: 141.1085969\ttotal: 4m 7s\tremaining: 12.2s\n",
            "953:\tlearn: 141.1085967\ttotal: 4m 7s\tremaining: 12s\n",
            "954:\tlearn: 141.1085960\ttotal: 4m 8s\tremaining: 11.7s\n",
            "955:\tlearn: 141.1085959\ttotal: 4m 8s\tremaining: 11.4s\n",
            "956:\tlearn: 141.1082048\ttotal: 4m 8s\tremaining: 11.2s\n",
            "957:\tlearn: 141.1082046\ttotal: 4m 8s\tremaining: 10.9s\n",
            "958:\tlearn: 141.1082043\ttotal: 4m 9s\tremaining: 10.7s\n",
            "959:\tlearn: 141.1082037\ttotal: 4m 9s\tremaining: 10.4s\n",
            "960:\tlearn: 141.1082033\ttotal: 4m 9s\tremaining: 10.1s\n",
            "961:\tlearn: 141.1080080\ttotal: 4m 9s\tremaining: 9.87s\n",
            "962:\tlearn: 141.1080076\ttotal: 4m 10s\tremaining: 9.61s\n",
            "963:\tlearn: 141.1080075\ttotal: 4m 10s\tremaining: 9.35s\n",
            "964:\tlearn: 141.1079825\ttotal: 4m 10s\tremaining: 9.09s\n",
            "965:\tlearn: 141.1079825\ttotal: 4m 10s\tremaining: 8.83s\n",
            "966:\tlearn: 141.1079824\ttotal: 4m 11s\tremaining: 8.57s\n",
            "967:\tlearn: 141.1079823\ttotal: 4m 11s\tremaining: 8.31s\n",
            "968:\tlearn: 141.1077986\ttotal: 4m 11s\tremaining: 8.05s\n",
            "969:\tlearn: 141.1077979\ttotal: 4m 11s\tremaining: 7.79s\n",
            "970:\tlearn: 141.1076994\ttotal: 4m 12s\tremaining: 7.53s\n",
            "971:\tlearn: 141.1076989\ttotal: 4m 12s\tremaining: 7.27s\n",
            "972:\tlearn: 141.1073788\ttotal: 4m 12s\tremaining: 7.01s\n",
            "973:\tlearn: 141.1068541\ttotal: 4m 12s\tremaining: 6.75s\n",
            "974:\tlearn: 141.1068519\ttotal: 4m 13s\tremaining: 6.49s\n",
            "975:\tlearn: 141.0457476\ttotal: 4m 13s\tremaining: 6.23s\n",
            "976:\tlearn: 141.0456567\ttotal: 4m 13s\tremaining: 5.97s\n",
            "977:\tlearn: 141.0456180\ttotal: 4m 13s\tremaining: 5.71s\n",
            "978:\tlearn: 141.0422031\ttotal: 4m 13s\tremaining: 5.45s\n",
            "979:\tlearn: 141.0421514\ttotal: 4m 14s\tremaining: 5.19s\n",
            "980:\tlearn: 141.0421002\ttotal: 4m 14s\tremaining: 4.93s\n",
            "981:\tlearn: 141.0419565\ttotal: 4m 14s\tremaining: 4.67s\n",
            "982:\tlearn: 141.0416264\ttotal: 4m 14s\tremaining: 4.41s\n",
            "983:\tlearn: 141.0415187\ttotal: 4m 15s\tremaining: 4.15s\n",
            "984:\tlearn: 141.0415179\ttotal: 4m 15s\tremaining: 3.89s\n",
            "985:\tlearn: 141.0412498\ttotal: 4m 15s\tremaining: 3.63s\n",
            "986:\tlearn: 141.0411196\ttotal: 4m 15s\tremaining: 3.37s\n",
            "987:\tlearn: 141.0411175\ttotal: 4m 15s\tremaining: 3.11s\n",
            "988:\tlearn: 141.0411093\ttotal: 4m 16s\tremaining: 2.85s\n",
            "989:\tlearn: 141.0410995\ttotal: 4m 16s\tremaining: 2.59s\n",
            "990:\tlearn: 141.0410953\ttotal: 4m 16s\tremaining: 2.33s\n",
            "991:\tlearn: 141.0410893\ttotal: 4m 16s\tremaining: 2.07s\n",
            "992:\tlearn: 141.0410853\ttotal: 4m 17s\tremaining: 1.81s\n",
            "993:\tlearn: 141.0410831\ttotal: 4m 17s\tremaining: 1.55s\n",
            "994:\tlearn: 141.0410753\ttotal: 4m 17s\tremaining: 1.29s\n",
            "995:\tlearn: 141.0410749\ttotal: 4m 17s\tremaining: 1.03s\n",
            "996:\tlearn: 141.0410730\ttotal: 4m 18s\tremaining: 777ms\n",
            "997:\tlearn: 141.0410693\ttotal: 4m 18s\tremaining: 518ms\n",
            "998:\tlearn: 141.0410668\ttotal: 4m 18s\tremaining: 259ms\n",
            "999:\tlearn: 141.0410646\ttotal: 4m 18s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('preprocessor',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('num',\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('imputer',\n",
              "                                                                   SimpleImputer(add_indicator=False,\n",
              "                                                                                 copy=True,\n",
              "                                                                                 fill_value=None,\n",
              "                                                                                 missing_values=nan,\n",
              "                                                                                 strategy='median',\n",
              "                                                                                 verbose=0)),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler(copy=True,\n",
              "                                                                                  with_mean...\n",
              "                                                   'text_digits_count',\n",
              "                                                   'text_emoji_count',\n",
              "                                                   'text_emoji_percent',\n",
              "                                                   'text_has_emoji',\n",
              "                                                   'text_upper_letter_count',\n",
              "                                                   'text_upper_letter_count_to_word_count',\n",
              "                                                   'text_upper_letter_count_to_length',\n",
              "                                                   'text_urls_count',\n",
              "                                                   'text_urls_count_to_words_count',\n",
              "                                                   'text_hashtags_count', ...])],\n",
              "                                   verbose=False)),\n",
              "                ('classifier',\n",
              "                 <catboost.core.CatBoostRegressor object at 0x7f55e6712320>)],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL27WJ69fmj1",
        "outputId": "02335e3a-9bda-4435-81b6-f0cf4b7a17e6"
      },
      "source": [
        "y_pred_10 = clf1.predict(X_test)\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_10))\n",
        "print(\"MAE score on zero perediction: %.3f\" % MAE(y_test, np.zeros(len(y_test))))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 143.634\n",
            "MAE score on zero perediction: 150.769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-klhI0WKHdXU"
      },
      "source": [
        "y_pred_test_10 = clf1.predict(df_test_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HZdK3F3spz0",
        "outputId": "c6135322-1894-4e9e-8ddf-29f374870c61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# model = clf1.named_steps.classifier\n",
        "# shap_values = model.get_feature_importance(Pool(X_train, y_train))\n",
        "# # print(len(shap_values))\n",
        "\n",
        "# # expected_value = shap_values[-1]\n",
        "# # shap_values = shap_values[:-1]\n",
        "\n",
        "# # shap.initjs()\n",
        "# # shap.force_plot(expected_value, shap_values[3,:], X_test.iloc[3,:])\n",
        "# # print(clf.named_steps.classifier.feature_importances_)\n",
        "# important_features = np.argsort(shap_values)\n",
        "# cat_features = important_features[-100:]\n",
        "# # print(clf.named_steps.classifier.feature_importances_[cat_features])\n",
        "# # list(cat_features)\n",
        "# shap_values[cat_features]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 1.16677402e-15, 1.54254340e-12,\n",
              "       1.05499600e-10, 1.63421519e-10, 1.24018328e-09, 2.13640911e-09,\n",
              "       3.76532735e-09, 3.87542302e-09, 4.54992493e-09, 7.64309267e-09,\n",
              "       1.07891669e-08, 4.02034915e-08, 7.68079054e-08, 8.03507604e-08,\n",
              "       1.21968652e-07, 1.24277349e-07, 1.76616484e-07, 1.87079373e-07,\n",
              "       4.26660111e-07, 5.89172750e-07, 7.42371669e-07, 1.09887930e-06,\n",
              "       1.55361185e-06, 2.24702011e-06, 2.38583410e-06, 3.94942852e-06,\n",
              "       5.40713900e-06, 6.00891668e-06, 1.05206437e-05, 6.33005244e-05,\n",
              "       1.21878197e-04, 1.57160703e-04, 2.28066851e-04, 3.22773815e-04,\n",
              "       3.35562586e-04, 6.58907761e-04, 7.55373543e-04, 9.33125623e-04,\n",
              "       1.33804910e-03, 3.70659851e-03, 9.29021610e-03, 1.48889548e-02,\n",
              "       2.01965203e-02, 2.94429129e-01, 9.28693738e-01, 5.44694870e+00,\n",
              "       2.66535885e+01, 6.66233076e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6-aHPQrI8fj",
        "outputId": "1b0c56d2-e851-466b-edd7-410332687550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cat_features"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([102, 101,  52,  12, 180,   5,  35,  11,  22,  33,  18,  32,  72,\n",
              "        39,  40,  45,  10,  36,  24,  26,   6,  16,  15,  14,  46,  25,\n",
              "       138,   9,  13,  34,  21,  28,  30,  38,  27,   2,  19,  43,  20,\n",
              "         1,  31,  47,  37,  44,  17,   3,   7,   8,  29,  42])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyZrtwBeAyE-",
        "outputId": "d1737c4b-9b37-440f-9418-4bcae430a1eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cat_features"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 72,  22,  27,  45,   5,   3,   1,  35,   2,  48,  16, 102, 180,\n",
              "       138,  30,  26,  12,  17,  34,  18,  39,  46,  47,  19,  42,   4,\n",
              "        14,  11,  28,  37,   6,  13,  43,  38,  51,  41,  20,  21,  15,\n",
              "         9,  24,  36,  10,   8,  33,  25,  40,   7,  31,  29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZOqHIMn9Bwr"
      },
      "source": [
        "numeric_features = X_train.columns[cat_features]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = features_category\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        # ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "clf1_pro = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', CatBoostRegressor(iterations=1000, depth=7, loss_function ='MAE', eval_metric = 'MAE', random_seed=57, learning_rate=0.1, l2_leaf_reg=6))])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLPab3wtBkDC",
        "outputId": "2d1943ad-e5dd-4504-e14e-b714da5af2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf1_pro.fit(X_train[X_train.columns[cat_features]], y_train)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 146.4380013\ttotal: 323ms\tremaining: 5m 22s\n",
            "1:\tlearn: 146.0019901\ttotal: 588ms\tremaining: 4m 53s\n",
            "2:\tlearn: 145.7258038\ttotal: 860ms\tremaining: 4m 45s\n",
            "3:\tlearn: 145.2308273\ttotal: 1.12s\tremaining: 4m 38s\n",
            "4:\tlearn: 145.1462080\ttotal: 1.39s\tremaining: 4m 36s\n",
            "5:\tlearn: 144.9906148\ttotal: 1.65s\tremaining: 4m 32s\n",
            "6:\tlearn: 144.8220760\ttotal: 1.91s\tremaining: 4m 31s\n",
            "7:\tlearn: 144.5238374\ttotal: 2.17s\tremaining: 4m 29s\n",
            "8:\tlearn: 144.3338735\ttotal: 2.43s\tremaining: 4m 27s\n",
            "9:\tlearn: 144.3093108\ttotal: 2.69s\tremaining: 4m 26s\n",
            "10:\tlearn: 143.9874529\ttotal: 2.94s\tremaining: 4m 24s\n",
            "11:\tlearn: 143.9502269\ttotal: 3.19s\tremaining: 4m 22s\n",
            "12:\tlearn: 143.8280143\ttotal: 3.45s\tremaining: 4m 22s\n",
            "13:\tlearn: 143.7153456\ttotal: 3.7s\tremaining: 4m 20s\n",
            "14:\tlearn: 143.6945976\ttotal: 3.96s\tremaining: 4m 20s\n",
            "15:\tlearn: 143.6641409\ttotal: 4.2s\tremaining: 4m 18s\n",
            "16:\tlearn: 143.5963297\ttotal: 4.43s\tremaining: 4m 16s\n",
            "17:\tlearn: 143.5653374\ttotal: 4.69s\tremaining: 4m 15s\n",
            "18:\tlearn: 143.5172263\ttotal: 4.94s\tremaining: 4m 14s\n",
            "19:\tlearn: 143.4556626\ttotal: 5.18s\tremaining: 4m 13s\n",
            "20:\tlearn: 143.4223475\ttotal: 5.41s\tremaining: 4m 12s\n",
            "21:\tlearn: 143.3069834\ttotal: 5.66s\tremaining: 4m 11s\n",
            "22:\tlearn: 143.2841482\ttotal: 5.89s\tremaining: 4m 10s\n",
            "23:\tlearn: 143.2034513\ttotal: 6.13s\tremaining: 4m 9s\n",
            "24:\tlearn: 143.0718466\ttotal: 6.35s\tremaining: 4m 7s\n",
            "25:\tlearn: 143.0690588\ttotal: 6.59s\tremaining: 4m 6s\n",
            "26:\tlearn: 143.0482541\ttotal: 6.82s\tremaining: 4m 5s\n",
            "27:\tlearn: 142.9796455\ttotal: 7.06s\tremaining: 4m 5s\n",
            "28:\tlearn: 142.6484740\ttotal: 7.36s\tremaining: 4m 6s\n",
            "29:\tlearn: 142.3502656\ttotal: 7.68s\tremaining: 4m 8s\n",
            "30:\tlearn: 142.3469347\ttotal: 7.97s\tremaining: 4m 9s\n",
            "31:\tlearn: 142.3379943\ttotal: 8.27s\tremaining: 4m 10s\n",
            "32:\tlearn: 142.3169298\ttotal: 8.59s\tremaining: 4m 11s\n",
            "33:\tlearn: 142.2931873\ttotal: 8.9s\tremaining: 4m 12s\n",
            "34:\tlearn: 142.2728206\ttotal: 9.15s\tremaining: 4m 12s\n",
            "35:\tlearn: 142.2091902\ttotal: 9.39s\tremaining: 4m 11s\n",
            "36:\tlearn: 142.2079254\ttotal: 9.63s\tremaining: 4m 10s\n",
            "37:\tlearn: 142.2038531\ttotal: 9.89s\tremaining: 4m 10s\n",
            "38:\tlearn: 142.1881586\ttotal: 10.1s\tremaining: 4m 10s\n",
            "39:\tlearn: 142.0811896\ttotal: 10.4s\tremaining: 4m 9s\n",
            "40:\tlearn: 142.0806933\ttotal: 10.6s\tremaining: 4m 7s\n",
            "41:\tlearn: 142.0760588\ttotal: 10.8s\tremaining: 4m 7s\n",
            "42:\tlearn: 142.0754958\ttotal: 11.1s\tremaining: 4m 7s\n",
            "43:\tlearn: 142.0748859\ttotal: 11.4s\tremaining: 4m 6s\n",
            "44:\tlearn: 142.0733184\ttotal: 11.6s\tremaining: 4m 6s\n",
            "45:\tlearn: 142.0730912\ttotal: 11.9s\tremaining: 4m 6s\n",
            "46:\tlearn: 142.0685291\ttotal: 12.2s\tremaining: 4m 6s\n",
            "47:\tlearn: 142.0673047\ttotal: 12.4s\tremaining: 4m 6s\n",
            "48:\tlearn: 142.0663044\ttotal: 12.7s\tremaining: 4m 6s\n",
            "49:\tlearn: 142.0661726\ttotal: 13s\tremaining: 4m 6s\n",
            "50:\tlearn: 142.0658729\ttotal: 13.2s\tremaining: 4m 5s\n",
            "51:\tlearn: 142.0657077\ttotal: 13.5s\tremaining: 4m 5s\n",
            "52:\tlearn: 142.0654215\ttotal: 13.7s\tremaining: 4m 5s\n",
            "53:\tlearn: 142.0648215\ttotal: 14s\tremaining: 4m 5s\n",
            "54:\tlearn: 142.0613713\ttotal: 14.3s\tremaining: 4m 5s\n",
            "55:\tlearn: 142.0612880\ttotal: 14.5s\tremaining: 4m 5s\n",
            "56:\tlearn: 142.0612297\ttotal: 14.8s\tremaining: 4m 4s\n",
            "57:\tlearn: 142.0611880\ttotal: 15.1s\tremaining: 4m 4s\n",
            "58:\tlearn: 142.0611218\ttotal: 15.3s\tremaining: 4m 4s\n",
            "59:\tlearn: 142.0609669\ttotal: 15.6s\tremaining: 4m 3s\n",
            "60:\tlearn: 142.0607330\ttotal: 15.8s\tremaining: 4m 3s\n",
            "61:\tlearn: 142.0604321\ttotal: 16.1s\tremaining: 4m 3s\n",
            "62:\tlearn: 142.0602545\ttotal: 16.3s\tremaining: 4m 3s\n",
            "63:\tlearn: 142.0600635\ttotal: 16.6s\tremaining: 4m 2s\n",
            "64:\tlearn: 142.0598933\ttotal: 16.9s\tremaining: 4m 2s\n",
            "65:\tlearn: 142.0598126\ttotal: 17.2s\tremaining: 4m 2s\n",
            "66:\tlearn: 142.0597859\ttotal: 17.4s\tremaining: 4m 2s\n",
            "67:\tlearn: 142.0597116\ttotal: 17.7s\tremaining: 4m 2s\n",
            "68:\tlearn: 142.0571805\ttotal: 18s\tremaining: 4m 2s\n",
            "69:\tlearn: 142.0570486\ttotal: 18.2s\tremaining: 4m 1s\n",
            "70:\tlearn: 142.0561291\ttotal: 18.4s\tremaining: 4m 1s\n",
            "71:\tlearn: 142.0532518\ttotal: 18.7s\tremaining: 4m\n",
            "72:\tlearn: 142.0532332\ttotal: 19s\tremaining: 4m\n",
            "73:\tlearn: 142.0532237\ttotal: 19.2s\tremaining: 4m\n",
            "74:\tlearn: 142.0532147\ttotal: 19.5s\tremaining: 4m\n",
            "75:\tlearn: 142.0532117\ttotal: 19.8s\tremaining: 4m\n",
            "76:\tlearn: 142.0531725\ttotal: 20s\tremaining: 4m\n",
            "77:\tlearn: 142.0531402\ttotal: 20.3s\tremaining: 4m\n",
            "78:\tlearn: 142.0531070\ttotal: 20.6s\tremaining: 3m 59s\n",
            "79:\tlearn: 142.0530846\ttotal: 20.9s\tremaining: 3m 59s\n",
            "80:\tlearn: 142.0530037\ttotal: 21.1s\tremaining: 3m 59s\n",
            "81:\tlearn: 142.0529868\ttotal: 21.4s\tremaining: 3m 59s\n",
            "82:\tlearn: 142.0529805\ttotal: 21.6s\tremaining: 3m 59s\n",
            "83:\tlearn: 142.0529631\ttotal: 21.9s\tremaining: 3m 59s\n",
            "84:\tlearn: 142.0528255\ttotal: 22.2s\tremaining: 3m 58s\n",
            "85:\tlearn: 142.0528058\ttotal: 22.5s\tremaining: 3m 58s\n",
            "86:\tlearn: 142.0527571\ttotal: 22.7s\tremaining: 3m 58s\n",
            "87:\tlearn: 142.0526715\ttotal: 23s\tremaining: 3m 58s\n",
            "88:\tlearn: 142.0526607\ttotal: 23.2s\tremaining: 3m 57s\n",
            "89:\tlearn: 142.0525778\ttotal: 23.5s\tremaining: 3m 57s\n",
            "90:\tlearn: 142.0525246\ttotal: 23.8s\tremaining: 3m 57s\n",
            "91:\tlearn: 142.0524889\ttotal: 24s\tremaining: 3m 57s\n",
            "92:\tlearn: 142.0524355\ttotal: 24.3s\tremaining: 3m 57s\n",
            "93:\tlearn: 142.0523827\ttotal: 24.6s\tremaining: 3m 56s\n",
            "94:\tlearn: 142.0522712\ttotal: 24.8s\tremaining: 3m 56s\n",
            "95:\tlearn: 142.0332378\ttotal: 25.1s\tremaining: 3m 56s\n",
            "96:\tlearn: 142.0331213\ttotal: 25.3s\tremaining: 3m 55s\n",
            "97:\tlearn: 142.0327725\ttotal: 25.6s\tremaining: 3m 55s\n",
            "98:\tlearn: 142.0322975\ttotal: 25.8s\tremaining: 3m 54s\n",
            "99:\tlearn: 142.0297221\ttotal: 26s\tremaining: 3m 53s\n",
            "100:\tlearn: 142.0297217\ttotal: 26.2s\tremaining: 3m 53s\n",
            "101:\tlearn: 142.0297177\ttotal: 26.4s\tremaining: 3m 52s\n",
            "102:\tlearn: 142.0297093\ttotal: 26.7s\tremaining: 3m 52s\n",
            "103:\tlearn: 142.0296853\ttotal: 26.9s\tremaining: 3m 51s\n",
            "104:\tlearn: 142.0296792\ttotal: 27.1s\tremaining: 3m 51s\n",
            "105:\tlearn: 142.0296694\ttotal: 27.4s\tremaining: 3m 50s\n",
            "106:\tlearn: 142.0296592\ttotal: 27.6s\tremaining: 3m 50s\n",
            "107:\tlearn: 142.0296580\ttotal: 27.8s\tremaining: 3m 49s\n",
            "108:\tlearn: 142.0294386\ttotal: 28.1s\tremaining: 3m 49s\n",
            "109:\tlearn: 142.0292934\ttotal: 28.3s\tremaining: 3m 49s\n",
            "110:\tlearn: 142.0292805\ttotal: 28.5s\tremaining: 3m 48s\n",
            "111:\tlearn: 142.0291359\ttotal: 28.8s\tremaining: 3m 48s\n",
            "112:\tlearn: 142.0289962\ttotal: 29s\tremaining: 3m 47s\n",
            "113:\tlearn: 142.0289197\ttotal: 29.2s\tremaining: 3m 47s\n",
            "114:\tlearn: 142.0289192\ttotal: 29.5s\tremaining: 3m 46s\n",
            "115:\tlearn: 142.0283544\ttotal: 29.7s\tremaining: 3m 46s\n",
            "116:\tlearn: 142.0283037\ttotal: 30s\tremaining: 3m 46s\n",
            "117:\tlearn: 142.0282732\ttotal: 30.2s\tremaining: 3m 45s\n",
            "118:\tlearn: 142.0282715\ttotal: 30.4s\tremaining: 3m 45s\n",
            "119:\tlearn: 142.0282381\ttotal: 30.7s\tremaining: 3m 44s\n",
            "120:\tlearn: 142.0282340\ttotal: 30.9s\tremaining: 3m 44s\n",
            "121:\tlearn: 142.0282320\ttotal: 31.2s\tremaining: 3m 44s\n",
            "122:\tlearn: 142.0282269\ttotal: 31.4s\tremaining: 3m 43s\n",
            "123:\tlearn: 142.0282046\ttotal: 31.6s\tremaining: 3m 43s\n",
            "124:\tlearn: 142.0281360\ttotal: 31.9s\tremaining: 3m 43s\n",
            "125:\tlearn: 142.0281310\ttotal: 32.1s\tremaining: 3m 42s\n",
            "126:\tlearn: 142.0281027\ttotal: 32.3s\tremaining: 3m 42s\n",
            "127:\tlearn: 142.0281007\ttotal: 32.6s\tremaining: 3m 41s\n",
            "128:\tlearn: 142.0280880\ttotal: 32.8s\tremaining: 3m 41s\n",
            "129:\tlearn: 142.0280765\ttotal: 33s\tremaining: 3m 40s\n",
            "130:\tlearn: 142.0280721\ttotal: 33.3s\tremaining: 3m 40s\n",
            "131:\tlearn: 142.0280549\ttotal: 33.5s\tremaining: 3m 40s\n",
            "132:\tlearn: 142.0280238\ttotal: 33.7s\tremaining: 3m 39s\n",
            "133:\tlearn: 142.0279379\ttotal: 34s\tremaining: 3m 39s\n",
            "134:\tlearn: 142.0279177\ttotal: 34.2s\tremaining: 3m 39s\n",
            "135:\tlearn: 142.0279046\ttotal: 34.4s\tremaining: 3m 38s\n",
            "136:\tlearn: 142.0278942\ttotal: 34.7s\tremaining: 3m 38s\n",
            "137:\tlearn: 142.0278834\ttotal: 34.9s\tremaining: 3m 38s\n",
            "138:\tlearn: 142.0278627\ttotal: 35.1s\tremaining: 3m 37s\n",
            "139:\tlearn: 142.0278556\ttotal: 35.4s\tremaining: 3m 37s\n",
            "140:\tlearn: 142.0276256\ttotal: 35.6s\tremaining: 3m 36s\n",
            "141:\tlearn: 142.0276233\ttotal: 35.8s\tremaining: 3m 36s\n",
            "142:\tlearn: 142.0275451\ttotal: 36s\tremaining: 3m 36s\n",
            "143:\tlearn: 142.0275450\ttotal: 36.3s\tremaining: 3m 35s\n",
            "144:\tlearn: 142.0274276\ttotal: 36.5s\tremaining: 3m 35s\n",
            "145:\tlearn: 142.0265099\ttotal: 36.7s\tremaining: 3m 34s\n",
            "146:\tlearn: 142.0263195\ttotal: 37s\tremaining: 3m 34s\n",
            "147:\tlearn: 142.0260742\ttotal: 37.2s\tremaining: 3m 34s\n",
            "148:\tlearn: 142.0260093\ttotal: 37.4s\tremaining: 3m 33s\n",
            "149:\tlearn: 142.0251836\ttotal: 37.6s\tremaining: 3m 33s\n",
            "150:\tlearn: 142.0251239\ttotal: 37.8s\tremaining: 3m 32s\n",
            "151:\tlearn: 142.0248705\ttotal: 38.1s\tremaining: 3m 32s\n",
            "152:\tlearn: 142.0247883\ttotal: 38.3s\tremaining: 3m 31s\n",
            "153:\tlearn: 142.0247358\ttotal: 38.5s\tremaining: 3m 31s\n",
            "154:\tlearn: 142.0245355\ttotal: 38.7s\tremaining: 3m 31s\n",
            "155:\tlearn: 142.0240721\ttotal: 39s\tremaining: 3m 30s\n",
            "156:\tlearn: 142.0239316\ttotal: 39.2s\tremaining: 3m 30s\n",
            "157:\tlearn: 142.0238781\ttotal: 39.4s\tremaining: 3m 29s\n",
            "158:\tlearn: 142.0235664\ttotal: 39.6s\tremaining: 3m 29s\n",
            "159:\tlearn: 142.0233672\ttotal: 39.9s\tremaining: 3m 29s\n",
            "160:\tlearn: 142.0226844\ttotal: 40.1s\tremaining: 3m 28s\n",
            "161:\tlearn: 142.0226008\ttotal: 40.3s\tremaining: 3m 28s\n",
            "162:\tlearn: 142.0222561\ttotal: 40.5s\tremaining: 3m 28s\n",
            "163:\tlearn: 142.0216695\ttotal: 40.8s\tremaining: 3m 27s\n",
            "164:\tlearn: 142.0215719\ttotal: 41s\tremaining: 3m 27s\n",
            "165:\tlearn: 142.0212437\ttotal: 41.2s\tremaining: 3m 27s\n",
            "166:\tlearn: 142.0211786\ttotal: 41.4s\tremaining: 3m 26s\n",
            "167:\tlearn: 142.0210923\ttotal: 41.7s\tremaining: 3m 26s\n",
            "168:\tlearn: 142.0208615\ttotal: 41.9s\tremaining: 3m 25s\n",
            "169:\tlearn: 142.0198415\ttotal: 42.1s\tremaining: 3m 25s\n",
            "170:\tlearn: 142.0191071\ttotal: 42.3s\tremaining: 3m 25s\n",
            "171:\tlearn: 142.0189938\ttotal: 42.6s\tremaining: 3m 24s\n",
            "172:\tlearn: 142.0188612\ttotal: 42.8s\tremaining: 3m 24s\n",
            "173:\tlearn: 142.0188006\ttotal: 43s\tremaining: 3m 24s\n",
            "174:\tlearn: 142.0187886\ttotal: 43.2s\tremaining: 3m 23s\n",
            "175:\tlearn: 142.0178516\ttotal: 43.4s\tremaining: 3m 23s\n",
            "176:\tlearn: 142.0178233\ttotal: 43.7s\tremaining: 3m 23s\n",
            "177:\tlearn: 142.0173624\ttotal: 43.9s\tremaining: 3m 22s\n",
            "178:\tlearn: 142.0170461\ttotal: 44.1s\tremaining: 3m 22s\n",
            "179:\tlearn: 142.0169584\ttotal: 44.4s\tremaining: 3m 22s\n",
            "180:\tlearn: 142.0157581\ttotal: 44.6s\tremaining: 3m 21s\n",
            "181:\tlearn: 142.0044311\ttotal: 44.8s\tremaining: 3m 21s\n",
            "182:\tlearn: 141.8021295\ttotal: 45s\tremaining: 3m 20s\n",
            "183:\tlearn: 141.7964836\ttotal: 45.2s\tremaining: 3m 20s\n",
            "184:\tlearn: 141.7919110\ttotal: 45.5s\tremaining: 3m 20s\n",
            "185:\tlearn: 141.7912071\ttotal: 45.7s\tremaining: 3m 20s\n",
            "186:\tlearn: 141.7909370\ttotal: 45.9s\tremaining: 3m 19s\n",
            "187:\tlearn: 141.7907816\ttotal: 46.2s\tremaining: 3m 19s\n",
            "188:\tlearn: 141.7904277\ttotal: 46.4s\tremaining: 3m 18s\n",
            "189:\tlearn: 141.7830078\ttotal: 46.6s\tremaining: 3m 18s\n",
            "190:\tlearn: 141.7250691\ttotal: 46.8s\tremaining: 3m 18s\n",
            "191:\tlearn: 141.7237786\ttotal: 47s\tremaining: 3m 17s\n",
            "192:\tlearn: 141.6854116\ttotal: 47.2s\tremaining: 3m 17s\n",
            "193:\tlearn: 141.6853798\ttotal: 47.5s\tremaining: 3m 17s\n",
            "194:\tlearn: 141.6849993\ttotal: 47.7s\tremaining: 3m 16s\n",
            "195:\tlearn: 141.6768802\ttotal: 47.9s\tremaining: 3m 16s\n",
            "196:\tlearn: 141.6756078\ttotal: 48.1s\tremaining: 3m 16s\n",
            "197:\tlearn: 141.6752145\ttotal: 48.3s\tremaining: 3m 15s\n",
            "198:\tlearn: 141.6750125\ttotal: 48.5s\tremaining: 3m 15s\n",
            "199:\tlearn: 141.6729715\ttotal: 48.7s\tremaining: 3m 14s\n",
            "200:\tlearn: 141.6728554\ttotal: 49s\tremaining: 3m 14s\n",
            "201:\tlearn: 141.6725541\ttotal: 49.2s\tremaining: 3m 14s\n",
            "202:\tlearn: 141.6719709\ttotal: 49.4s\tremaining: 3m 14s\n",
            "203:\tlearn: 141.6710626\ttotal: 49.7s\tremaining: 3m 13s\n",
            "204:\tlearn: 141.6705184\ttotal: 49.9s\tremaining: 3m 13s\n",
            "205:\tlearn: 141.6612740\ttotal: 50.1s\tremaining: 3m 13s\n",
            "206:\tlearn: 141.6450685\ttotal: 50.3s\tremaining: 3m 12s\n",
            "207:\tlearn: 141.6450484\ttotal: 50.5s\tremaining: 3m 12s\n",
            "208:\tlearn: 141.6449538\ttotal: 50.7s\tremaining: 3m 11s\n",
            "209:\tlearn: 141.6443754\ttotal: 50.9s\tremaining: 3m 11s\n",
            "210:\tlearn: 141.6436235\ttotal: 51.1s\tremaining: 3m 11s\n",
            "211:\tlearn: 141.6422759\ttotal: 51.3s\tremaining: 3m 10s\n",
            "212:\tlearn: 141.6422581\ttotal: 51.6s\tremaining: 3m 10s\n",
            "213:\tlearn: 141.6422001\ttotal: 51.8s\tremaining: 3m 10s\n",
            "214:\tlearn: 141.6419131\ttotal: 52s\tremaining: 3m 9s\n",
            "215:\tlearn: 141.6418917\ttotal: 52.2s\tremaining: 3m 9s\n",
            "216:\tlearn: 141.6417771\ttotal: 52.4s\tremaining: 3m 9s\n",
            "217:\tlearn: 141.5594614\ttotal: 52.6s\tremaining: 3m 8s\n",
            "218:\tlearn: 141.5594500\ttotal: 52.8s\tremaining: 3m 8s\n",
            "219:\tlearn: 141.5591653\ttotal: 53.1s\tremaining: 3m 8s\n",
            "220:\tlearn: 141.5589770\ttotal: 53.3s\tremaining: 3m 7s\n",
            "221:\tlearn: 141.5588586\ttotal: 53.5s\tremaining: 3m 7s\n",
            "222:\tlearn: 141.5587305\ttotal: 53.7s\tremaining: 3m 7s\n",
            "223:\tlearn: 141.5586582\ttotal: 53.9s\tremaining: 3m 6s\n",
            "224:\tlearn: 141.5585826\ttotal: 54.2s\tremaining: 3m 6s\n",
            "225:\tlearn: 141.5584228\ttotal: 54.4s\tremaining: 3m 6s\n",
            "226:\tlearn: 141.5582186\ttotal: 54.6s\tremaining: 3m 6s\n",
            "227:\tlearn: 141.5578804\ttotal: 54.9s\tremaining: 3m 5s\n",
            "228:\tlearn: 141.5575269\ttotal: 55.1s\tremaining: 3m 5s\n",
            "229:\tlearn: 141.5574697\ttotal: 55.3s\tremaining: 3m 5s\n",
            "230:\tlearn: 141.5570023\ttotal: 55.5s\tremaining: 3m 4s\n",
            "231:\tlearn: 141.5569791\ttotal: 55.7s\tremaining: 3m 4s\n",
            "232:\tlearn: 141.5567404\ttotal: 56s\tremaining: 3m 4s\n",
            "233:\tlearn: 141.5567370\ttotal: 56.2s\tremaining: 3m 3s\n",
            "234:\tlearn: 141.5566804\ttotal: 56.4s\tremaining: 3m 3s\n",
            "235:\tlearn: 141.5555625\ttotal: 56.6s\tremaining: 3m 3s\n",
            "236:\tlearn: 141.5553425\ttotal: 56.9s\tremaining: 3m 3s\n",
            "237:\tlearn: 141.5548568\ttotal: 57.1s\tremaining: 3m 2s\n",
            "238:\tlearn: 141.5548381\ttotal: 57.3s\tremaining: 3m 2s\n",
            "239:\tlearn: 141.5546008\ttotal: 57.5s\tremaining: 3m 2s\n",
            "240:\tlearn: 141.5522429\ttotal: 57.7s\tremaining: 3m 1s\n",
            "241:\tlearn: 141.5430004\ttotal: 58s\tremaining: 3m 1s\n",
            "242:\tlearn: 141.5424511\ttotal: 58.2s\tremaining: 3m 1s\n",
            "243:\tlearn: 141.5424488\ttotal: 58.4s\tremaining: 3m\n",
            "244:\tlearn: 141.5423475\ttotal: 58.6s\tremaining: 3m\n",
            "245:\tlearn: 141.5405797\ttotal: 58.8s\tremaining: 3m\n",
            "246:\tlearn: 141.5395393\ttotal: 59.1s\tremaining: 3m\n",
            "247:\tlearn: 141.5395279\ttotal: 59.3s\tremaining: 2m 59s\n",
            "248:\tlearn: 141.5364470\ttotal: 59.5s\tremaining: 2m 59s\n",
            "249:\tlearn: 141.5281002\ttotal: 59.7s\tremaining: 2m 59s\n",
            "250:\tlearn: 141.5278430\ttotal: 59.9s\tremaining: 2m 58s\n",
            "251:\tlearn: 141.5258782\ttotal: 1m\tremaining: 2m 58s\n",
            "252:\tlearn: 141.5150299\ttotal: 1m\tremaining: 2m 58s\n",
            "253:\tlearn: 141.5149692\ttotal: 1m\tremaining: 2m 57s\n",
            "254:\tlearn: 141.5133760\ttotal: 1m\tremaining: 2m 57s\n",
            "255:\tlearn: 141.5121209\ttotal: 1m 1s\tremaining: 2m 57s\n",
            "256:\tlearn: 141.5119619\ttotal: 1m 1s\tremaining: 2m 57s\n",
            "257:\tlearn: 141.5117760\ttotal: 1m 1s\tremaining: 2m 56s\n",
            "258:\tlearn: 141.5116178\ttotal: 1m 1s\tremaining: 2m 56s\n",
            "259:\tlearn: 141.5115543\ttotal: 1m 1s\tremaining: 2m 56s\n",
            "260:\tlearn: 141.5091701\ttotal: 1m 2s\tremaining: 2m 56s\n",
            "261:\tlearn: 141.2426353\ttotal: 1m 2s\tremaining: 2m 55s\n",
            "262:\tlearn: 141.2422442\ttotal: 1m 2s\tremaining: 2m 55s\n",
            "263:\tlearn: 141.2422055\ttotal: 1m 2s\tremaining: 2m 55s\n",
            "264:\tlearn: 141.2421494\ttotal: 1m 3s\tremaining: 2m 54s\n",
            "265:\tlearn: 141.2421182\ttotal: 1m 3s\tremaining: 2m 54s\n",
            "266:\tlearn: 141.2416217\ttotal: 1m 3s\tremaining: 2m 54s\n",
            "267:\tlearn: 141.2213531\ttotal: 1m 3s\tremaining: 2m 54s\n",
            "268:\tlearn: 141.2208706\ttotal: 1m 3s\tremaining: 2m 53s\n",
            "269:\tlearn: 140.9918781\ttotal: 1m 4s\tremaining: 2m 53s\n",
            "270:\tlearn: 140.9911933\ttotal: 1m 4s\tremaining: 2m 53s\n",
            "271:\tlearn: 140.9911197\ttotal: 1m 4s\tremaining: 2m 52s\n",
            "272:\tlearn: 140.9765623\ttotal: 1m 4s\tremaining: 2m 52s\n",
            "273:\tlearn: 140.9763226\ttotal: 1m 5s\tremaining: 2m 52s\n",
            "274:\tlearn: 140.9762860\ttotal: 1m 5s\tremaining: 2m 52s\n",
            "275:\tlearn: 140.9761725\ttotal: 1m 5s\tremaining: 2m 51s\n",
            "276:\tlearn: 140.9739720\ttotal: 1m 5s\tremaining: 2m 51s\n",
            "277:\tlearn: 140.9737835\ttotal: 1m 5s\tremaining: 2m 51s\n",
            "278:\tlearn: 140.9737605\ttotal: 1m 6s\tremaining: 2m 51s\n",
            "279:\tlearn: 140.9711082\ttotal: 1m 6s\tremaining: 2m 50s\n",
            "280:\tlearn: 140.9704941\ttotal: 1m 6s\tremaining: 2m 50s\n",
            "281:\tlearn: 140.9700332\ttotal: 1m 6s\tremaining: 2m 50s\n",
            "282:\tlearn: 140.9660393\ttotal: 1m 7s\tremaining: 2m 49s\n",
            "283:\tlearn: 140.9660340\ttotal: 1m 7s\tremaining: 2m 49s\n",
            "284:\tlearn: 140.9659638\ttotal: 1m 7s\tremaining: 2m 49s\n",
            "285:\tlearn: 140.9659553\ttotal: 1m 7s\tremaining: 2m 48s\n",
            "286:\tlearn: 140.9659538\ttotal: 1m 7s\tremaining: 2m 48s\n",
            "287:\tlearn: 140.9659510\ttotal: 1m 8s\tremaining: 2m 48s\n",
            "288:\tlearn: 140.9659254\ttotal: 1m 8s\tremaining: 2m 48s\n",
            "289:\tlearn: 140.9658470\ttotal: 1m 8s\tremaining: 2m 47s\n",
            "290:\tlearn: 140.9657434\ttotal: 1m 8s\tremaining: 2m 47s\n",
            "291:\tlearn: 140.9471932\ttotal: 1m 9s\tremaining: 2m 47s\n",
            "292:\tlearn: 140.9441924\ttotal: 1m 9s\tremaining: 2m 47s\n",
            "293:\tlearn: 140.9440974\ttotal: 1m 9s\tremaining: 2m 46s\n",
            "294:\tlearn: 140.9439591\ttotal: 1m 9s\tremaining: 2m 46s\n",
            "295:\tlearn: 140.9438615\ttotal: 1m 9s\tremaining: 2m 46s\n",
            "296:\tlearn: 140.9438377\ttotal: 1m 10s\tremaining: 2m 45s\n",
            "297:\tlearn: 140.9437346\ttotal: 1m 10s\tremaining: 2m 45s\n",
            "298:\tlearn: 140.9431612\ttotal: 1m 10s\tremaining: 2m 45s\n",
            "299:\tlearn: 140.9431134\ttotal: 1m 10s\tremaining: 2m 45s\n",
            "300:\tlearn: 140.9171450\ttotal: 1m 10s\tremaining: 2m 44s\n",
            "301:\tlearn: 140.9144059\ttotal: 1m 11s\tremaining: 2m 44s\n",
            "302:\tlearn: 140.9143261\ttotal: 1m 11s\tremaining: 2m 44s\n",
            "303:\tlearn: 140.9143201\ttotal: 1m 11s\tremaining: 2m 43s\n",
            "304:\tlearn: 140.9143179\ttotal: 1m 11s\tremaining: 2m 43s\n",
            "305:\tlearn: 140.9142758\ttotal: 1m 12s\tremaining: 2m 43s\n",
            "306:\tlearn: 140.9142174\ttotal: 1m 12s\tremaining: 2m 43s\n",
            "307:\tlearn: 140.9141091\ttotal: 1m 12s\tremaining: 2m 42s\n",
            "308:\tlearn: 140.9140619\ttotal: 1m 12s\tremaining: 2m 42s\n",
            "309:\tlearn: 140.9139578\ttotal: 1m 12s\tremaining: 2m 42s\n",
            "310:\tlearn: 140.9139177\ttotal: 1m 13s\tremaining: 2m 42s\n",
            "311:\tlearn: 140.9139104\ttotal: 1m 13s\tremaining: 2m 41s\n",
            "312:\tlearn: 140.9132102\ttotal: 1m 13s\tremaining: 2m 41s\n",
            "313:\tlearn: 140.9132080\ttotal: 1m 13s\tremaining: 2m 41s\n",
            "314:\tlearn: 140.9131687\ttotal: 1m 14s\tremaining: 2m 41s\n",
            "315:\tlearn: 140.9131679\ttotal: 1m 14s\tremaining: 2m 40s\n",
            "316:\tlearn: 140.9131286\ttotal: 1m 14s\tremaining: 2m 40s\n",
            "317:\tlearn: 140.9130299\ttotal: 1m 14s\tremaining: 2m 40s\n",
            "318:\tlearn: 140.9129905\ttotal: 1m 14s\tremaining: 2m 39s\n",
            "319:\tlearn: 140.9126144\ttotal: 1m 15s\tremaining: 2m 39s\n",
            "320:\tlearn: 140.9126060\ttotal: 1m 15s\tremaining: 2m 39s\n",
            "321:\tlearn: 140.9125036\ttotal: 1m 15s\tremaining: 2m 39s\n",
            "322:\tlearn: 140.9124194\ttotal: 1m 15s\tremaining: 2m 38s\n",
            "323:\tlearn: 140.9124065\ttotal: 1m 16s\tremaining: 2m 38s\n",
            "324:\tlearn: 140.9124000\ttotal: 1m 16s\tremaining: 2m 38s\n",
            "325:\tlearn: 140.9123892\ttotal: 1m 16s\tremaining: 2m 38s\n",
            "326:\tlearn: 140.9106423\ttotal: 1m 16s\tremaining: 2m 37s\n",
            "327:\tlearn: 140.9105119\ttotal: 1m 16s\tremaining: 2m 37s\n",
            "328:\tlearn: 140.9104918\ttotal: 1m 17s\tremaining: 2m 37s\n",
            "329:\tlearn: 140.9104849\ttotal: 1m 17s\tremaining: 2m 36s\n",
            "330:\tlearn: 140.9104780\ttotal: 1m 17s\tremaining: 2m 36s\n",
            "331:\tlearn: 140.9104725\ttotal: 1m 17s\tremaining: 2m 36s\n",
            "332:\tlearn: 140.9104662\ttotal: 1m 17s\tremaining: 2m 36s\n",
            "333:\tlearn: 140.9104560\ttotal: 1m 18s\tremaining: 2m 35s\n",
            "334:\tlearn: 140.9104418\ttotal: 1m 18s\tremaining: 2m 35s\n",
            "335:\tlearn: 140.9104314\ttotal: 1m 18s\tremaining: 2m 35s\n",
            "336:\tlearn: 140.9104026\ttotal: 1m 18s\tremaining: 2m 35s\n",
            "337:\tlearn: 140.9102909\ttotal: 1m 19s\tremaining: 2m 34s\n",
            "338:\tlearn: 140.9102591\ttotal: 1m 19s\tremaining: 2m 34s\n",
            "339:\tlearn: 140.9098526\ttotal: 1m 19s\tremaining: 2m 34s\n",
            "340:\tlearn: 140.9098196\ttotal: 1m 19s\tremaining: 2m 33s\n",
            "341:\tlearn: 140.9097981\ttotal: 1m 19s\tremaining: 2m 33s\n",
            "342:\tlearn: 140.9096397\ttotal: 1m 20s\tremaining: 2m 33s\n",
            "343:\tlearn: 140.9096261\ttotal: 1m 20s\tremaining: 2m 33s\n",
            "344:\tlearn: 140.9094553\ttotal: 1m 20s\tremaining: 2m 32s\n",
            "345:\tlearn: 140.9092889\ttotal: 1m 20s\tremaining: 2m 32s\n",
            "346:\tlearn: 140.9092775\ttotal: 1m 21s\tremaining: 2m 32s\n",
            "347:\tlearn: 140.9092364\ttotal: 1m 21s\tremaining: 2m 32s\n",
            "348:\tlearn: 140.9092333\ttotal: 1m 21s\tremaining: 2m 32s\n",
            "349:\tlearn: 140.9090988\ttotal: 1m 21s\tremaining: 2m 31s\n",
            "350:\tlearn: 140.9090374\ttotal: 1m 21s\tremaining: 2m 31s\n",
            "351:\tlearn: 140.9063338\ttotal: 1m 22s\tremaining: 2m 31s\n",
            "352:\tlearn: 140.9061389\ttotal: 1m 22s\tremaining: 2m 30s\n",
            "353:\tlearn: 140.9038294\ttotal: 1m 22s\tremaining: 2m 30s\n",
            "354:\tlearn: 140.9033900\ttotal: 1m 22s\tremaining: 2m 30s\n",
            "355:\tlearn: 140.9031661\ttotal: 1m 23s\tremaining: 2m 30s\n",
            "356:\tlearn: 140.9028210\ttotal: 1m 23s\tremaining: 2m 29s\n",
            "357:\tlearn: 140.8687783\ttotal: 1m 23s\tremaining: 2m 29s\n",
            "358:\tlearn: 140.8071794\ttotal: 1m 23s\tremaining: 2m 29s\n",
            "359:\tlearn: 140.8010667\ttotal: 1m 23s\tremaining: 2m 29s\n",
            "360:\tlearn: 140.8010441\ttotal: 1m 24s\tremaining: 2m 28s\n",
            "361:\tlearn: 140.8010254\ttotal: 1m 24s\tremaining: 2m 28s\n",
            "362:\tlearn: 140.8010013\ttotal: 1m 24s\tremaining: 2m 28s\n",
            "363:\tlearn: 140.8009881\ttotal: 1m 24s\tremaining: 2m 28s\n",
            "364:\tlearn: 140.8009749\ttotal: 1m 24s\tremaining: 2m 27s\n",
            "365:\tlearn: 140.8009527\ttotal: 1m 25s\tremaining: 2m 27s\n",
            "366:\tlearn: 140.7994755\ttotal: 1m 25s\tremaining: 2m 27s\n",
            "367:\tlearn: 140.7993976\ttotal: 1m 25s\tremaining: 2m 27s\n",
            "368:\tlearn: 140.7993928\ttotal: 1m 25s\tremaining: 2m 26s\n",
            "369:\tlearn: 140.7980412\ttotal: 1m 26s\tremaining: 2m 26s\n",
            "370:\tlearn: 140.7968442\ttotal: 1m 26s\tremaining: 2m 26s\n",
            "371:\tlearn: 140.7968396\ttotal: 1m 26s\tremaining: 2m 26s\n",
            "372:\tlearn: 140.7968142\ttotal: 1m 26s\tremaining: 2m 25s\n",
            "373:\tlearn: 140.7967823\ttotal: 1m 26s\tremaining: 2m 25s\n",
            "374:\tlearn: 140.7923660\ttotal: 1m 27s\tremaining: 2m 25s\n",
            "375:\tlearn: 140.7915702\ttotal: 1m 27s\tremaining: 2m 25s\n",
            "376:\tlearn: 140.7887316\ttotal: 1m 27s\tremaining: 2m 24s\n",
            "377:\tlearn: 140.7887301\ttotal: 1m 27s\tremaining: 2m 24s\n",
            "378:\tlearn: 140.7887224\ttotal: 1m 28s\tremaining: 2m 24s\n",
            "379:\tlearn: 140.7887116\ttotal: 1m 28s\tremaining: 2m 24s\n",
            "380:\tlearn: 140.7887055\ttotal: 1m 28s\tremaining: 2m 23s\n",
            "381:\tlearn: 140.7886774\ttotal: 1m 28s\tremaining: 2m 23s\n",
            "382:\tlearn: 140.7885990\ttotal: 1m 28s\tremaining: 2m 23s\n",
            "383:\tlearn: 140.7885361\ttotal: 1m 29s\tremaining: 2m 23s\n",
            "384:\tlearn: 140.7885149\ttotal: 1m 29s\tremaining: 2m 22s\n",
            "385:\tlearn: 140.7884921\ttotal: 1m 29s\tremaining: 2m 22s\n",
            "386:\tlearn: 140.7884778\ttotal: 1m 29s\tremaining: 2m 22s\n",
            "387:\tlearn: 140.7884667\ttotal: 1m 30s\tremaining: 2m 22s\n",
            "388:\tlearn: 140.7884353\ttotal: 1m 30s\tremaining: 2m 21s\n",
            "389:\tlearn: 140.7883422\ttotal: 1m 30s\tremaining: 2m 21s\n",
            "390:\tlearn: 140.7881858\ttotal: 1m 30s\tremaining: 2m 21s\n",
            "391:\tlearn: 140.7881616\ttotal: 1m 31s\tremaining: 2m 21s\n",
            "392:\tlearn: 140.7881491\ttotal: 1m 31s\tremaining: 2m 21s\n",
            "393:\tlearn: 140.7880482\ttotal: 1m 31s\tremaining: 2m 20s\n",
            "394:\tlearn: 140.7879834\ttotal: 1m 31s\tremaining: 2m 20s\n",
            "395:\tlearn: 140.7879817\ttotal: 1m 32s\tremaining: 2m 20s\n",
            "396:\tlearn: 140.7879761\ttotal: 1m 32s\tremaining: 2m 20s\n",
            "397:\tlearn: 140.7879560\ttotal: 1m 32s\tremaining: 2m 19s\n",
            "398:\tlearn: 140.7879183\ttotal: 1m 32s\tremaining: 2m 19s\n",
            "399:\tlearn: 140.7879152\ttotal: 1m 32s\tremaining: 2m 19s\n",
            "400:\tlearn: 140.7879098\ttotal: 1m 33s\tremaining: 2m 19s\n",
            "401:\tlearn: 140.7878519\ttotal: 1m 33s\tremaining: 2m 18s\n",
            "402:\tlearn: 140.6940851\ttotal: 1m 33s\tremaining: 2m 18s\n",
            "403:\tlearn: 140.6940599\ttotal: 1m 33s\tremaining: 2m 18s\n",
            "404:\tlearn: 140.6940407\ttotal: 1m 33s\tremaining: 2m 17s\n",
            "405:\tlearn: 140.6940357\ttotal: 1m 34s\tremaining: 2m 17s\n",
            "406:\tlearn: 140.6921270\ttotal: 1m 34s\tremaining: 2m 17s\n",
            "407:\tlearn: 140.6900944\ttotal: 1m 34s\tremaining: 2m 17s\n",
            "408:\tlearn: 140.6873975\ttotal: 1m 34s\tremaining: 2m 16s\n",
            "409:\tlearn: 140.6873488\ttotal: 1m 34s\tremaining: 2m 16s\n",
            "410:\tlearn: 140.6873295\ttotal: 1m 35s\tremaining: 2m 16s\n",
            "411:\tlearn: 140.6872790\ttotal: 1m 35s\tremaining: 2m 16s\n",
            "412:\tlearn: 140.6869899\ttotal: 1m 35s\tremaining: 2m 15s\n",
            "413:\tlearn: 140.6868009\ttotal: 1m 35s\tremaining: 2m 15s\n",
            "414:\tlearn: 140.6867250\ttotal: 1m 36s\tremaining: 2m 15s\n",
            "415:\tlearn: 140.6866630\ttotal: 1m 36s\tremaining: 2m 15s\n",
            "416:\tlearn: 140.6864911\ttotal: 1m 36s\tremaining: 2m 14s\n",
            "417:\tlearn: 140.6863646\ttotal: 1m 36s\tremaining: 2m 14s\n",
            "418:\tlearn: 140.6863364\ttotal: 1m 36s\tremaining: 2m 14s\n",
            "419:\tlearn: 140.6863014\ttotal: 1m 37s\tremaining: 2m 14s\n",
            "420:\tlearn: 140.6862999\ttotal: 1m 37s\tremaining: 2m 13s\n",
            "421:\tlearn: 140.6862769\ttotal: 1m 37s\tremaining: 2m 13s\n",
            "422:\tlearn: 140.6800318\ttotal: 1m 37s\tremaining: 2m 13s\n",
            "423:\tlearn: 140.6787399\ttotal: 1m 37s\tremaining: 2m 13s\n",
            "424:\tlearn: 140.6732828\ttotal: 1m 38s\tremaining: 2m 12s\n",
            "425:\tlearn: 140.6723265\ttotal: 1m 38s\tremaining: 2m 12s\n",
            "426:\tlearn: 140.6536268\ttotal: 1m 38s\tremaining: 2m 12s\n",
            "427:\tlearn: 140.6522239\ttotal: 1m 38s\tremaining: 2m 12s\n",
            "428:\tlearn: 140.6520819\ttotal: 1m 38s\tremaining: 2m 11s\n",
            "429:\tlearn: 140.6517864\ttotal: 1m 39s\tremaining: 2m 11s\n",
            "430:\tlearn: 140.6502148\ttotal: 1m 39s\tremaining: 2m 11s\n",
            "431:\tlearn: 140.6501962\ttotal: 1m 39s\tremaining: 2m 11s\n",
            "432:\tlearn: 140.6500919\ttotal: 1m 39s\tremaining: 2m 10s\n",
            "433:\tlearn: 140.6500085\ttotal: 1m 40s\tremaining: 2m 10s\n",
            "434:\tlearn: 140.6499884\ttotal: 1m 40s\tremaining: 2m 10s\n",
            "435:\tlearn: 140.6499250\ttotal: 1m 40s\tremaining: 2m 10s\n",
            "436:\tlearn: 140.6499027\ttotal: 1m 40s\tremaining: 2m 9s\n",
            "437:\tlearn: 140.6498764\ttotal: 1m 40s\tremaining: 2m 9s\n",
            "438:\tlearn: 140.6498748\ttotal: 1m 41s\tremaining: 2m 9s\n",
            "439:\tlearn: 140.6498553\ttotal: 1m 41s\tremaining: 2m 9s\n",
            "440:\tlearn: 140.6498417\ttotal: 1m 41s\tremaining: 2m 8s\n",
            "441:\tlearn: 140.6498257\ttotal: 1m 41s\tremaining: 2m 8s\n",
            "442:\tlearn: 140.6498128\ttotal: 1m 42s\tremaining: 2m 8s\n",
            "443:\tlearn: 140.6498083\ttotal: 1m 42s\tremaining: 2m 8s\n",
            "444:\tlearn: 140.6497998\ttotal: 1m 42s\tremaining: 2m 7s\n",
            "445:\tlearn: 140.6497986\ttotal: 1m 42s\tremaining: 2m 7s\n",
            "446:\tlearn: 140.6497977\ttotal: 1m 42s\tremaining: 2m 7s\n",
            "447:\tlearn: 140.6497950\ttotal: 1m 43s\tremaining: 2m 7s\n",
            "448:\tlearn: 140.6497663\ttotal: 1m 43s\tremaining: 2m 6s\n",
            "449:\tlearn: 140.6497406\ttotal: 1m 43s\tremaining: 2m 6s\n",
            "450:\tlearn: 140.6497150\ttotal: 1m 43s\tremaining: 2m 6s\n",
            "451:\tlearn: 140.6496919\ttotal: 1m 44s\tremaining: 2m 6s\n",
            "452:\tlearn: 140.6496732\ttotal: 1m 44s\tremaining: 2m 5s\n",
            "453:\tlearn: 140.6496710\ttotal: 1m 44s\tremaining: 2m 5s\n",
            "454:\tlearn: 140.6496677\ttotal: 1m 44s\tremaining: 2m 5s\n",
            "455:\tlearn: 140.6496636\ttotal: 1m 44s\tremaining: 2m 5s\n",
            "456:\tlearn: 140.6496522\ttotal: 1m 45s\tremaining: 2m 4s\n",
            "457:\tlearn: 140.6496467\ttotal: 1m 45s\tremaining: 2m 4s\n",
            "458:\tlearn: 140.6496164\ttotal: 1m 45s\tremaining: 2m 4s\n",
            "459:\tlearn: 140.6496018\ttotal: 1m 45s\tremaining: 2m 4s\n",
            "460:\tlearn: 140.6495991\ttotal: 1m 46s\tremaining: 2m 4s\n",
            "461:\tlearn: 140.6495972\ttotal: 1m 46s\tremaining: 2m 3s\n",
            "462:\tlearn: 140.6495782\ttotal: 1m 46s\tremaining: 2m 3s\n",
            "463:\tlearn: 140.6495632\ttotal: 1m 46s\tremaining: 2m 3s\n",
            "464:\tlearn: 140.6492853\ttotal: 1m 47s\tremaining: 2m 3s\n",
            "465:\tlearn: 140.6492786\ttotal: 1m 47s\tremaining: 2m 2s\n",
            "466:\tlearn: 140.6492710\ttotal: 1m 47s\tremaining: 2m 2s\n",
            "467:\tlearn: 140.6492569\ttotal: 1m 47s\tremaining: 2m 2s\n",
            "468:\tlearn: 140.6492457\ttotal: 1m 48s\tremaining: 2m 2s\n",
            "469:\tlearn: 140.6492342\ttotal: 1m 48s\tremaining: 2m 2s\n",
            "470:\tlearn: 140.6450228\ttotal: 1m 48s\tremaining: 2m 1s\n",
            "471:\tlearn: 140.6450138\ttotal: 1m 48s\tremaining: 2m 1s\n",
            "472:\tlearn: 140.6445005\ttotal: 1m 48s\tremaining: 2m 1s\n",
            "473:\tlearn: 140.6444492\ttotal: 1m 49s\tremaining: 2m 1s\n",
            "474:\tlearn: 140.6444119\ttotal: 1m 49s\tremaining: 2m\n",
            "475:\tlearn: 140.6443824\ttotal: 1m 49s\tremaining: 2m\n",
            "476:\tlearn: 140.6443793\ttotal: 1m 49s\tremaining: 2m\n",
            "477:\tlearn: 140.6443392\ttotal: 1m 50s\tremaining: 2m\n",
            "478:\tlearn: 140.6420618\ttotal: 1m 50s\tremaining: 1m 59s\n",
            "479:\tlearn: 140.6420467\ttotal: 1m 50s\tremaining: 1m 59s\n",
            "480:\tlearn: 140.6419373\ttotal: 1m 50s\tremaining: 1m 59s\n",
            "481:\tlearn: 140.6418744\ttotal: 1m 50s\tremaining: 1m 59s\n",
            "482:\tlearn: 140.6418641\ttotal: 1m 51s\tremaining: 1m 59s\n",
            "483:\tlearn: 140.6418024\ttotal: 1m 51s\tremaining: 1m 58s\n",
            "484:\tlearn: 140.6409984\ttotal: 1m 51s\tremaining: 1m 58s\n",
            "485:\tlearn: 140.6409972\ttotal: 1m 51s\tremaining: 1m 58s\n",
            "486:\tlearn: 140.6409680\ttotal: 1m 52s\tremaining: 1m 58s\n",
            "487:\tlearn: 140.6409674\ttotal: 1m 52s\tremaining: 1m 57s\n",
            "488:\tlearn: 140.6409651\ttotal: 1m 52s\tremaining: 1m 57s\n",
            "489:\tlearn: 140.6409217\ttotal: 1m 52s\tremaining: 1m 57s\n",
            "490:\tlearn: 140.6407734\ttotal: 1m 52s\tremaining: 1m 57s\n",
            "491:\tlearn: 140.6407731\ttotal: 1m 53s\tremaining: 1m 56s\n",
            "492:\tlearn: 140.6407676\ttotal: 1m 53s\tremaining: 1m 56s\n",
            "493:\tlearn: 140.6407640\ttotal: 1m 53s\tremaining: 1m 56s\n",
            "494:\tlearn: 140.6407637\ttotal: 1m 53s\tremaining: 1m 56s\n",
            "495:\tlearn: 140.6407617\ttotal: 1m 54s\tremaining: 1m 55s\n",
            "496:\tlearn: 140.6399007\ttotal: 1m 54s\tremaining: 1m 55s\n",
            "497:\tlearn: 140.6363898\ttotal: 1m 54s\tremaining: 1m 55s\n",
            "498:\tlearn: 140.5769615\ttotal: 1m 54s\tremaining: 1m 55s\n",
            "499:\tlearn: 140.5706495\ttotal: 1m 54s\tremaining: 1m 54s\n",
            "500:\tlearn: 140.5676191\ttotal: 1m 55s\tremaining: 1m 54s\n",
            "501:\tlearn: 140.5675593\ttotal: 1m 55s\tremaining: 1m 54s\n",
            "502:\tlearn: 140.5675491\ttotal: 1m 55s\tremaining: 1m 54s\n",
            "503:\tlearn: 140.5675360\ttotal: 1m 55s\tremaining: 1m 53s\n",
            "504:\tlearn: 140.5675296\ttotal: 1m 56s\tremaining: 1m 53s\n",
            "505:\tlearn: 140.5675175\ttotal: 1m 56s\tremaining: 1m 53s\n",
            "506:\tlearn: 140.5674706\ttotal: 1m 56s\tremaining: 1m 53s\n",
            "507:\tlearn: 140.5674278\ttotal: 1m 56s\tremaining: 1m 53s\n",
            "508:\tlearn: 140.5674137\ttotal: 1m 56s\tremaining: 1m 52s\n",
            "509:\tlearn: 140.5674055\ttotal: 1m 57s\tremaining: 1m 52s\n",
            "510:\tlearn: 140.5674008\ttotal: 1m 57s\tremaining: 1m 52s\n",
            "511:\tlearn: 140.5673763\ttotal: 1m 57s\tremaining: 1m 52s\n",
            "512:\tlearn: 140.5615435\ttotal: 1m 57s\tremaining: 1m 51s\n",
            "513:\tlearn: 140.5615274\ttotal: 1m 58s\tremaining: 1m 51s\n",
            "514:\tlearn: 140.5615246\ttotal: 1m 58s\tremaining: 1m 51s\n",
            "515:\tlearn: 140.5614411\ttotal: 1m 58s\tremaining: 1m 51s\n",
            "516:\tlearn: 140.5614145\ttotal: 1m 58s\tremaining: 1m 50s\n",
            "517:\tlearn: 140.5614141\ttotal: 1m 58s\tremaining: 1m 50s\n",
            "518:\tlearn: 140.5605654\ttotal: 1m 59s\tremaining: 1m 50s\n",
            "519:\tlearn: 140.5605626\ttotal: 1m 59s\tremaining: 1m 50s\n",
            "520:\tlearn: 140.5605606\ttotal: 1m 59s\tremaining: 1m 49s\n",
            "521:\tlearn: 140.5605459\ttotal: 1m 59s\tremaining: 1m 49s\n",
            "522:\tlearn: 140.5605455\ttotal: 1m 59s\tremaining: 1m 49s\n",
            "523:\tlearn: 140.5605231\ttotal: 2m\tremaining: 1m 49s\n",
            "524:\tlearn: 140.5605008\ttotal: 2m\tremaining: 1m 48s\n",
            "525:\tlearn: 140.5602417\ttotal: 2m\tremaining: 1m 48s\n",
            "526:\tlearn: 140.5602091\ttotal: 2m\tremaining: 1m 48s\n",
            "527:\tlearn: 140.5602081\ttotal: 2m 1s\tremaining: 1m 48s\n",
            "528:\tlearn: 140.5601923\ttotal: 2m 1s\tremaining: 1m 47s\n",
            "529:\tlearn: 140.5601921\ttotal: 2m 1s\tremaining: 1m 47s\n",
            "530:\tlearn: 140.5601206\ttotal: 2m 1s\tremaining: 1m 47s\n",
            "531:\tlearn: 140.5601206\ttotal: 2m 1s\tremaining: 1m 47s\n",
            "532:\tlearn: 140.5601165\ttotal: 2m 2s\tremaining: 1m 46s\n",
            "533:\tlearn: 140.5601163\ttotal: 2m 2s\tremaining: 1m 46s\n",
            "534:\tlearn: 140.5601163\ttotal: 2m 2s\tremaining: 1m 46s\n",
            "535:\tlearn: 140.5601145\ttotal: 2m 2s\tremaining: 1m 46s\n",
            "536:\tlearn: 140.5556200\ttotal: 2m 2s\tremaining: 1m 45s\n",
            "537:\tlearn: 140.5556184\ttotal: 2m 3s\tremaining: 1m 45s\n",
            "538:\tlearn: 140.5555780\ttotal: 2m 3s\tremaining: 1m 45s\n",
            "539:\tlearn: 140.5542526\ttotal: 2m 3s\tremaining: 1m 45s\n",
            "540:\tlearn: 140.5216253\ttotal: 2m 3s\tremaining: 1m 44s\n",
            "541:\tlearn: 140.5202733\ttotal: 2m 3s\tremaining: 1m 44s\n",
            "542:\tlearn: 140.5199009\ttotal: 2m 4s\tremaining: 1m 44s\n",
            "543:\tlearn: 140.5193116\ttotal: 2m 4s\tremaining: 1m 44s\n",
            "544:\tlearn: 140.5192818\ttotal: 2m 4s\tremaining: 1m 44s\n",
            "545:\tlearn: 140.5192330\ttotal: 2m 4s\tremaining: 1m 43s\n",
            "546:\tlearn: 140.5191444\ttotal: 2m 5s\tremaining: 1m 43s\n",
            "547:\tlearn: 140.5191331\ttotal: 2m 5s\tremaining: 1m 43s\n",
            "548:\tlearn: 140.5188534\ttotal: 2m 5s\tremaining: 1m 43s\n",
            "549:\tlearn: 140.5178373\ttotal: 2m 5s\tremaining: 1m 42s\n",
            "550:\tlearn: 140.5172020\ttotal: 2m 5s\tremaining: 1m 42s\n",
            "551:\tlearn: 140.5171011\ttotal: 2m 6s\tremaining: 1m 42s\n",
            "552:\tlearn: 140.5168809\ttotal: 2m 6s\tremaining: 1m 42s\n",
            "553:\tlearn: 140.5162077\ttotal: 2m 6s\tremaining: 1m 41s\n",
            "554:\tlearn: 140.5152576\ttotal: 2m 6s\tremaining: 1m 41s\n",
            "555:\tlearn: 140.5146428\ttotal: 2m 7s\tremaining: 1m 41s\n",
            "556:\tlearn: 140.5144418\ttotal: 2m 7s\tremaining: 1m 41s\n",
            "557:\tlearn: 140.5144412\ttotal: 2m 7s\tremaining: 1m 41s\n",
            "558:\tlearn: 140.5143460\ttotal: 2m 7s\tremaining: 1m 40s\n",
            "559:\tlearn: 140.5143459\ttotal: 2m 7s\tremaining: 1m 40s\n",
            "560:\tlearn: 140.5143454\ttotal: 2m 8s\tremaining: 1m 40s\n",
            "561:\tlearn: 140.5142907\ttotal: 2m 8s\tremaining: 1m 40s\n",
            "562:\tlearn: 140.5137142\ttotal: 2m 8s\tremaining: 1m 39s\n",
            "563:\tlearn: 140.5133841\ttotal: 2m 8s\tremaining: 1m 39s\n",
            "564:\tlearn: 140.5107957\ttotal: 2m 9s\tremaining: 1m 39s\n",
            "565:\tlearn: 140.5078087\ttotal: 2m 9s\tremaining: 1m 39s\n",
            "566:\tlearn: 140.5076852\ttotal: 2m 9s\tremaining: 1m 38s\n",
            "567:\tlearn: 140.5073772\ttotal: 2m 9s\tremaining: 1m 38s\n",
            "568:\tlearn: 140.5073280\ttotal: 2m 9s\tremaining: 1m 38s\n",
            "569:\tlearn: 140.5073026\ttotal: 2m 10s\tremaining: 1m 38s\n",
            "570:\tlearn: 140.5072711\ttotal: 2m 10s\tremaining: 1m 37s\n",
            "571:\tlearn: 140.5071381\ttotal: 2m 10s\tremaining: 1m 37s\n",
            "572:\tlearn: 140.5071372\ttotal: 2m 10s\tremaining: 1m 37s\n",
            "573:\tlearn: 140.5071116\ttotal: 2m 11s\tremaining: 1m 37s\n",
            "574:\tlearn: 140.5070897\ttotal: 2m 11s\tremaining: 1m 37s\n",
            "575:\tlearn: 140.5070766\ttotal: 2m 11s\tremaining: 1m 36s\n",
            "576:\tlearn: 140.5070341\ttotal: 2m 11s\tremaining: 1m 36s\n",
            "577:\tlearn: 140.5069223\ttotal: 2m 12s\tremaining: 1m 36s\n",
            "578:\tlearn: 140.5069127\ttotal: 2m 12s\tremaining: 1m 36s\n",
            "579:\tlearn: 140.5069040\ttotal: 2m 12s\tremaining: 1m 35s\n",
            "580:\tlearn: 140.5068968\ttotal: 2m 12s\tremaining: 1m 35s\n",
            "581:\tlearn: 140.5068951\ttotal: 2m 12s\tremaining: 1m 35s\n",
            "582:\tlearn: 140.5068496\ttotal: 2m 13s\tremaining: 1m 35s\n",
            "583:\tlearn: 140.5068177\ttotal: 2m 13s\tremaining: 1m 35s\n",
            "584:\tlearn: 140.5068142\ttotal: 2m 13s\tremaining: 1m 34s\n",
            "585:\tlearn: 140.5068062\ttotal: 2m 13s\tremaining: 1m 34s\n",
            "586:\tlearn: 140.5068020\ttotal: 2m 14s\tremaining: 1m 34s\n",
            "587:\tlearn: 140.5067947\ttotal: 2m 14s\tremaining: 1m 34s\n",
            "588:\tlearn: 140.5067841\ttotal: 2m 14s\tremaining: 1m 33s\n",
            "589:\tlearn: 140.5067798\ttotal: 2m 14s\tremaining: 1m 33s\n",
            "590:\tlearn: 140.5067143\ttotal: 2m 15s\tremaining: 1m 33s\n",
            "591:\tlearn: 140.5066648\ttotal: 2m 15s\tremaining: 1m 33s\n",
            "592:\tlearn: 140.5063077\ttotal: 2m 15s\tremaining: 1m 33s\n",
            "593:\tlearn: 140.5063068\ttotal: 2m 15s\tremaining: 1m 32s\n",
            "594:\tlearn: 140.5062836\ttotal: 2m 15s\tremaining: 1m 32s\n",
            "595:\tlearn: 140.5061158\ttotal: 2m 16s\tremaining: 1m 32s\n",
            "596:\tlearn: 140.5061091\ttotal: 2m 16s\tremaining: 1m 32s\n",
            "597:\tlearn: 140.5055655\ttotal: 2m 16s\tremaining: 1m 31s\n",
            "598:\tlearn: 140.5055639\ttotal: 2m 16s\tremaining: 1m 31s\n",
            "599:\tlearn: 140.5055594\ttotal: 2m 17s\tremaining: 1m 31s\n",
            "600:\tlearn: 140.5055263\ttotal: 2m 17s\tremaining: 1m 31s\n",
            "601:\tlearn: 140.5041876\ttotal: 2m 17s\tremaining: 1m 30s\n",
            "602:\tlearn: 140.5041844\ttotal: 2m 17s\tremaining: 1m 30s\n",
            "603:\tlearn: 140.5039239\ttotal: 2m 18s\tremaining: 1m 30s\n",
            "604:\tlearn: 140.5037994\ttotal: 2m 18s\tremaining: 1m 30s\n",
            "605:\tlearn: 140.5037592\ttotal: 2m 18s\tremaining: 1m 30s\n",
            "606:\tlearn: 140.5037327\ttotal: 2m 18s\tremaining: 1m 29s\n",
            "607:\tlearn: 140.5037246\ttotal: 2m 19s\tremaining: 1m 29s\n",
            "608:\tlearn: 140.5037087\ttotal: 2m 19s\tremaining: 1m 29s\n",
            "609:\tlearn: 140.5036094\ttotal: 2m 19s\tremaining: 1m 29s\n",
            "610:\tlearn: 140.5034777\ttotal: 2m 19s\tremaining: 1m 28s\n",
            "611:\tlearn: 140.5034649\ttotal: 2m 19s\tremaining: 1m 28s\n",
            "612:\tlearn: 140.5033769\ttotal: 2m 20s\tremaining: 1m 28s\n",
            "613:\tlearn: 140.4947742\ttotal: 2m 20s\tremaining: 1m 28s\n",
            "614:\tlearn: 140.4947054\ttotal: 2m 20s\tremaining: 1m 27s\n",
            "615:\tlearn: 140.4947044\ttotal: 2m 20s\tremaining: 1m 27s\n",
            "616:\tlearn: 140.4946782\ttotal: 2m 20s\tremaining: 1m 27s\n",
            "617:\tlearn: 140.4946512\ttotal: 2m 21s\tremaining: 1m 27s\n",
            "618:\tlearn: 140.4946260\ttotal: 2m 21s\tremaining: 1m 27s\n",
            "619:\tlearn: 140.4946062\ttotal: 2m 21s\tremaining: 1m 26s\n",
            "620:\tlearn: 140.4932407\ttotal: 2m 21s\tremaining: 1m 26s\n",
            "621:\tlearn: 140.4932045\ttotal: 2m 22s\tremaining: 1m 26s\n",
            "622:\tlearn: 140.4932033\ttotal: 2m 22s\tremaining: 1m 26s\n",
            "623:\tlearn: 140.4911575\ttotal: 2m 22s\tremaining: 1m 25s\n",
            "624:\tlearn: 140.4902383\ttotal: 2m 22s\tremaining: 1m 25s\n",
            "625:\tlearn: 140.4901654\ttotal: 2m 22s\tremaining: 1m 25s\n",
            "626:\tlearn: 140.4901492\ttotal: 2m 23s\tremaining: 1m 25s\n",
            "627:\tlearn: 140.4901468\ttotal: 2m 23s\tremaining: 1m 24s\n",
            "628:\tlearn: 140.4901399\ttotal: 2m 23s\tremaining: 1m 24s\n",
            "629:\tlearn: 140.4901397\ttotal: 2m 23s\tremaining: 1m 24s\n",
            "630:\tlearn: 140.4896695\ttotal: 2m 24s\tremaining: 1m 24s\n",
            "631:\tlearn: 140.4896695\ttotal: 2m 24s\tremaining: 1m 24s\n",
            "632:\tlearn: 140.4895589\ttotal: 2m 24s\tremaining: 1m 23s\n",
            "633:\tlearn: 140.4895562\ttotal: 2m 24s\tremaining: 1m 23s\n",
            "634:\tlearn: 140.4895473\ttotal: 2m 24s\tremaining: 1m 23s\n",
            "635:\tlearn: 140.4894527\ttotal: 2m 25s\tremaining: 1m 23s\n",
            "636:\tlearn: 140.4894462\ttotal: 2m 25s\tremaining: 1m 22s\n",
            "637:\tlearn: 140.4893956\ttotal: 2m 25s\tremaining: 1m 22s\n",
            "638:\tlearn: 140.4893944\ttotal: 2m 25s\tremaining: 1m 22s\n",
            "639:\tlearn: 140.4893939\ttotal: 2m 25s\tremaining: 1m 22s\n",
            "640:\tlearn: 140.4876899\ttotal: 2m 26s\tremaining: 1m 21s\n",
            "641:\tlearn: 140.4876890\ttotal: 2m 26s\tremaining: 1m 21s\n",
            "642:\tlearn: 140.4876737\ttotal: 2m 26s\tremaining: 1m 21s\n",
            "643:\tlearn: 140.4876545\ttotal: 2m 26s\tremaining: 1m 21s\n",
            "644:\tlearn: 140.4876121\ttotal: 2m 27s\tremaining: 1m 20s\n",
            "645:\tlearn: 140.4875796\ttotal: 2m 27s\tremaining: 1m 20s\n",
            "646:\tlearn: 140.4875780\ttotal: 2m 27s\tremaining: 1m 20s\n",
            "647:\tlearn: 140.4875769\ttotal: 2m 27s\tremaining: 1m 20s\n",
            "648:\tlearn: 140.4875742\ttotal: 2m 27s\tremaining: 1m 19s\n",
            "649:\tlearn: 140.4875684\ttotal: 2m 28s\tremaining: 1m 19s\n",
            "650:\tlearn: 140.4875630\ttotal: 2m 28s\tremaining: 1m 19s\n",
            "651:\tlearn: 140.4875618\ttotal: 2m 28s\tremaining: 1m 19s\n",
            "652:\tlearn: 140.4875615\ttotal: 2m 28s\tremaining: 1m 19s\n",
            "653:\tlearn: 140.4875608\ttotal: 2m 29s\tremaining: 1m 18s\n",
            "654:\tlearn: 140.4875595\ttotal: 2m 29s\tremaining: 1m 18s\n",
            "655:\tlearn: 140.4875591\ttotal: 2m 29s\tremaining: 1m 18s\n",
            "656:\tlearn: 140.4875585\ttotal: 2m 29s\tremaining: 1m 18s\n",
            "657:\tlearn: 140.4875575\ttotal: 2m 29s\tremaining: 1m 17s\n",
            "658:\tlearn: 140.4875569\ttotal: 2m 30s\tremaining: 1m 17s\n",
            "659:\tlearn: 140.4875568\ttotal: 2m 30s\tremaining: 1m 17s\n",
            "660:\tlearn: 140.4875291\ttotal: 2m 30s\tremaining: 1m 17s\n",
            "661:\tlearn: 140.4875274\ttotal: 2m 30s\tremaining: 1m 17s\n",
            "662:\tlearn: 140.4875267\ttotal: 2m 31s\tremaining: 1m 16s\n",
            "663:\tlearn: 140.4874944\ttotal: 2m 31s\tremaining: 1m 16s\n",
            "664:\tlearn: 140.4874943\ttotal: 2m 31s\tremaining: 1m 16s\n",
            "665:\tlearn: 140.4874039\ttotal: 2m 31s\tremaining: 1m 16s\n",
            "666:\tlearn: 140.4873421\ttotal: 2m 32s\tremaining: 1m 15s\n",
            "667:\tlearn: 140.4873285\ttotal: 2m 32s\tremaining: 1m 15s\n",
            "668:\tlearn: 140.4873147\ttotal: 2m 32s\tremaining: 1m 15s\n",
            "669:\tlearn: 140.4873037\ttotal: 2m 32s\tremaining: 1m 15s\n",
            "670:\tlearn: 140.4872962\ttotal: 2m 33s\tremaining: 1m 15s\n",
            "671:\tlearn: 140.4871931\ttotal: 2m 33s\tremaining: 1m 14s\n",
            "672:\tlearn: 140.4871788\ttotal: 2m 33s\tremaining: 1m 14s\n",
            "673:\tlearn: 140.4871583\ttotal: 2m 33s\tremaining: 1m 14s\n",
            "674:\tlearn: 140.4871474\ttotal: 2m 34s\tremaining: 1m 14s\n",
            "675:\tlearn: 140.4871295\ttotal: 2m 34s\tremaining: 1m 13s\n",
            "676:\tlearn: 140.4871252\ttotal: 2m 34s\tremaining: 1m 13s\n",
            "677:\tlearn: 140.4871225\ttotal: 2m 34s\tremaining: 1m 13s\n",
            "678:\tlearn: 140.4871106\ttotal: 2m 34s\tremaining: 1m 13s\n",
            "679:\tlearn: 140.4871002\ttotal: 2m 35s\tremaining: 1m 13s\n",
            "680:\tlearn: 140.4870761\ttotal: 2m 35s\tremaining: 1m 12s\n",
            "681:\tlearn: 140.4870713\ttotal: 2m 35s\tremaining: 1m 12s\n",
            "682:\tlearn: 140.4870631\ttotal: 2m 35s\tremaining: 1m 12s\n",
            "683:\tlearn: 140.4870506\ttotal: 2m 36s\tremaining: 1m 12s\n",
            "684:\tlearn: 140.4870489\ttotal: 2m 36s\tremaining: 1m 11s\n",
            "685:\tlearn: 140.4870391\ttotal: 2m 36s\tremaining: 1m 11s\n",
            "686:\tlearn: 140.4870292\ttotal: 2m 36s\tremaining: 1m 11s\n",
            "687:\tlearn: 140.4869985\ttotal: 2m 36s\tremaining: 1m 11s\n",
            "688:\tlearn: 140.4869869\ttotal: 2m 37s\tremaining: 1m 10s\n",
            "689:\tlearn: 140.4869702\ttotal: 2m 37s\tremaining: 1m 10s\n",
            "690:\tlearn: 140.4869686\ttotal: 2m 37s\tremaining: 1m 10s\n",
            "691:\tlearn: 140.4869667\ttotal: 2m 37s\tremaining: 1m 10s\n",
            "692:\tlearn: 140.4869603\ttotal: 2m 38s\tremaining: 1m 10s\n",
            "693:\tlearn: 140.4869581\ttotal: 2m 38s\tremaining: 1m 9s\n",
            "694:\tlearn: 140.4869453\ttotal: 2m 38s\tremaining: 1m 9s\n",
            "695:\tlearn: 140.4869428\ttotal: 2m 38s\tremaining: 1m 9s\n",
            "696:\tlearn: 140.4869415\ttotal: 2m 38s\tremaining: 1m 9s\n",
            "697:\tlearn: 140.4834901\ttotal: 2m 39s\tremaining: 1m 8s\n",
            "698:\tlearn: 140.4834610\ttotal: 2m 39s\tremaining: 1m 8s\n",
            "699:\tlearn: 140.4834509\ttotal: 2m 39s\tremaining: 1m 8s\n",
            "700:\tlearn: 140.4834499\ttotal: 2m 39s\tremaining: 1m 8s\n",
            "701:\tlearn: 140.4834499\ttotal: 2m 40s\tremaining: 1m 7s\n",
            "702:\tlearn: 140.4832848\ttotal: 2m 40s\tremaining: 1m 7s\n",
            "703:\tlearn: 140.4832847\ttotal: 2m 40s\tremaining: 1m 7s\n",
            "704:\tlearn: 140.4808222\ttotal: 2m 40s\tremaining: 1m 7s\n",
            "705:\tlearn: 140.4808042\ttotal: 2m 40s\tremaining: 1m 7s\n",
            "706:\tlearn: 140.4808037\ttotal: 2m 41s\tremaining: 1m 6s\n",
            "707:\tlearn: 140.4808032\ttotal: 2m 41s\tremaining: 1m 6s\n",
            "708:\tlearn: 140.4808006\ttotal: 2m 41s\tremaining: 1m 6s\n",
            "709:\tlearn: 140.4808005\ttotal: 2m 41s\tremaining: 1m 6s\n",
            "710:\tlearn: 140.4808004\ttotal: 2m 42s\tremaining: 1m 5s\n",
            "711:\tlearn: 140.4808004\ttotal: 2m 42s\tremaining: 1m 5s\n",
            "712:\tlearn: 140.4807998\ttotal: 2m 42s\tremaining: 1m 5s\n",
            "713:\tlearn: 140.4807997\ttotal: 2m 42s\tremaining: 1m 5s\n",
            "714:\tlearn: 140.4807920\ttotal: 2m 43s\tremaining: 1m 5s\n",
            "715:\tlearn: 140.4807649\ttotal: 2m 43s\tremaining: 1m 4s\n",
            "716:\tlearn: 140.4807306\ttotal: 2m 43s\tremaining: 1m 4s\n",
            "717:\tlearn: 140.4807079\ttotal: 2m 43s\tremaining: 1m 4s\n",
            "718:\tlearn: 140.4807056\ttotal: 2m 44s\tremaining: 1m 4s\n",
            "719:\tlearn: 140.4807044\ttotal: 2m 44s\tremaining: 1m 3s\n",
            "720:\tlearn: 140.4807027\ttotal: 2m 44s\tremaining: 1m 3s\n",
            "721:\tlearn: 140.4779421\ttotal: 2m 44s\tremaining: 1m 3s\n",
            "722:\tlearn: 140.4754979\ttotal: 2m 45s\tremaining: 1m 3s\n",
            "723:\tlearn: 140.4754470\ttotal: 2m 45s\tremaining: 1m 3s\n",
            "724:\tlearn: 140.4742119\ttotal: 2m 45s\tremaining: 1m 2s\n",
            "725:\tlearn: 140.4741801\ttotal: 2m 45s\tremaining: 1m 2s\n",
            "726:\tlearn: 140.4741797\ttotal: 2m 46s\tremaining: 1m 2s\n",
            "727:\tlearn: 140.4741612\ttotal: 2m 46s\tremaining: 1m 2s\n",
            "728:\tlearn: 140.4741548\ttotal: 2m 46s\tremaining: 1m 1s\n",
            "729:\tlearn: 140.4741492\ttotal: 2m 46s\tremaining: 1m 1s\n",
            "730:\tlearn: 140.4741484\ttotal: 2m 47s\tremaining: 1m 1s\n",
            "731:\tlearn: 140.4736786\ttotal: 2m 47s\tremaining: 1m 1s\n",
            "732:\tlearn: 140.4736779\ttotal: 2m 47s\tremaining: 1m 1s\n",
            "733:\tlearn: 140.4724237\ttotal: 2m 47s\tremaining: 1m\n",
            "734:\tlearn: 140.4724207\ttotal: 2m 48s\tremaining: 1m\n",
            "735:\tlearn: 140.4724199\ttotal: 2m 48s\tremaining: 1m\n",
            "736:\tlearn: 140.4724198\ttotal: 2m 48s\tremaining: 1m\n",
            "737:\tlearn: 140.4724140\ttotal: 2m 48s\tremaining: 59.9s\n",
            "738:\tlearn: 140.4581708\ttotal: 2m 48s\tremaining: 59.7s\n",
            "739:\tlearn: 140.4581708\ttotal: 2m 49s\tremaining: 59.4s\n",
            "740:\tlearn: 140.4581708\ttotal: 2m 49s\tremaining: 59.2s\n",
            "741:\tlearn: 140.4580612\ttotal: 2m 49s\tremaining: 59s\n",
            "742:\tlearn: 140.4580609\ttotal: 2m 49s\tremaining: 58.7s\n",
            "743:\tlearn: 140.4580575\ttotal: 2m 50s\tremaining: 58.5s\n",
            "744:\tlearn: 140.4578544\ttotal: 2m 50s\tremaining: 58.3s\n",
            "745:\tlearn: 140.4578544\ttotal: 2m 50s\tremaining: 58.1s\n",
            "746:\tlearn: 140.4578543\ttotal: 2m 50s\tremaining: 57.8s\n",
            "747:\tlearn: 140.4578538\ttotal: 2m 50s\tremaining: 57.6s\n",
            "748:\tlearn: 140.4578537\ttotal: 2m 51s\tremaining: 57.4s\n",
            "749:\tlearn: 140.4578518\ttotal: 2m 51s\tremaining: 57.1s\n",
            "750:\tlearn: 140.4578508\ttotal: 2m 51s\tremaining: 56.9s\n",
            "751:\tlearn: 140.4578508\ttotal: 2m 51s\tremaining: 56.7s\n",
            "752:\tlearn: 140.4578507\ttotal: 2m 52s\tremaining: 56.4s\n",
            "753:\tlearn: 140.4578496\ttotal: 2m 52s\tremaining: 56.2s\n",
            "754:\tlearn: 140.4578436\ttotal: 2m 52s\tremaining: 56s\n",
            "755:\tlearn: 140.4578389\ttotal: 2m 52s\tremaining: 55.7s\n",
            "756:\tlearn: 140.4578386\ttotal: 2m 52s\tremaining: 55.5s\n",
            "757:\tlearn: 140.4578306\ttotal: 2m 53s\tremaining: 55.3s\n",
            "758:\tlearn: 140.4578270\ttotal: 2m 53s\tremaining: 55s\n",
            "759:\tlearn: 140.4578269\ttotal: 2m 53s\tremaining: 54.8s\n",
            "760:\tlearn: 140.4578066\ttotal: 2m 53s\tremaining: 54.6s\n",
            "761:\tlearn: 140.4578060\ttotal: 2m 54s\tremaining: 54.4s\n",
            "762:\tlearn: 140.4578059\ttotal: 2m 54s\tremaining: 54.1s\n",
            "763:\tlearn: 140.4524553\ttotal: 2m 54s\tremaining: 53.9s\n",
            "764:\tlearn: 140.4524068\ttotal: 2m 54s\tremaining: 53.7s\n",
            "765:\tlearn: 140.4524067\ttotal: 2m 54s\tremaining: 53.4s\n",
            "766:\tlearn: 140.4523938\ttotal: 2m 55s\tremaining: 53.2s\n",
            "767:\tlearn: 140.4523938\ttotal: 2m 55s\tremaining: 53s\n",
            "768:\tlearn: 140.4523938\ttotal: 2m 55s\tremaining: 52.8s\n",
            "769:\tlearn: 140.4523934\ttotal: 2m 55s\tremaining: 52.5s\n",
            "770:\tlearn: 140.4523933\ttotal: 2m 56s\tremaining: 52.3s\n",
            "771:\tlearn: 140.4523911\ttotal: 2m 56s\tremaining: 52.1s\n",
            "772:\tlearn: 140.4523911\ttotal: 2m 56s\tremaining: 51.9s\n",
            "773:\tlearn: 140.4523875\ttotal: 2m 56s\tremaining: 51.6s\n",
            "774:\tlearn: 140.4523874\ttotal: 2m 57s\tremaining: 51.4s\n",
            "775:\tlearn: 140.4523874\ttotal: 2m 57s\tremaining: 51.2s\n",
            "776:\tlearn: 140.4523846\ttotal: 2m 57s\tremaining: 51s\n",
            "777:\tlearn: 140.4521882\ttotal: 2m 57s\tremaining: 50.7s\n",
            "778:\tlearn: 140.4520110\ttotal: 2m 57s\tremaining: 50.5s\n",
            "779:\tlearn: 140.4519522\ttotal: 2m 58s\tremaining: 50.3s\n",
            "780:\tlearn: 140.4519522\ttotal: 2m 58s\tremaining: 50s\n",
            "781:\tlearn: 140.4519517\ttotal: 2m 58s\tremaining: 49.8s\n",
            "782:\tlearn: 140.4519472\ttotal: 2m 58s\tremaining: 49.6s\n",
            "783:\tlearn: 140.4515805\ttotal: 2m 59s\tremaining: 49.4s\n",
            "784:\tlearn: 140.4515805\ttotal: 2m 59s\tremaining: 49.1s\n",
            "785:\tlearn: 140.4515460\ttotal: 2m 59s\tremaining: 48.9s\n",
            "786:\tlearn: 140.4513198\ttotal: 2m 59s\tremaining: 48.7s\n",
            "787:\tlearn: 140.4513194\ttotal: 3m\tremaining: 48.5s\n",
            "788:\tlearn: 140.4513090\ttotal: 3m\tremaining: 48.3s\n",
            "789:\tlearn: 140.4505132\ttotal: 3m\tremaining: 48s\n",
            "790:\tlearn: 140.4504480\ttotal: 3m\tremaining: 47.8s\n",
            "791:\tlearn: 140.4504446\ttotal: 3m 1s\tremaining: 47.6s\n",
            "792:\tlearn: 140.4504408\ttotal: 3m 1s\tremaining: 47.4s\n",
            "793:\tlearn: 140.4504390\ttotal: 3m 1s\tremaining: 47.2s\n",
            "794:\tlearn: 140.4504387\ttotal: 3m 1s\tremaining: 46.9s\n",
            "795:\tlearn: 140.4444057\ttotal: 3m 2s\tremaining: 46.7s\n",
            "796:\tlearn: 140.4444045\ttotal: 3m 2s\tremaining: 46.5s\n",
            "797:\tlearn: 140.4332682\ttotal: 3m 2s\tremaining: 46.3s\n",
            "798:\tlearn: 140.4331850\ttotal: 3m 2s\tremaining: 46s\n",
            "799:\tlearn: 140.4286660\ttotal: 3m 3s\tremaining: 45.8s\n",
            "800:\tlearn: 140.4285480\ttotal: 3m 3s\tremaining: 45.6s\n",
            "801:\tlearn: 140.4280506\ttotal: 3m 3s\tremaining: 45.4s\n",
            "802:\tlearn: 140.3581357\ttotal: 3m 3s\tremaining: 45.1s\n",
            "803:\tlearn: 140.3581355\ttotal: 3m 4s\tremaining: 44.9s\n",
            "804:\tlearn: 140.3581355\ttotal: 3m 4s\tremaining: 44.7s\n",
            "805:\tlearn: 140.3581335\ttotal: 3m 4s\tremaining: 44.4s\n",
            "806:\tlearn: 140.3581320\ttotal: 3m 4s\tremaining: 44.2s\n",
            "807:\tlearn: 140.3581147\ttotal: 3m 5s\tremaining: 44s\n",
            "808:\tlearn: 140.3580771\ttotal: 3m 5s\tremaining: 43.8s\n",
            "809:\tlearn: 140.3580761\ttotal: 3m 5s\tremaining: 43.5s\n",
            "810:\tlearn: 140.3580759\ttotal: 3m 5s\tremaining: 43.3s\n",
            "811:\tlearn: 140.3580754\ttotal: 3m 6s\tremaining: 43.1s\n",
            "812:\tlearn: 140.3580754\ttotal: 3m 6s\tremaining: 42.8s\n",
            "813:\tlearn: 140.3580746\ttotal: 3m 6s\tremaining: 42.6s\n",
            "814:\tlearn: 140.3580737\ttotal: 3m 6s\tremaining: 42.4s\n",
            "815:\tlearn: 140.3580736\ttotal: 3m 6s\tremaining: 42.1s\n",
            "816:\tlearn: 140.3580672\ttotal: 3m 7s\tremaining: 41.9s\n",
            "817:\tlearn: 140.3569057\ttotal: 3m 7s\tremaining: 41.7s\n",
            "818:\tlearn: 140.3558607\ttotal: 3m 7s\tremaining: 41.5s\n",
            "819:\tlearn: 140.3556105\ttotal: 3m 7s\tremaining: 41.2s\n",
            "820:\tlearn: 140.3556104\ttotal: 3m 8s\tremaining: 41s\n",
            "821:\tlearn: 140.3555877\ttotal: 3m 8s\tremaining: 40.8s\n",
            "822:\tlearn: 140.3555877\ttotal: 3m 8s\tremaining: 40.5s\n",
            "823:\tlearn: 140.3555875\ttotal: 3m 8s\tremaining: 40.3s\n",
            "824:\tlearn: 140.3555718\ttotal: 3m 8s\tremaining: 40.1s\n",
            "825:\tlearn: 140.3555622\ttotal: 3m 9s\tremaining: 39.8s\n",
            "826:\tlearn: 140.3555591\ttotal: 3m 9s\tremaining: 39.6s\n",
            "827:\tlearn: 140.3555590\ttotal: 3m 9s\tremaining: 39.4s\n",
            "828:\tlearn: 140.3555589\ttotal: 3m 9s\tremaining: 39.2s\n",
            "829:\tlearn: 140.3555588\ttotal: 3m 10s\tremaining: 38.9s\n",
            "830:\tlearn: 140.3555587\ttotal: 3m 10s\tremaining: 38.7s\n",
            "831:\tlearn: 140.3555559\ttotal: 3m 10s\tremaining: 38.5s\n",
            "832:\tlearn: 140.3555559\ttotal: 3m 10s\tremaining: 38.2s\n",
            "833:\tlearn: 140.3555555\ttotal: 3m 10s\tremaining: 38s\n",
            "834:\tlearn: 140.3555436\ttotal: 3m 11s\tremaining: 37.8s\n",
            "835:\tlearn: 140.3555420\ttotal: 3m 11s\tremaining: 37.5s\n",
            "836:\tlearn: 140.3555363\ttotal: 3m 11s\tremaining: 37.3s\n",
            "837:\tlearn: 140.3547941\ttotal: 3m 11s\tremaining: 37.1s\n",
            "838:\tlearn: 140.3547847\ttotal: 3m 12s\tremaining: 36.9s\n",
            "839:\tlearn: 140.3547825\ttotal: 3m 12s\tremaining: 36.6s\n",
            "840:\tlearn: 140.3547825\ttotal: 3m 12s\tremaining: 36.4s\n",
            "841:\tlearn: 140.3547825\ttotal: 3m 12s\tremaining: 36.2s\n",
            "842:\tlearn: 140.3547815\ttotal: 3m 12s\tremaining: 35.9s\n",
            "843:\tlearn: 140.3547811\ttotal: 3m 13s\tremaining: 35.7s\n",
            "844:\tlearn: 140.3547808\ttotal: 3m 13s\tremaining: 35.5s\n",
            "845:\tlearn: 140.3547532\ttotal: 3m 13s\tremaining: 35.3s\n",
            "846:\tlearn: 140.3547526\ttotal: 3m 13s\tremaining: 35s\n",
            "847:\tlearn: 140.3547525\ttotal: 3m 14s\tremaining: 34.8s\n",
            "848:\tlearn: 140.3547523\ttotal: 3m 14s\tremaining: 34.6s\n",
            "849:\tlearn: 140.3547247\ttotal: 3m 14s\tremaining: 34.3s\n",
            "850:\tlearn: 140.3546570\ttotal: 3m 14s\tremaining: 34.1s\n",
            "851:\tlearn: 140.3546568\ttotal: 3m 14s\tremaining: 33.9s\n",
            "852:\tlearn: 140.3546559\ttotal: 3m 15s\tremaining: 33.6s\n",
            "853:\tlearn: 140.3546545\ttotal: 3m 15s\tremaining: 33.4s\n",
            "854:\tlearn: 140.3546537\ttotal: 3m 15s\tremaining: 33.2s\n",
            "855:\tlearn: 140.3546526\ttotal: 3m 15s\tremaining: 32.9s\n",
            "856:\tlearn: 140.3546496\ttotal: 3m 16s\tremaining: 32.7s\n",
            "857:\tlearn: 140.3546481\ttotal: 3m 16s\tremaining: 32.5s\n",
            "858:\tlearn: 140.3546333\ttotal: 3m 16s\tremaining: 32.3s\n",
            "859:\tlearn: 140.3546285\ttotal: 3m 16s\tremaining: 32s\n",
            "860:\tlearn: 140.3545463\ttotal: 3m 16s\tremaining: 31.8s\n",
            "861:\tlearn: 140.3544679\ttotal: 3m 17s\tremaining: 31.6s\n",
            "862:\tlearn: 140.3544579\ttotal: 3m 17s\tremaining: 31.3s\n",
            "863:\tlearn: 140.3544579\ttotal: 3m 17s\tremaining: 31.1s\n",
            "864:\tlearn: 140.3544562\ttotal: 3m 17s\tremaining: 30.9s\n",
            "865:\tlearn: 140.3544556\ttotal: 3m 18s\tremaining: 30.6s\n",
            "866:\tlearn: 140.3544460\ttotal: 3m 18s\tremaining: 30.4s\n",
            "867:\tlearn: 140.3544460\ttotal: 3m 18s\tremaining: 30.2s\n",
            "868:\tlearn: 140.3541555\ttotal: 3m 18s\tremaining: 29.9s\n",
            "869:\tlearn: 140.3541554\ttotal: 3m 18s\tremaining: 29.7s\n",
            "870:\tlearn: 140.3541360\ttotal: 3m 19s\tremaining: 29.5s\n",
            "871:\tlearn: 140.3531066\ttotal: 3m 19s\tremaining: 29.3s\n",
            "872:\tlearn: 140.3529248\ttotal: 3m 19s\tremaining: 29s\n",
            "873:\tlearn: 140.3529129\ttotal: 3m 19s\tremaining: 28.8s\n",
            "874:\tlearn: 140.3529128\ttotal: 3m 19s\tremaining: 28.6s\n",
            "875:\tlearn: 140.3528949\ttotal: 3m 20s\tremaining: 28.3s\n",
            "876:\tlearn: 140.3528932\ttotal: 3m 20s\tremaining: 28.1s\n",
            "877:\tlearn: 140.3528720\ttotal: 3m 20s\tremaining: 27.9s\n",
            "878:\tlearn: 140.3528702\ttotal: 3m 20s\tremaining: 27.6s\n",
            "879:\tlearn: 140.3528667\ttotal: 3m 21s\tremaining: 27.4s\n",
            "880:\tlearn: 140.3528659\ttotal: 3m 21s\tremaining: 27.2s\n",
            "881:\tlearn: 140.3528651\ttotal: 3m 21s\tremaining: 26.9s\n",
            "882:\tlearn: 140.3527716\ttotal: 3m 21s\tremaining: 26.7s\n",
            "883:\tlearn: 140.3527700\ttotal: 3m 21s\tremaining: 26.5s\n",
            "884:\tlearn: 140.3527693\ttotal: 3m 22s\tremaining: 26.3s\n",
            "885:\tlearn: 140.3527689\ttotal: 3m 22s\tremaining: 26s\n",
            "886:\tlearn: 140.3527649\ttotal: 3m 22s\tremaining: 25.8s\n",
            "887:\tlearn: 140.3527648\ttotal: 3m 22s\tremaining: 25.6s\n",
            "888:\tlearn: 140.3527645\ttotal: 3m 22s\tremaining: 25.3s\n",
            "889:\tlearn: 140.3526715\ttotal: 3m 23s\tremaining: 25.1s\n",
            "890:\tlearn: 140.3526714\ttotal: 3m 23s\tremaining: 24.9s\n",
            "891:\tlearn: 140.3526712\ttotal: 3m 23s\tremaining: 24.7s\n",
            "892:\tlearn: 140.3526484\ttotal: 3m 23s\tremaining: 24.4s\n",
            "893:\tlearn: 140.3526473\ttotal: 3m 24s\tremaining: 24.2s\n",
            "894:\tlearn: 140.3526467\ttotal: 3m 24s\tremaining: 24s\n",
            "895:\tlearn: 140.3526129\ttotal: 3m 24s\tremaining: 23.7s\n",
            "896:\tlearn: 140.3526119\ttotal: 3m 24s\tremaining: 23.5s\n",
            "897:\tlearn: 140.3526119\ttotal: 3m 24s\tremaining: 23.3s\n",
            "898:\tlearn: 140.3526119\ttotal: 3m 25s\tremaining: 23s\n",
            "899:\tlearn: 140.3526118\ttotal: 3m 25s\tremaining: 22.8s\n",
            "900:\tlearn: 140.3524873\ttotal: 3m 25s\tremaining: 22.6s\n",
            "901:\tlearn: 140.3524846\ttotal: 3m 25s\tremaining: 22.4s\n",
            "902:\tlearn: 140.3521061\ttotal: 3m 26s\tremaining: 22.1s\n",
            "903:\tlearn: 140.3521056\ttotal: 3m 26s\tremaining: 21.9s\n",
            "904:\tlearn: 140.3515356\ttotal: 3m 26s\tremaining: 21.7s\n",
            "905:\tlearn: 140.3515148\ttotal: 3m 26s\tremaining: 21.4s\n",
            "906:\tlearn: 140.3515099\ttotal: 3m 26s\tremaining: 21.2s\n",
            "907:\tlearn: 140.3514884\ttotal: 3m 27s\tremaining: 21s\n",
            "908:\tlearn: 140.3514884\ttotal: 3m 27s\tremaining: 20.8s\n",
            "909:\tlearn: 140.3514884\ttotal: 3m 27s\tremaining: 20.5s\n",
            "910:\tlearn: 140.3514636\ttotal: 3m 27s\tremaining: 20.3s\n",
            "911:\tlearn: 140.3513972\ttotal: 3m 28s\tremaining: 20.1s\n",
            "912:\tlearn: 140.3513934\ttotal: 3m 28s\tremaining: 19.8s\n",
            "913:\tlearn: 140.3513933\ttotal: 3m 28s\tremaining: 19.6s\n",
            "914:\tlearn: 140.3513931\ttotal: 3m 28s\tremaining: 19.4s\n",
            "915:\tlearn: 140.3513923\ttotal: 3m 28s\tremaining: 19.2s\n",
            "916:\tlearn: 140.3513923\ttotal: 3m 29s\tremaining: 18.9s\n",
            "917:\tlearn: 140.3513922\ttotal: 3m 29s\tremaining: 18.7s\n",
            "918:\tlearn: 140.3513922\ttotal: 3m 29s\tremaining: 18.5s\n",
            "919:\tlearn: 140.3513906\ttotal: 3m 29s\tremaining: 18.2s\n",
            "920:\tlearn: 140.3513524\ttotal: 3m 30s\tremaining: 18s\n",
            "921:\tlearn: 140.3513506\ttotal: 3m 30s\tremaining: 17.8s\n",
            "922:\tlearn: 140.3513504\ttotal: 3m 30s\tremaining: 17.6s\n",
            "923:\tlearn: 140.3476178\ttotal: 3m 30s\tremaining: 17.3s\n",
            "924:\tlearn: 140.3414918\ttotal: 3m 30s\tremaining: 17.1s\n",
            "925:\tlearn: 140.3414918\ttotal: 3m 31s\tremaining: 16.9s\n",
            "926:\tlearn: 140.3413848\ttotal: 3m 31s\tremaining: 16.6s\n",
            "927:\tlearn: 140.3413605\ttotal: 3m 31s\tremaining: 16.4s\n",
            "928:\tlearn: 140.3413597\ttotal: 3m 31s\tremaining: 16.2s\n",
            "929:\tlearn: 140.3413597\ttotal: 3m 32s\tremaining: 16s\n",
            "930:\tlearn: 140.3413597\ttotal: 3m 32s\tremaining: 15.7s\n",
            "931:\tlearn: 140.3395323\ttotal: 3m 32s\tremaining: 15.5s\n",
            "932:\tlearn: 140.3395315\ttotal: 3m 32s\tremaining: 15.3s\n",
            "933:\tlearn: 140.3394385\ttotal: 3m 32s\tremaining: 15s\n",
            "934:\tlearn: 140.3394378\ttotal: 3m 33s\tremaining: 14.8s\n",
            "935:\tlearn: 140.3293858\ttotal: 3m 33s\tremaining: 14.6s\n",
            "936:\tlearn: 140.3293745\ttotal: 3m 33s\tremaining: 14.4s\n",
            "937:\tlearn: 140.3293743\ttotal: 3m 33s\tremaining: 14.1s\n",
            "938:\tlearn: 140.3291275\ttotal: 3m 34s\tremaining: 13.9s\n",
            "939:\tlearn: 140.3291238\ttotal: 3m 34s\tremaining: 13.7s\n",
            "940:\tlearn: 140.3291032\ttotal: 3m 34s\tremaining: 13.4s\n",
            "941:\tlearn: 140.3291001\ttotal: 3m 34s\tremaining: 13.2s\n",
            "942:\tlearn: 140.3290959\ttotal: 3m 34s\tremaining: 13s\n",
            "943:\tlearn: 140.3290026\ttotal: 3m 35s\tremaining: 12.8s\n",
            "944:\tlearn: 140.3290020\ttotal: 3m 35s\tremaining: 12.5s\n",
            "945:\tlearn: 140.3289968\ttotal: 3m 35s\tremaining: 12.3s\n",
            "946:\tlearn: 140.3283809\ttotal: 3m 35s\tremaining: 12.1s\n",
            "947:\tlearn: 140.3283733\ttotal: 3m 36s\tremaining: 11.8s\n",
            "948:\tlearn: 140.3280117\ttotal: 3m 36s\tremaining: 11.6s\n",
            "949:\tlearn: 140.3279961\ttotal: 3m 36s\tremaining: 11.4s\n",
            "950:\tlearn: 140.3275746\ttotal: 3m 36s\tremaining: 11.2s\n",
            "951:\tlearn: 140.3272806\ttotal: 3m 36s\tremaining: 10.9s\n",
            "952:\tlearn: 140.3266854\ttotal: 3m 37s\tremaining: 10.7s\n",
            "953:\tlearn: 140.3266845\ttotal: 3m 37s\tremaining: 10.5s\n",
            "954:\tlearn: 140.3266845\ttotal: 3m 37s\tremaining: 10.3s\n",
            "955:\tlearn: 140.3266826\ttotal: 3m 37s\tremaining: 10s\n",
            "956:\tlearn: 140.3266780\ttotal: 3m 38s\tremaining: 9.79s\n",
            "957:\tlearn: 140.3244427\ttotal: 3m 38s\tremaining: 9.57s\n",
            "958:\tlearn: 140.3244241\ttotal: 3m 38s\tremaining: 9.34s\n",
            "959:\tlearn: 140.3219757\ttotal: 3m 38s\tremaining: 9.11s\n",
            "960:\tlearn: 140.3219612\ttotal: 3m 38s\tremaining: 8.88s\n",
            "961:\tlearn: 140.3218626\ttotal: 3m 39s\tremaining: 8.66s\n",
            "962:\tlearn: 140.3218562\ttotal: 3m 39s\tremaining: 8.43s\n",
            "963:\tlearn: 140.3218559\ttotal: 3m 39s\tremaining: 8.2s\n",
            "964:\tlearn: 140.3181277\ttotal: 3m 39s\tremaining: 7.97s\n",
            "965:\tlearn: 140.3181275\ttotal: 3m 40s\tremaining: 7.75s\n",
            "966:\tlearn: 140.3157214\ttotal: 3m 40s\tremaining: 7.52s\n",
            "967:\tlearn: 140.2863008\ttotal: 3m 40s\tremaining: 7.29s\n",
            "968:\tlearn: 140.2863008\ttotal: 3m 40s\tremaining: 7.06s\n",
            "969:\tlearn: 140.2596052\ttotal: 3m 40s\tremaining: 6.83s\n",
            "970:\tlearn: 140.2578179\ttotal: 3m 41s\tremaining: 6.61s\n",
            "971:\tlearn: 140.2562071\ttotal: 3m 41s\tremaining: 6.38s\n",
            "972:\tlearn: 140.2562069\ttotal: 3m 41s\tremaining: 6.15s\n",
            "973:\tlearn: 140.2562012\ttotal: 3m 41s\tremaining: 5.92s\n",
            "974:\tlearn: 140.2561981\ttotal: 3m 42s\tremaining: 5.7s\n",
            "975:\tlearn: 140.2561963\ttotal: 3m 42s\tremaining: 5.47s\n",
            "976:\tlearn: 140.2561958\ttotal: 3m 42s\tremaining: 5.24s\n",
            "977:\tlearn: 140.2561958\ttotal: 3m 42s\tremaining: 5.01s\n",
            "978:\tlearn: 140.2555783\ttotal: 3m 43s\tremaining: 4.78s\n",
            "979:\tlearn: 140.2555754\ttotal: 3m 43s\tremaining: 4.56s\n",
            "980:\tlearn: 140.2555751\ttotal: 3m 43s\tremaining: 4.33s\n",
            "981:\tlearn: 140.2547593\ttotal: 3m 43s\tremaining: 4.1s\n",
            "982:\tlearn: 140.2530072\ttotal: 3m 43s\tremaining: 3.87s\n",
            "983:\tlearn: 140.2529984\ttotal: 3m 44s\tremaining: 3.64s\n",
            "984:\tlearn: 140.2529692\ttotal: 3m 44s\tremaining: 3.42s\n",
            "985:\tlearn: 140.2529692\ttotal: 3m 44s\tremaining: 3.19s\n",
            "986:\tlearn: 140.2526772\ttotal: 3m 44s\tremaining: 2.96s\n",
            "987:\tlearn: 140.2526546\ttotal: 3m 44s\tremaining: 2.73s\n",
            "988:\tlearn: 140.2526534\ttotal: 3m 45s\tremaining: 2.5s\n",
            "989:\tlearn: 140.2526530\ttotal: 3m 45s\tremaining: 2.28s\n",
            "990:\tlearn: 140.2526528\ttotal: 3m 45s\tremaining: 2.05s\n",
            "991:\tlearn: 140.2526288\ttotal: 3m 45s\tremaining: 1.82s\n",
            "992:\tlearn: 140.2526118\ttotal: 3m 46s\tremaining: 1.59s\n",
            "993:\tlearn: 140.2301550\ttotal: 3m 46s\tremaining: 1.37s\n",
            "994:\tlearn: 140.2301549\ttotal: 3m 46s\tremaining: 1.14s\n",
            "995:\tlearn: 140.2301514\ttotal: 3m 46s\tremaining: 911ms\n",
            "996:\tlearn: 140.2301083\ttotal: 3m 46s\tremaining: 683ms\n",
            "997:\tlearn: 140.2301068\ttotal: 3m 47s\tremaining: 455ms\n",
            "998:\tlearn: 140.2298248\ttotal: 3m 47s\tremaining: 228ms\n",
            "999:\tlearn: 140.2293235\ttotal: 3m 47s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('preprocessor',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('num',\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('imputer',\n",
              "                                                                   SimpleImputer(add_indicator=False,\n",
              "                                                                                 copy=True,\n",
              "                                                                                 fill_value=None,\n",
              "                                                                                 missing_values=nan,\n",
              "                                                                                 strategy='median',\n",
              "                                                                                 verbose=0)),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler(copy=True,\n",
              "                                                                                  with_mean...\n",
              "       'text_digits_count', 'user_statuses_count', 'text_usertag_count',\n",
              "       'text_has_word_covid', 'text_proc_punctuation_to_alpha', 'mentions_int',\n",
              "       'text_proc_alphas_count_to_text_alphas_count', 'user_friends_count',\n",
              "       'text_proc_length_to_text_length', 'text_lines_count',\n",
              "       'text_hashtags_count', 'vfollowers'],\n",
              "      dtype='object'))],\n",
              "                                   verbose=False)),\n",
              "                ('classifier',\n",
              "                 <catboost.core.CatBoostRegressor object at 0x7f55e15dcc50>)],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3h-D8HMBkN5",
        "outputId": "cf0361b1-bf4c-4c58-9f8f-12bfc1bf4abc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_10_pro = clf1_pro.predict(X_test[X_train.columns[cat_features]])\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_10_pro))\n",
        "print(\"MAE score on zero perediction: %.3f\" % MAE(y_test, np.zeros(len(y_test))))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 143.925\n",
            "MAE score on zero perediction: 150.769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr7BqpqwC2p3"
      },
      "source": [
        "y_pred_test_pro = clf1_pro.predict(df_test_final[X_train.columns[cat_features]].replace([np.inf, -np.inf], np.nan))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A6YYeIpC2sz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDrKkoO0CrGU"
      },
      "source": [
        "y_pred_test_15 = clf1.predict(df_test_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan))\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnNIDcwBCxWR"
      },
      "source": [
        "clf2 = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', CatBoostRegressor(iterations=10000, depth=7, loss_function ='MAE', eval_metric = 'MAE', random_seed=57, learning_rate=0.1,l2_leaf_reg=6))])\n"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N4s22ATJmVu"
      },
      "source": [
        "clf2.fit(X_train[100000:200000], y_train[100000:200000])\n",
        "print(\"model score: %.3f\" % clf2.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2kjZnyjC8ip",
        "outputId": "22113948-bd66-4592-c2f0-40dab0ae100a"
      },
      "source": [
        "y_pred_20 = clf2.predict(X_test)\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_20))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 145.388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1uIOwRiDJ4t"
      },
      "source": [
        "y_pred_test_20 = clf2.predict(df_test_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan))"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4HG0EoECg__"
      },
      "source": [
        "clf3 = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', CatBoostRegressor(iterations=10000, depth=7, loss_function ='MAE', eval_metric = 'MAE', random_seed=57, learning_rate=0.1,l2_leaf_reg=6))])\n"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16WUzuPUgVh3"
      },
      "source": [
        "clf3.fit(X_train[200000:300000], y_train[200000:300000])\n",
        "print(\"model score: %.3f\" % clf3.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtMvettjgbiv",
        "outputId": "39d15394-4915-4f51-8c64-cde3ecae6963"
      },
      "source": [
        "y_pred_30 = clf3.predict(X_test)\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_30))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 146.812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArYs70JNDTp2"
      },
      "source": [
        "y_pred_test_30 = clf3.predict(df_test_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan))"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VrwpiEsDDT5"
      },
      "source": [
        "clf4 = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', CatBoostRegressor(iterations=10000, depth=7, loss_function ='MAE', eval_metric = 'MAE', random_seed=57, learning_rate=0.1,l2_leaf_reg=6))])\n"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHyf3Egzgeiq"
      },
      "source": [
        "clf4.fit(X_train[300000:400000], y_train[300000:400000])\n",
        "print(\"model score: %.3f\" % clf4.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHIL2WVGgikL",
        "outputId": "d908eb36-1496-4aca-af92-75120d22ff25"
      },
      "source": [
        "y_pred_40 = clf4.predict(X_test)\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_40))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 144.173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QenFj2CqDWUN"
      },
      "source": [
        "y_pred_test_40 = clf4.predict(df_test_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan))"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycQp8RfzgsSg",
        "outputId": "4e3211e9-43e6-42b5-d901-abb62016cece"
      },
      "source": [
        "y_pred_mean = (y_pred_10 + y_pred_20 + y_pred_30 + y_pred_40) / 4\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_mean))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 142.474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU7oIKJoPyh2",
        "outputId": "76e98a87-313b-4d6c-fc21-df1efe5d5a2f"
      },
      "source": [
        "y_pred_mean_2 = (y_pred_10 + y_pred_20) / 2\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_mean_2))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 142.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LuIWPEQPWb5",
        "outputId": "b523de30-c601-4cf5-ca1e-47cb2b0ac544"
      },
      "source": [
        "nc = len(y_pred_mean)\n",
        "y_pred_mean_ceil = np.zeros(nc)\n",
        "for i in range(nc):\n",
        "  if y_pred_mean[i] > 0:\n",
        "    y_pred_mean_ceil[i] = ceil(y_pred_mean[i])\n",
        "\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_mean_ceil))\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, np.zeros(nc)))"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 142.587\n",
            "MAE score: 141.023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TK66JW-QJ8Y",
        "outputId": "db11229d-fa47-448f-9526-ad5ff970987c"
      },
      "source": [
        "nc = len(y_pred_mean)\n",
        "y_pred_mean_floor = np.zeros(nc)\n",
        "for i in range(nc):\n",
        "  if y_pred_mean[i] > 0:\n",
        "    y_pred_mean_floor[i] = floor(y_pred_mean[i])\n",
        "\n",
        "print(\"MAE score: %.3f\" % MAE(y_test, y_pred_mean_floor))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE score: 142.206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovMHsqj4gHJJ"
      },
      "source": [
        "# print(\"MAE score: %.3f\" % MAE(y_test, y_pred_40))"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yoOsj-oJva_"
      },
      "source": [
        "# y_pred = clf.predict(X_train[200000:])\n",
        "# print(\"MAE score: %.3f\" % MAE(y_train[:], y_pred))"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcdCph32DcnE"
      },
      "source": [
        "y_pred_test_mean = (y_pred_test_10 + y_pred_test_20 + y_pred_test_30 + y_pred_test_40) / 4"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdev3_-EEW4C"
      },
      "source": [
        ""
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ix9pSw7DuaP",
        "outputId": "277993af-158e-4442-d8a6-cae91ef08978"
      },
      "source": [
        "n = len(y_pred_test_10)\n",
        "# y_pred_final = np.zeros(n)\n",
        "for i in range(n):\n",
        "  if y_pred_test_10[i] < 0:\n",
        "    y_pred_test_10[i] = 0\n",
        "\n",
        "\n",
        "y_pred_test_10.min()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmsU9imjK9M-"
      },
      "source": [
        "# y_pred_test = clf.predict(df_test_final[features_numerical + features_category].replace([np.inf, -np.inf], np.nan))"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK8HRdsN4usL"
      },
      "source": [
        "### Write final prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYC_dOPb5F8Y"
      },
      "source": [
        "with open(\"CatBoost_FS_mean_predictions_350000_1k_epochs.txt\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
        "    for index, prediction in enumerate(y_pred_test_pro):\n",
        "            writer.writerow([str(665776 + index) , str(int(prediction))])"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHeZntLc40Cs"
      },
      "source": [
        "# with open(\"gbr_predictions.txt\", 'w') as f:\n",
        "#     writer = csv.writer(f)\n",
        "#     writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
        "#     for index, prediction in enumerate(y_pred_test):\n",
        "#         writer.writerow([str(eval_data['id'].iloc[index]) , str(int(prediction))])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}