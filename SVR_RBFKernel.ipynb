{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SVR_RBFKernel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IemProg/DataChallengeXINF554/blob/main/SVR_RBFKernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juLi_0abKDze"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os, sys\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-jCbaFBKJfd"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from verstack.stratified_continuous_split import scsplit \n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT7sY-ogKLa1",
        "outputId": "e8e93957-314d-45ee-962b-799ec7796754"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdWfAOZyKhUo"
      },
      "source": [
        "path = \"/content/drive/MyDrive/DataSets/\"\n",
        "path_data_train = path + \"train.csv\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvhlAfYWKjSd"
      },
      "source": [
        "train_data = pd.read_csv(path_data_train)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXun-dR6Kth0"
      },
      "source": [
        "#Non-relevant features, can not be used for SVMs models\n",
        "train_data.drop('timestamp', axis=1, inplace=True)\n",
        "train_data.drop('user_mentions', axis=1, inplace=True)\n",
        "train_data.drop('urls', axis=1, inplace=True)\n",
        "train_data.drop('hashtags', axis=1, inplace=True)\n",
        "train_data.drop('text', axis=1, inplace=True)\n",
        "train_data.drop('id', axis=1, inplace=True)\n",
        "train_data.drop('user_verified', axis=1, inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDfz6FjGtcW7",
        "outputId": "d3c413e1-6d85-4d36-b854-9602a8702bc3"
      },
      "source": [
        "nbr = train_data[train_data.retweet_count != 0].shape[0]\n",
        "nbr1 = train_data[train_data.retweet_count == 0].shape[0]\n",
        "print(\"\\t Number of rows where retweets != 0: \", nbr)\n",
        "print(\"\\t Number of rows where retweets == 0: \", nbr1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Number of rows where retweets != 0:  242974\n",
            "\t Number of rows where retweets == 0:  422803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7WR7SqstKt1",
        "outputId": "03a9126e-457b-412d-936b-1712e2e890c4"
      },
      "source": [
        "# Shuffle the Dataset.\n",
        "shuffled_train = train_data.sample(frac=1, random_state=4)\n",
        "\n",
        "# Put all the samples where they dont have zeros re-tweet in a separate dataset.\n",
        "non_zero_retweet = shuffled_train.loc[shuffled_train['retweet_count'] != 0]\n",
        "nbr_samples = non_zero_retweet.shape[0] // 1  #We will take only sixth of it\n",
        "\n",
        "#Randomly select samples observations from the zero re-tweet (majority class)\n",
        "zero_retweet = shuffled_train.loc[shuffled_train['retweet_count'] == 0].sample(n=nbr_samples, random_state=42)\n",
        "\n",
        "print(\"Shape of non_zero_retweet: \", non_zero_retweet[:nbr_samples].shape)\n",
        "print(\"Shape of zero_retweet: \", zero_retweet.shape)\n",
        "\n",
        "# Concatenate both dataframes again\n",
        "normalized_train = pd.concat([non_zero_retweet[:nbr_samples], zero_retweet])\n",
        "print(\"Normalized train dataset: \", normalized_train.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of non_zero_retweet:  (242974, 4)\n",
            "Shape of zero_retweet:  (242974, 4)\n",
            "Normalized train dataset:  (485948, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfVq__7Mz76c",
        "outputId": "372f4212-2de2-4a2d-e14e-5261d45972d6"
      },
      "source": [
        "nbr = normalized_train[normalized_train.retweet_count != 0].shape[0]\n",
        "nbr1 = normalized_train[normalized_train.retweet_count == 0].shape[0]\n",
        "print(\"\\t Number of rows in normalized_train where retweets != 0: \", nbr)\n",
        "print(\"\\t Number of rows in normalized_train where retweets == 0: \", nbr1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Number of rows in normalized_train where retweets != 0:  242974\n",
            "\t Number of rows in normalized_train where retweets == 0:  242974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsHud9F3vJ-d",
        "outputId": "df128505-4655-47bc-a490-bd6ff9a3ecef"
      },
      "source": [
        "normalized_train.columns"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['retweet_count', 'user_statuses_count', 'user_followers_count',\n",
              "       'user_friends_count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4WIqem7tPPA"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\r\n",
        "X_train_minmax = min_max_scaler.fit_transform(normalized_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuxzALx_K4mb"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(normalized_train, normalized_train[\"retweet_count\"],\n",
        "                                                    test_size=0.3, random_state=85)\n",
        "# We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
        "X_train = X_train.drop(['retweet_count'], axis=1)\n",
        "X_test = X_test.drop(['retweet_count'], axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdhViZaG0Tpo",
        "outputId": "b639d8ea-eccd-4997-87fc-44fdde8e5eb6"
      },
      "source": [
        "X_train.columns\n",
        "X_test.columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_statuses_count', 'user_followers_count', 'user_friends_count'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWE7aF5mLV7k",
        "outputId": "6319107f-774b-4ba5-f7ef-85e6f1f77c21"
      },
      "source": [
        "print(\"\\t Train dataset shape: \", X_train.shape)\n",
        "print(\"\\t Test dataset shape: \", X_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Train dataset shape:  (340163, 3)\n",
            "\t Test dataset shape:  (145785, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqPPt1g-1QQq"
      },
      "source": [
        "**Comment:**\n",
        "> - Storing the kernel matrix requires memory that scales quadratically with the number of data points. Training time for traditional SVM algorithms also scales superlinearly with the number of data points. So, these algorithms aren't feasible for large data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjwYi6QC0LE_"
      },
      "source": [
        "svr = SVR(kernel='rbf')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2SyrFP1seGj"
      },
      "source": [
        "svr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehG-lYCQLq-z"
      },
      "source": [
        "svr_score = svr.score(X_train, y_train)\n",
        "print(\"\\t Train accuracy: \", svr_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRrWUULRLuKt"
      },
      "source": [
        "predict = svr.predict(X_test)\n",
        "print(\"\\t Test Linear SVM accuracy: \", predict)\n",
        "print(\"\\t Prediction error using MAE: \", mean_absolute_error(y_true=y_test, y_pred=predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITugmcFuscWP"
      },
      "source": [
        "path_data_eval = path + \"/evaluation.csv\"\r\n",
        "evaluation = pd.read_csv(path_data_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7aauxYbsp6g"
      },
      "source": [
        "#Non-relevant features, can not be used for LR models\r\n",
        "evaluation.drop('timestamp', axis=1, inplace=True)\r\n",
        "evaluation.drop('user_mentions', axis=1, inplace=True)\r\n",
        "evaluation.drop('urls', axis=1, inplace=True)\r\n",
        "evaluation.drop('hashtags', axis=1, inplace=True)\r\n",
        "evaluation.drop('text', axis=1, inplace=True)\r\n",
        "evaluation.drop('user_verified', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72XkcmXjss7i"
      },
      "source": [
        "withoutID = evaluation.copy()\r\n",
        "withoutID.drop('id', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTxVbuU_vOeV"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\r\n",
        "withoutID_minmax = min_max_scaler.fit_transform(withoutID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq1f7_Btsu5-"
      },
      "source": [
        "kaggleOut  =  svr.predict(withoutID_minmax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnOlvF2qre3z"
      },
      "source": [
        "import csv\r\n",
        "\r\n",
        "f = open(\"svr_rbf.csv\", \"w+\")\r\n",
        "with open(\"svr_rbf.csv\", 'w') as f:\r\n",
        "    writer = csv.writer(f)\r\n",
        "    writer.writerow([\"TweetID\", \"NoRetweets\"])\r\n",
        "    for index, prediction in enumerate(kaggleOut):\r\n",
        "        print(str(evaluation['id'].iloc[index]) + \" ,\" + str(int(prediction)))\r\n",
        "        writer.writerow([str(evaluation['id'].iloc[index]) , str(int(prediction))])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}