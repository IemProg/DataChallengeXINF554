{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "juLi_0abKDze"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os, sys\n",
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHzXg9MJKFJr",
        "outputId": "def7e9cc-e565-4896-b261-ed956b11ed6d"
      },
      "source": [
        "!pip install verstack"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: verstack in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from verstack) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from verstack) (1.1.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from verstack) (0.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from verstack) (0.90)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->verstack) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->verstack) (2.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->verstack) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost->verstack) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->verstack) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->verstack) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-jCbaFBKJfd"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from verstack.stratified_continuous_split import scsplit "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT7sY-ogKLa1",
        "outputId": "ed9eac06-5b4d-4ea2-a2d6-0e44f4919c50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "APboaOhFKVnV",
        "outputId": "91f16c49-f170-4d2e-ddcc-2a2575e565bd"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdWfAOZyKhUo"
      },
      "source": [
        "path = \"/content/drive/My Drive/\"\n",
        "path_data_train = path + \"/covidChallenge/data/train.csv\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvhlAfYWKjSd"
      },
      "source": [
        "train_data = pd.read_csv(path_data_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXbXmcVwKlAE"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXun-dR6Kth0"
      },
      "source": [
        "#Non-relevant features, can not be used for SVMs models\n",
        "train_data.drop('timestamp', axis=1, inplace=True)\n",
        "train_data.drop('user_mentions', axis=1, inplace=True)\n",
        "train_data.drop('urls', axis=1, inplace=True)\n",
        "train_data.drop('hashtags', axis=1, inplace=True)\n",
        "train_data.drop('text', axis=1, inplace=True)\n",
        "train_data.drop('id', axis=1, inplace=True)\n",
        "train_data.drop('user_verified', axis=1, inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDfz6FjGtcW7",
        "outputId": "dbeabcdb-c97d-49f7-8039-5ae0955e6046"
      },
      "source": [
        "nbr = train_data[train_data.retweet_count != 0].shape[0]\n",
        "nbr1 = train_data[train_data.retweet_count == 0].shape[0]\n",
        "print(\"\\t Number of rows where retweets != 0: \", nbr)\n",
        "print(\"\\t Number of rows where retweets == 0: \", nbr1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Number of retweets != 0:  242974\n",
            "\t Number of retweets == 0:  422803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7WR7SqstKt1",
        "outputId": "a8ef2077-8b5d-4f96-a140-4a0cb0635363"
      },
      "source": [
        "# Shuffle the Dataset.\n",
        "shuffled_train = train_data.sample(frac=1, random_state=4)\n",
        "\n",
        "# Put all the samples where they dont have zeros re-tweet in a separate dataset.\n",
        "non_zero_retweet = shuffled_train.loc[shuffled_train['retweet_count'] != 0]\n",
        "nbr_samples = non_zero_retweet.shape[0] // 10  #We will take only sixth of it\n",
        "\n",
        "#Randomly select samples observations from the zero re-tweet (majority class)\n",
        "zero_retweet = shuffled_train.loc[shuffled_train['retweet_count'] == 0].sample(n=nbr_samples, random_state=42)\n",
        "\n",
        "print(\"Shape of non_zero_retweet: \", non_zero_retweet[:nbr_samples].shape)\n",
        "print(\"Shape of zero_retweet: \", zero_retweet.shape)\n",
        "\n",
        "# Concatenate both dataframes again\n",
        "normalized_train = pd.concat([non_zero_retweet[:nbr_samples], zero_retweet])\n",
        "print(\"Normalized train dataset: \", normalized_train.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of non_zero_retweet:  (24297, 4)\n",
            "Shape of zero_retweet:  (24297, 4)\n",
            "Normalized train dataset:  (48594, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfVq__7Mz76c",
        "outputId": "a6b293e1-c056-446c-be1e-f1fc3dd14143"
      },
      "source": [
        "nbr = normalized_train[normalized_train.retweet_count != 0].shape[0]\n",
        "nbr1 = normalized_train[normalized_train.retweet_count == 0].shape[0]\n",
        "print(\"\\t Number of rows in normalized_train where retweets != 0: \", nbr)\n",
        "print(\"\\t Number of rows in normalized_train where retweets == 0: \", nbr1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Number of rows in normalized_train where retweets != 0:  24297\n",
            "\t Number of rows in normalized_train where retweets == 0:  24297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsHud9F3vJ-d",
        "outputId": "171101b3-8fe2-4231-c2a6-0c64486a53d3"
      },
      "source": [
        "normalized_train.columns"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['retweet_count', 'user_statuses_count', 'user_followers_count',\n",
              "       'user_friends_count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuxzALx_K4mb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_train, normalized_train[\"retweet_count\"],\n",
        "                                                    test_size=0.3, random_state=85)\n",
        "# We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
        "X_train = X_train.drop(['retweet_count'], axis=1)\n",
        "X_test = X_test.drop(['retweet_count'], axis=1)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdhViZaG0Tpo",
        "outputId": "598880e7-d811-4b52-f968-e180ceb0a619"
      },
      "source": [
        "X_train.columns\n",
        "X_test.columns"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_statuses_count', 'user_followers_count', 'user_friends_count'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWE7aF5mLV7k",
        "outputId": "62eb826c-2dac-4af7-e926-b3a0dc22a652"
      },
      "source": [
        "print(\"\\t Train dataset shape: \", X_train.shape)\n",
        "print(\"\\t Test dataset shape: \", X_test.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Train dataset shape:  (34015, 3)\n",
            "\t Test dataset shape:  (14579, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqPPt1g-1QQq"
      },
      "source": [
        "**Comment:**\n",
        "> - Storing the kernel matrix requires memory that scales quadratically with the number of data points. Training time for traditional SVM algorithms also scales superlinearly with the number of data points. So, these algorithms aren't feasible for large data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7tnm0n9LWg7"
      },
      "source": [
        "linear_svm = SVC(kernel = 'linear', probability=False)\n",
        "linear_svm.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "ehG-lYCQLq-z",
        "outputId": "5a080d63-7948-49a2-fdee-32b3c597bdbc"
      },
      "source": [
        "linear_svm_score = linear_svm.score(x_train_small, y_train_small)\n",
        "print(\"\\t Train accuracy: \", linear_svm_score)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a16a8bd85fc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlinear_svm_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t Train accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_svm_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'linear_svm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "IRrWUULRLuKt",
        "outputId": "5fa43b6c-bd37-47ea-c356-af5b6abd8eed"
      },
      "source": [
        "predict = model.predict(X_test)\n",
        "print(\"\\t Test Linear SVM accuracy: \", predict)\n",
        "print(\"\\t Prediction error using MAE: \", mean_absolute_error(y_true=y_test, y_pred=predict))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6f63b1969565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t Test Linear SVM accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t Prediction error using MAE: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj6V5d0TLySf"
      },
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n",
        "Polynomial Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9i23vEaLxQ0"
      },
      "source": [
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "roc_auc = []\n",
        "f1_score = []\n",
        "pr_auc = []\n",
        "for i in range(2,8):\n",
        "    model = SVC(kernel = 'poly', probability=False, degree= i)\n",
        "    model.fit(x_train_small, y_train_small)\n",
        "    train_accuracy.append(model.score(x_train_small, y_train_small))\n",
        "\n",
        "    predicted_label = model.predict(x_test_small)\n",
        "\n",
        "    test_accuracy.append(metrics.accuracy_score(y_test_small, predicted_label)*100)\n",
        "    #roc_auc.append(metrics.roc_auc_score(y_test_small, predicted_proba))\n",
        "    f1_score.append(metrics.f1_score(y_test_small, predicted_label))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}